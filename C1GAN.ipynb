{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "from keras.datasets import mnist\n",
    "#from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D , merge, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from data_loader_ab import DataLoader\n",
    "from skimage.io import imsave\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C1GAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 256\n",
    "        self.img_cols = 256\n",
    "        self.G_channels = 1\n",
    "        self.D_channels = 2\n",
    "        self.G_img_shape = (self.img_rows, self.img_cols, self.G_channels)\n",
    "        self.D_img_shape = (self.img_rows, self.img_cols, self.D_channels)\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'place365'\n",
    "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
    "                                      img_res=(self.img_rows, self.img_cols))\n",
    "\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "        \n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        optimizerD = Adam(lr=3.16e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=optimizerD,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.D_img_shape) \n",
    "        img_B = Input(shape=self.G_img_shape)\n",
    "        embeddings = Input(shape=(1000,))\n",
    "        # By conditioning on B, throught inception embeddings, generate a fake version of A\n",
    "        fake_A = self.generator([img_B , embeddings])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([fake_A, img_B])\n",
    "\n",
    "        self.combined = Model(inputs=[img_A, img_B , embeddings], outputs=[valid, fake_A])\n",
    "        self.combined.compile(loss=['mse', 'mse'],\n",
    "                              loss_weights=[1, 100],\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        \n",
    "        embed_input = Input(shape=(1000,))\n",
    "        #Encoder\n",
    "        encoder_input = Input(shape=(256, 256, 1,))\n",
    "        encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "        #encoder_output = BatchNormalization(momentum=0.8)(encoder_output)\n",
    "        encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "        encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "        encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "        encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "        encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "        encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "        encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "\n",
    "        #Fusion\n",
    "        fusion_output = RepeatVector(32 * 32)(embed_input) \n",
    "        fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
    "        fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
    "        fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
    "\n",
    "        #Decoder\n",
    "        decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
    "        decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "        decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "        decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "        decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "        decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "        decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "        decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "        model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.D_img_shape)\n",
    "        img_B = Input(shape=self.G_img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A, img_B], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for batch_i, (imgs_A, embeddings, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on B and generate a translated version\n",
    "                #imgs_B = np.expand_dims(imgs_B, axis=0)\n",
    "                fake_A = self.generator.predict([imgs_B , embeddings])\n",
    "\n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B , embeddings], [valid, imgs_A])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                # Plot the progress\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs,\n",
    "                                                                        batch_i, self.data_loader.n_batches,\n",
    "                                                                        d_loss[0], 100*d_loss[1],\n",
    "                                                                        g_loss[0],\n",
    "                                                                        elapsed_time))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    self.sample_images(epoch, batch_i)\n",
    "               \n",
    "            self.save(epoch)\n",
    "            print(\"weights saved...\")\n",
    "            \n",
    "            \n",
    "\n",
    "    def sample_images(self, epoch, batch_i):\n",
    "        os.makedirs('images/C1-%s-%d' % (epoch , batch_i), exist_ok=True)\n",
    "        r, c = 3, 3\n",
    "\n",
    "        imgs_A, embed ,imgs_B = self.data_loader.load_data(batch_size=40)\n",
    "        fake_A = self.generator.predict([imgs_B , embed])\n",
    "        fake_A = fake_A * 128\n",
    "\n",
    "        # Output colorizations\n",
    "        for i in range(len(fake_A)):\n",
    "            cur = np.zeros((256, 256, 3))\n",
    "            cur[:,:,0] = imgs_B[i][:,:,0]\n",
    "            cur[:,:,1:] = fake_A[i]\n",
    "            imsave(\"images/C1-%s-%d/gen_%d.png\" % (epoch,batch_i, i), lab2rgb(cur))\n",
    "            \n",
    "    def sample_imagesOLD(self, epoch, batch_i , save_model = True):    \n",
    "        os.makedirs('images/C1-%s-%d' % (epoch , batch_i), exist_ok=True)\n",
    "        imgs_A, embed ,imgs_B = self.data_loader.load_data(batch_size=25)\n",
    "        fake_A = self.generator.predict([imgs_B , embed])\n",
    "        fake_A = fake_A * 128\n",
    "        imgs_A = imgs_A*128\n",
    "        \n",
    "        titles = ['B&W', 'Generated', 'Original']\n",
    "        \n",
    "        \n",
    "        for i in range(len(fake_A)):\n",
    "\n",
    "            fig, axs = plt.subplots(3)\n",
    "            axs[0].set_title(titles[0])\n",
    "            axs[1].set_title(titles[1])\n",
    "            axs[2].set_title(titles[2])\n",
    "            \n",
    "            gen = np.zeros((256, 256, 3))\n",
    "            gen[:,:,0] = imgs_B[i][:,:,0]\n",
    "            gen[:,:,1:] = fake_A[i]\n",
    "            rgb_gen = lab2rgb(gen)\n",
    "            \n",
    "            real = np.zeros((256, 256, 3))\n",
    "            real[:,:,0] = imgs_B[i][:,:,0]\n",
    "            real[:,:,1:] = imgs_A[i]\n",
    "            rgb_real = lab2rgb(real)\n",
    "            \n",
    "            \n",
    "            gen = np.zeros((256, 256, 3))\n",
    "            gen[:,:,0] = imgs_B[i][:,:,0]\n",
    "            gen[:,:,1:] = imgs_A[i]/128\n",
    "            rgb_bew = lab2rgb(gen)\n",
    "\n",
    "            \n",
    "            \n",
    "            axs[0].imshow(rgb_bew)\n",
    "            axs[1].imshow(rgb_gen)\n",
    "            axs[2].imshow(rgb_real)\n",
    "            \n",
    "            #imsave(\"images/C1-%s-%d/%d_bew.png\" % (epoch,batch_i, i), rgb_bew)\n",
    "            #imsave(\"images/C1-%s-%d/%d_real.png\" % (epoch,batch_i, i), rgb_real)\n",
    "            #imsave(\"images/C1-%s-%d/%d_gen.png\" % (epoch,batch_i, i), rgb_gen)\n",
    "            \n",
    "            fig.savefig(\"images/C1-%s-%d/turing%d.png\" % (epoch,batch_i, i))\n",
    "            plt.close()\n",
    "            \n",
    "        if(save_model):    \n",
    "            self.save(epoch)\n",
    "        \n",
    "    def save(self,ep):\n",
    "        os.makedirs('saved_model/C1-%s' % ep, exist_ok=True)\n",
    "        self.combined.save_weights(\"./saved_model/C1-%s/modelW_epoch_%d.h5\" % (ep , ep))\n",
    "        self.generator.save_weights(\"./saved_model/C1-%s/genW_epoch_%d.h5\" % (ep, ep))\n",
    "        self.discriminator.save_weights(\"./saved_model/C1-%s/disW_epoch_%d.h5\" % (ep, ep))\n",
    "        \n",
    "    def load(self,ep):\n",
    "        self.combined.load_weights(\"./saved_model/C1-%s/modelW_epoch_%d.h5\" % (ep , ep))\n",
    "        self.generator.load_weights(\"./saved_model/C1-%s/genW_epoch_%d.h5\" % (ep, ep))\n",
    "        self.discriminator.load_weights(\"./saved_model/C1-%s/disW_epoch_%d.h5\" % (ep, ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = C1GAN()\n",
    "gan.load(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\miche\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 0/350] [D loss: 0.266566, acc:  32%] [G loss: 1.143466] time: 0:00:16.366317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 1/350] [D loss: 0.259885, acc:  53%] [G loss: 1.130720] time: 0:00:29.419494\n",
      "[Epoch 0/10] [Batch 2/350] [D loss: 0.256177, acc:  57%] [G loss: 1.258416] time: 0:00:35.805417\n",
      "[Epoch 0/10] [Batch 3/350] [D loss: 0.253612, acc:  50%] [G loss: 1.476810] time: 0:00:42.192338\n",
      "[Epoch 0/10] [Batch 4/350] [D loss: 0.252900, acc:  48%] [G loss: 1.317581] time: 0:00:48.661043\n",
      "[Epoch 0/10] [Batch 5/350] [D loss: 0.253167, acc:  46%] [G loss: 1.326573] time: 0:00:55.065917\n",
      "[Epoch 0/10] [Batch 6/350] [D loss: 0.253152, acc:  50%] [G loss: 1.300932] time: 0:01:01.481731\n",
      "[Epoch 0/10] [Batch 7/350] [D loss: 0.252400, acc:  49%] [G loss: 1.284121] time: 0:01:07.862670\n",
      "[Epoch 0/10] [Batch 8/350] [D loss: 0.252998, acc:  43%] [G loss: 1.077934] time: 0:01:14.258569\n",
      "[Epoch 0/10] [Batch 9/350] [D loss: 0.252083, acc:  50%] [G loss: 1.191026] time: 0:01:20.645523\n",
      "[Epoch 0/10] [Batch 10/350] [D loss: 0.251629, acc:  47%] [G loss: 1.300182] time: 0:01:27.015459\n",
      "[Epoch 0/10] [Batch 11/350] [D loss: 0.252638, acc:  48%] [G loss: 1.472468] time: 0:01:33.408398\n",
      "[Epoch 0/10] [Batch 12/350] [D loss: 0.252429, acc:  52%] [G loss: 1.223845] time: 0:01:39.785315\n",
      "[Epoch 0/10] [Batch 13/350] [D loss: 0.251340, acc:  48%] [G loss: 1.112201] time: 0:01:46.151294\n",
      "[Epoch 0/10] [Batch 14/350] [D loss: 0.251220, acc:  48%] [G loss: 1.162718] time: 0:01:52.487384\n",
      "[Epoch 0/10] [Batch 15/350] [D loss: 0.251652, acc:  47%] [G loss: 1.119345] time: 0:01:58.837405\n",
      "[Epoch 0/10] [Batch 16/350] [D loss: 0.251891, acc:  52%] [G loss: 1.104950] time: 0:02:05.123598\n",
      "[Epoch 0/10] [Batch 17/350] [D loss: 0.252228, acc:  45%] [G loss: 1.529463] time: 0:02:11.392836\n",
      "[Epoch 0/10] [Batch 18/350] [D loss: 0.251548, acc:  50%] [G loss: 1.278983] time: 0:02:17.758782\n",
      "[Epoch 0/10] [Batch 19/350] [D loss: 0.251988, acc:  50%] [G loss: 1.245606] time: 0:02:24.069908\n",
      "[Epoch 0/10] [Batch 20/350] [D loss: 0.251936, acc:  50%] [G loss: 1.404367] time: 0:02:30.396990\n",
      "[Epoch 0/10] [Batch 21/350] [D loss: 0.251638, acc:  48%] [G loss: 1.279584] time: 0:02:36.703161\n",
      "[Epoch 0/10] [Batch 22/350] [D loss: 0.251858, acc:  48%] [G loss: 1.106699] time: 0:02:43.045171\n",
      "[Epoch 0/10] [Batch 23/350] [D loss: 0.251413, acc:  47%] [G loss: 1.376021] time: 0:02:49.349316\n",
      "[Epoch 0/10] [Batch 24/350] [D loss: 0.251810, acc:  51%] [G loss: 1.127939] time: 0:02:55.646478\n",
      "[Epoch 0/10] [Batch 25/350] [D loss: 0.251901, acc:  49%] [G loss: 1.138409] time: 0:03:01.961593\n",
      "[Epoch 0/10] [Batch 26/350] [D loss: 0.251641, acc:  46%] [G loss: 1.194580] time: 0:03:08.262776\n",
      "[Epoch 0/10] [Batch 27/350] [D loss: 0.251856, acc:  52%] [G loss: 1.256117] time: 0:03:14.563928\n",
      "[Epoch 0/10] [Batch 28/350] [D loss: 0.251993, acc:  48%] [G loss: 1.149622] time: 0:03:20.893010\n",
      "[Epoch 0/10] [Batch 29/350] [D loss: 0.251567, acc:  47%] [G loss: 1.213789] time: 0:03:27.198150\n",
      "[Epoch 0/10] [Batch 30/350] [D loss: 0.251371, acc:  48%] [G loss: 1.156102] time: 0:03:33.516254\n",
      "[Epoch 0/10] [Batch 31/350] [D loss: 0.251467, acc:  48%] [G loss: 1.236449] time: 0:03:39.846297\n",
      "[Epoch 0/10] [Batch 32/350] [D loss: 0.251578, acc:  47%] [G loss: 1.196718] time: 0:03:46.196349\n",
      "[Epoch 0/10] [Batch 33/350] [D loss: 0.251670, acc:  50%] [G loss: 1.241807] time: 0:03:52.501459\n",
      "[Epoch 0/10] [Batch 34/350] [D loss: 0.251946, acc:  50%] [G loss: 1.174577] time: 0:03:58.806632\n",
      "[Epoch 0/10] [Batch 35/350] [D loss: 0.251651, acc:  51%] [G loss: 1.068402] time: 0:04:05.117758\n",
      "[Epoch 0/10] [Batch 36/350] [D loss: 0.251545, acc:  48%] [G loss: 1.049722] time: 0:04:11.405913\n",
      "[Epoch 0/10] [Batch 37/350] [D loss: 0.251660, acc:  49%] [G loss: 1.343138] time: 0:04:17.700116\n",
      "[Epoch 0/10] [Batch 38/350] [D loss: 0.251745, acc:  48%] [G loss: 1.367854] time: 0:04:24.037140\n",
      "[Epoch 0/10] [Batch 39/350] [D loss: 0.251516, acc:  47%] [G loss: 1.193794] time: 0:04:30.495901\n",
      "[Epoch 0/10] [Batch 40/350] [D loss: 0.251723, acc:  46%] [G loss: 1.321678] time: 0:04:36.896755\n",
      "[Epoch 0/10] [Batch 41/350] [D loss: 0.252123, acc:  47%] [G loss: 1.296183] time: 0:04:43.221876\n",
      "[Epoch 0/10] [Batch 42/350] [D loss: 0.251669, acc:  47%] [G loss: 1.073487] time: 0:04:49.535995\n",
      "[Epoch 0/10] [Batch 43/350] [D loss: 0.251870, acc:  49%] [G loss: 1.272326] time: 0:04:55.851107\n",
      "[Epoch 0/10] [Batch 44/350] [D loss: 0.251611, acc:  46%] [G loss: 1.255644] time: 0:05:02.176163\n",
      "[Epoch 0/10] [Batch 45/350] [D loss: 0.251792, acc:  48%] [G loss: 1.221684] time: 0:05:08.485326\n",
      "[Epoch 0/10] [Batch 46/350] [D loss: 0.251410, acc:  48%] [G loss: 1.104512] time: 0:05:14.790470\n",
      "[Epoch 0/10] [Batch 47/350] [D loss: 0.251440, acc:  47%] [G loss: 1.232893] time: 0:05:21.101595\n",
      "[Epoch 0/10] [Batch 48/350] [D loss: 0.251574, acc:  46%] [G loss: 1.309576] time: 0:05:27.429641\n",
      "[Epoch 0/10] [Batch 49/350] [D loss: 0.251599, acc:  49%] [G loss: 1.069659] time: 0:05:33.756724\n",
      "[Epoch 0/10] [Batch 50/350] [D loss: 0.251545, acc:  48%] [G loss: 1.098002] time: 0:05:40.090787\n",
      "[Epoch 0/10] [Batch 51/350] [D loss: 0.251860, acc:  45%] [G loss: 1.079976] time: 0:05:46.426846\n",
      "[Epoch 0/10] [Batch 52/350] [D loss: 0.251917, acc:  49%] [G loss: 1.072578] time: 0:05:52.741992\n",
      "[Epoch 0/10] [Batch 53/350] [D loss: 0.252013, acc:  53%] [G loss: 1.060604] time: 0:05:59.094974\n",
      "[Epoch 0/10] [Batch 54/350] [D loss: 0.251612, acc:  53%] [G loss: 1.248801] time: 0:06:05.405102\n",
      "[Epoch 0/10] [Batch 55/350] [D loss: 0.251712, acc:  49%] [G loss: 1.194444] time: 0:06:11.730190\n",
      "[Epoch 0/10] [Batch 56/350] [D loss: 0.251448, acc:  50%] [G loss: 1.417415] time: 0:06:18.052314\n",
      "[Epoch 0/10] [Batch 57/350] [D loss: 0.251562, acc:  53%] [G loss: 1.279125] time: 0:06:24.348451\n",
      "[Epoch 0/10] [Batch 58/350] [D loss: 0.251652, acc:  50%] [G loss: 1.342727] time: 0:06:30.717422\n",
      "[Epoch 0/10] [Batch 59/350] [D loss: 0.251654, acc:  49%] [G loss: 1.290840] time: 0:06:37.058467\n",
      "[Epoch 0/10] [Batch 60/350] [D loss: 0.251818, acc:  50%] [G loss: 1.294955] time: 0:06:43.364606\n",
      "[Epoch 0/10] [Batch 61/350] [D loss: 0.251965, acc:  47%] [G loss: 1.461401] time: 0:06:49.684739\n",
      "[Epoch 0/10] [Batch 62/350] [D loss: 0.251901, acc:  44%] [G loss: 1.266715] time: 0:06:56.002843\n",
      "[Epoch 0/10] [Batch 63/350] [D loss: 0.251793, acc:  46%] [G loss: 1.340229] time: 0:07:02.289038\n",
      "[Epoch 0/10] [Batch 64/350] [D loss: 0.251702, acc:  47%] [G loss: 1.425466] time: 0:07:08.600163\n",
      "[Epoch 0/10] [Batch 65/350] [D loss: 0.252062, acc:  44%] [G loss: 1.224397] time: 0:07:15.001048\n",
      "[Epoch 0/10] [Batch 66/350] [D loss: 0.251793, acc:  50%] [G loss: 1.254171] time: 0:07:21.332089\n",
      "[Epoch 0/10] [Batch 67/350] [D loss: 0.251835, acc:  48%] [G loss: 1.381374] time: 0:07:27.639256\n",
      "[Epoch 0/10] [Batch 68/350] [D loss: 0.252261, acc:  47%] [G loss: 1.114009] time: 0:07:34.093998\n",
      "[Epoch 0/10] [Batch 69/350] [D loss: 0.252268, acc:  45%] [G loss: 1.296850] time: 0:07:40.443022\n",
      "[Epoch 0/10] [Batch 70/350] [D loss: 0.252464, acc:  49%] [G loss: 1.259300] time: 0:07:46.782041\n",
      "[Epoch 0/10] [Batch 71/350] [D loss: 0.252014, acc:  47%] [G loss: 1.255351] time: 0:07:53.097187\n",
      "[Epoch 0/10] [Batch 72/350] [D loss: 0.252058, acc:  51%] [G loss: 1.259315] time: 0:07:59.422275\n",
      "[Epoch 0/10] [Batch 73/350] [D loss: 0.252091, acc:  50%] [G loss: 1.174703] time: 0:08:05.734398\n",
      "[Epoch 0/10] [Batch 74/350] [D loss: 0.252189, acc:  48%] [G loss: 1.461728] time: 0:08:12.040504\n",
      "[Epoch 0/10] [Batch 75/350] [D loss: 0.252769, acc:  49%] [G loss: 1.325187] time: 0:08:18.375566\n",
      "[Epoch 0/10] [Batch 76/350] [D loss: 0.252840, acc:  49%] [G loss: 1.585301] time: 0:08:24.691709\n",
      "[Epoch 0/10] [Batch 77/350] [D loss: 0.251986, acc:  49%] [G loss: 1.232687] time: 0:08:31.005795\n",
      "[Epoch 0/10] [Batch 78/350] [D loss: 0.252159, acc:  53%] [G loss: 1.264084] time: 0:08:37.320945\n",
      "[Epoch 0/10] [Batch 79/350] [D loss: 0.252023, acc:  47%] [G loss: 1.401890] time: 0:08:43.673955\n",
      "[Epoch 0/10] [Batch 80/350] [D loss: 0.251959, acc:  49%] [G loss: 1.347163] time: 0:08:49.981091\n",
      "[Epoch 0/10] [Batch 81/350] [D loss: 0.252740, acc:  53%] [G loss: 1.397764] time: 0:08:56.290223\n",
      "[Epoch 0/10] [Batch 82/350] [D loss: 0.252805, acc:  50%] [G loss: 1.118869] time: 0:09:02.622291\n",
      "[Epoch 0/10] [Batch 83/350] [D loss: 0.252319, acc:  50%] [G loss: 1.336283] time: 0:09:08.936376\n",
      "[Epoch 0/10] [Batch 84/350] [D loss: 0.252560, acc:  47%] [G loss: 1.480484] time: 0:09:15.238526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 85/350] [D loss: 0.252129, acc:  45%] [G loss: 1.320943] time: 0:09:21.546659\n",
      "[Epoch 0/10] [Batch 86/350] [D loss: 0.252062, acc:  49%] [G loss: 1.159334] time: 0:09:27.845816\n",
      "[Epoch 0/10] [Batch 87/350] [D loss: 0.252746, acc:  51%] [G loss: 1.485478] time: 0:09:34.153950\n",
      "[Epoch 0/10] [Batch 88/350] [D loss: 0.252264, acc:  50%] [G loss: 1.122989] time: 0:09:40.521923\n",
      "[Epoch 0/10] [Batch 89/350] [D loss: 0.251572, acc:  50%] [G loss: 1.256689] time: 0:09:46.856019\n",
      "[Epoch 0/10] [Batch 90/350] [D loss: 0.251632, acc:  50%] [G loss: 1.166589] time: 0:09:53.153182\n",
      "[Epoch 0/10] [Batch 91/350] [D loss: 0.251602, acc:  49%] [G loss: 1.097389] time: 0:09:59.479235\n",
      "[Epoch 0/10] [Batch 92/350] [D loss: 0.251778, acc:  46%] [G loss: 1.142729] time: 0:10:05.795382\n",
      "[Epoch 0/10] [Batch 93/350] [D loss: 0.251510, acc:  48%] [G loss: 1.205928] time: 0:10:12.104478\n",
      "[Epoch 0/10] [Batch 94/350] [D loss: 0.251521, acc:  49%] [G loss: 1.264405] time: 0:10:18.426609\n",
      "[Epoch 0/10] [Batch 95/350] [D loss: 0.251468, acc:  45%] [G loss: 1.251741] time: 0:10:24.733741\n",
      "[Epoch 0/10] [Batch 96/350] [D loss: 0.251515, acc:  51%] [G loss: 1.108142] time: 0:10:31.011953\n",
      "[Epoch 0/10] [Batch 97/350] [D loss: 0.251467, acc:  49%] [G loss: 1.404819] time: 0:10:37.290137\n",
      "[Epoch 0/10] [Batch 98/350] [D loss: 0.251517, acc:  47%] [G loss: 1.153729] time: 0:10:43.551427\n",
      "[Epoch 0/10] [Batch 99/350] [D loss: 0.251417, acc:  46%] [G loss: 1.208346] time: 0:10:49.824622\n",
      "[Epoch 0/10] [Batch 100/350] [D loss: 0.251546, acc:  48%] [G loss: 1.316773] time: 0:10:56.086878\n",
      "[Epoch 0/10] [Batch 101/350] [D loss: 0.251772, acc:  50%] [G loss: 1.131930] time: 0:11:02.391054\n",
      "[Epoch 0/10] [Batch 102/350] [D loss: 0.252632, acc:  55%] [G loss: 1.422266] time: 0:11:08.660259\n",
      "[Epoch 0/10] [Batch 103/350] [D loss: 0.252873, acc:  49%] [G loss: 1.356397] time: 0:11:14.939504\n",
      "[Epoch 0/10] [Batch 104/350] [D loss: 0.252127, acc:  52%] [G loss: 1.319008] time: 0:11:21.235635\n",
      "[Epoch 0/10] [Batch 105/350] [D loss: 0.252066, acc:  41%] [G loss: 1.279433] time: 0:11:27.532827\n",
      "[Epoch 0/10] [Batch 106/350] [D loss: 0.252063, acc:  50%] [G loss: 1.513448] time: 0:11:33.834980\n",
      "[Epoch 0/10] [Batch 107/350] [D loss: 0.251656, acc:  51%] [G loss: 1.097742] time: 0:11:40.148068\n",
      "[Epoch 0/10] [Batch 108/350] [D loss: 0.252052, acc:  47%] [G loss: 1.261823] time: 0:11:46.478142\n",
      "[Epoch 0/10] [Batch 109/350] [D loss: 0.252915, acc:  51%] [G loss: 1.248914] time: 0:11:52.751369\n",
      "[Epoch 0/10] [Batch 110/350] [D loss: 0.252347, acc:  48%] [G loss: 1.381771] time: 0:11:59.027587\n",
      "[Epoch 0/10] [Batch 111/350] [D loss: 0.252128, acc:  47%] [G loss: 1.241488] time: 0:12:05.301811\n",
      "[Epoch 0/10] [Batch 112/350] [D loss: 0.253185, acc:  50%] [G loss: 1.495188] time: 0:12:11.588037\n",
      "[Epoch 0/10] [Batch 113/350] [D loss: 0.252769, acc:  50%] [G loss: 1.238649] time: 0:12:17.937027\n",
      "[Epoch 0/10] [Batch 114/350] [D loss: 0.251982, acc:  46%] [G loss: 1.270000] time: 0:12:24.233225\n",
      "[Epoch 0/10] [Batch 115/350] [D loss: 0.252713, acc:  47%] [G loss: 1.416757] time: 0:12:30.534375\n",
      "[Epoch 0/10] [Batch 116/350] [D loss: 0.252580, acc:  56%] [G loss: 1.324606] time: 0:12:36.830510\n",
      "[Epoch 0/10] [Batch 117/350] [D loss: 0.252485, acc:  55%] [G loss: 1.195567] time: 0:12:43.106729\n",
      "[Epoch 0/10] [Batch 118/350] [D loss: 0.253407, acc:  47%] [G loss: 1.345971] time: 0:12:49.379955\n",
      "[Epoch 0/10] [Batch 119/350] [D loss: 0.251887, acc:  43%] [G loss: 1.272448] time: 0:12:55.665182\n",
      "[Epoch 0/10] [Batch 120/350] [D loss: 0.252107, acc:  53%] [G loss: 1.269868] time: 0:13:01.966302\n",
      "[Epoch 0/10] [Batch 121/350] [D loss: 0.252047, acc:  47%] [G loss: 1.213365] time: 0:13:08.225566\n",
      "[Epoch 0/10] [Batch 122/350] [D loss: 0.251795, acc:  49%] [G loss: 1.206439] time: 0:13:14.482835\n",
      "[Epoch 0/10] [Batch 123/350] [D loss: 0.252468, acc:  48%] [G loss: 1.178051] time: 0:13:20.768030\n",
      "[Epoch 0/10] [Batch 124/350] [D loss: 0.252358, acc:  51%] [G loss: 1.206385] time: 0:13:27.039294\n",
      "[Epoch 0/10] [Batch 125/350] [D loss: 0.251803, acc:  48%] [G loss: 1.125653] time: 0:13:33.323492\n",
      "[Epoch 0/10] [Batch 126/350] [D loss: 0.251824, acc:  44%] [G loss: 1.302300] time: 0:13:39.624644\n",
      "[Epoch 0/10] [Batch 127/350] [D loss: 0.252130, acc:  50%] [G loss: 1.287739] time: 0:13:45.920777\n",
      "[Epoch 0/10] [Batch 128/350] [D loss: 0.252119, acc:  54%] [G loss: 1.124510] time: 0:13:52.210989\n",
      "[Epoch 0/10] [Batch 129/350] [D loss: 0.251996, acc:  47%] [G loss: 1.294219] time: 0:13:58.496185\n",
      "[Epoch 0/10] [Batch 130/350] [D loss: 0.252234, acc:  49%] [G loss: 1.310524] time: 0:14:04.792318\n",
      "[Epoch 0/10] [Batch 131/350] [D loss: 0.251810, acc:  51%] [G loss: 1.173441] time: 0:14:11.079507\n",
      "[Epoch 0/10] [Batch 132/350] [D loss: 0.251967, acc:  49%] [G loss: 1.147769] time: 0:14:17.375673\n",
      "[Epoch 0/10] [Batch 133/350] [D loss: 0.252459, acc:  48%] [G loss: 1.335831] time: 0:14:23.672835\n",
      "[Epoch 0/10] [Batch 134/350] [D loss: 0.251803, acc:  42%] [G loss: 1.238849] time: 0:14:29.937118\n",
      "[Epoch 0/10] [Batch 135/350] [D loss: 0.251498, acc:  50%] [G loss: 1.369610] time: 0:14:36.223309\n",
      "[Epoch 0/10] [Batch 136/350] [D loss: 0.251561, acc:  46%] [G loss: 1.194937] time: 0:14:42.513459\n",
      "[Epoch 0/10] [Batch 137/350] [D loss: 0.251469, acc:  48%] [G loss: 1.357841] time: 0:14:48.803641\n",
      "[Epoch 0/10] [Batch 138/350] [D loss: 0.251615, acc:  47%] [G loss: 1.456139] time: 0:14:55.061939\n",
      "[Epoch 0/10] [Batch 139/350] [D loss: 0.252359, acc:  53%] [G loss: 1.156049] time: 0:15:01.344141\n",
      "[Epoch 0/10] [Batch 140/350] [D loss: 0.252731, acc:  49%] [G loss: 1.331887] time: 0:15:07.625315\n",
      "[Epoch 0/10] [Batch 141/350] [D loss: 0.252086, acc:  43%] [G loss: 1.187790] time: 0:15:13.899540\n",
      "[Epoch 0/10] [Batch 142/350] [D loss: 0.252167, acc:  48%] [G loss: 1.146610] time: 0:15:20.419139\n",
      "[Epoch 0/10] [Batch 143/350] [D loss: 0.251952, acc:  48%] [G loss: 1.296786] time: 0:15:26.727241\n",
      "[Epoch 0/10] [Batch 144/350] [D loss: 0.251648, acc:  49%] [G loss: 1.318442] time: 0:15:33.010441\n",
      "[Epoch 0/10] [Batch 145/350] [D loss: 0.252014, acc:  48%] [G loss: 1.477561] time: 0:15:39.294638\n",
      "[Epoch 0/10] [Batch 146/350] [D loss: 0.251673, acc:  47%] [G loss: 1.379002] time: 0:15:45.632723\n",
      "[Epoch 0/10] [Batch 147/350] [D loss: 0.251656, acc:  45%] [G loss: 1.305182] time: 0:15:51.930883\n",
      "[Epoch 0/10] [Batch 148/350] [D loss: 0.252276, acc:  45%] [G loss: 1.333506] time: 0:15:58.222064\n",
      "[Epoch 0/10] [Batch 149/350] [D loss: 0.251844, acc:  50%] [G loss: 1.102109] time: 0:16:04.530194\n",
      "[Epoch 0/10] [Batch 150/350] [D loss: 0.251485, acc:  51%] [G loss: 1.295193] time: 0:16:10.830350\n",
      "[Epoch 0/10] [Batch 151/350] [D loss: 0.251325, acc:  47%] [G loss: 1.187119] time: 0:16:17.111555\n",
      "[Epoch 0/10] [Batch 152/350] [D loss: 0.251553, acc:  49%] [G loss: 1.366059] time: 0:16:23.404697\n",
      "[Epoch 0/10] [Batch 153/350] [D loss: 0.251483, acc:  49%] [G loss: 1.163889] time: 0:16:29.691886\n",
      "[Epoch 0/10] [Batch 154/350] [D loss: 0.251842, acc:  50%] [G loss: 1.275844] time: 0:16:36.002014\n",
      "[Epoch 0/10] [Batch 155/350] [D loss: 0.252063, acc:  46%] [G loss: 1.191979] time: 0:16:42.290201\n",
      "[Epoch 0/10] [Batch 156/350] [D loss: 0.252008, acc:  45%] [G loss: 1.173173] time: 0:16:48.569411\n",
      "[Epoch 0/10] [Batch 157/350] [D loss: 0.251855, acc:  51%] [G loss: 1.221812] time: 0:16:54.846627\n",
      "[Epoch 0/10] [Batch 158/350] [D loss: 0.251848, acc:  49%] [G loss: 1.174901] time: 0:17:01.127864\n",
      "[Epoch 0/10] [Batch 159/350] [D loss: 0.251664, acc:  47%] [G loss: 1.379715] time: 0:17:07.408041\n",
      "[Epoch 0/10] [Batch 160/350] [D loss: 0.251993, acc:  50%] [G loss: 1.205406] time: 0:17:13.694264\n",
      "[Epoch 0/10] [Batch 161/350] [D loss: 0.251949, acc:  46%] [G loss: 1.288431] time: 0:17:19.953527\n",
      "[Epoch 0/10] [Batch 162/350] [D loss: 0.251810, acc:  49%] [G loss: 1.196875] time: 0:17:26.249662\n",
      "[Epoch 0/10] [Batch 163/350] [D loss: 0.252614, acc:  47%] [G loss: 1.225037] time: 0:17:32.538877\n",
      "[Epoch 0/10] [Batch 164/350] [D loss: 0.252205, acc:  47%] [G loss: 1.171691] time: 0:17:38.806120\n",
      "[Epoch 0/10] [Batch 165/350] [D loss: 0.251697, acc:  47%] [G loss: 1.186166] time: 0:17:45.119240\n",
      "[Epoch 0/10] [Batch 166/350] [D loss: 0.251867, acc:  48%] [G loss: 1.265763] time: 0:17:51.393433\n",
      "[Epoch 0/10] [Batch 167/350] [D loss: 0.251659, acc:  48%] [G loss: 1.034269] time: 0:17:57.672643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 168/350] [D loss: 0.251901, acc:  46%] [G loss: 1.244353] time: 0:18:03.975790\n",
      "[Epoch 0/10] [Batch 169/350] [D loss: 0.252847, acc:  52%] [G loss: 1.019294] time: 0:18:10.224083\n",
      "[Epoch 0/10] [Batch 170/350] [D loss: 0.252681, acc:  47%] [G loss: 1.298074] time: 0:18:16.504323\n",
      "[Epoch 0/10] [Batch 171/350] [D loss: 0.252113, acc:  48%] [G loss: 1.256574] time: 0:18:22.797496\n",
      "[Epoch 0/10] [Batch 172/350] [D loss: 0.253263, acc:  51%] [G loss: 1.206284] time: 0:18:29.063742\n",
      "[Epoch 0/10] [Batch 173/350] [D loss: 0.253493, acc:  50%] [G loss: 1.475854] time: 0:18:35.357912\n",
      "[Epoch 0/10] [Batch 174/350] [D loss: 0.251988, acc:  50%] [G loss: 1.251519] time: 0:18:41.632105\n",
      "[Epoch 0/10] [Batch 175/350] [D loss: 0.253107, acc:  45%] [G loss: 1.367717] time: 0:18:47.909321\n",
      "[Epoch 0/10] [Batch 176/350] [D loss: 0.253708, acc:  49%] [G loss: 1.213065] time: 0:18:59.748695\n",
      "[Epoch 0/10] [Batch 177/350] [D loss: 0.251943, acc:  48%] [G loss: 1.342495] time: 0:19:06.039906\n",
      "[Epoch 0/10] [Batch 178/350] [D loss: 0.251759, acc:  49%] [G loss: 1.249292] time: 0:19:12.349036\n",
      "[Epoch 0/10] [Batch 179/350] [D loss: 0.251671, acc:  48%] [G loss: 1.171746] time: 0:19:18.653180\n",
      "[Epoch 0/10] [Batch 180/350] [D loss: 0.251624, acc:  48%] [G loss: 1.131455] time: 0:19:24.960284\n",
      "[Epoch 0/10] [Batch 181/350] [D loss: 0.251592, acc:  49%] [G loss: 1.232570] time: 0:19:31.278391\n",
      "[Epoch 0/10] [Batch 182/350] [D loss: 0.251608, acc:  48%] [G loss: 1.145044] time: 0:19:37.580540\n",
      "[Epoch 0/10] [Batch 183/350] [D loss: 0.251274, acc:  48%] [G loss: 1.328885] time: 0:19:43.918594\n",
      "[Epoch 0/10] [Batch 184/350] [D loss: 0.251461, acc:  48%] [G loss: 1.282040] time: 0:19:50.205814\n",
      "[Epoch 0/10] [Batch 185/350] [D loss: 0.251814, acc:  49%] [G loss: 1.020282] time: 0:19:56.502977\n",
      "[Epoch 0/10] [Batch 186/350] [D loss: 0.251740, acc:  47%] [G loss: 1.305498] time: 0:20:02.784183\n",
      "[Epoch 0/10] [Batch 187/350] [D loss: 0.251531, acc:  46%] [G loss: 1.281968] time: 0:20:09.100295\n",
      "[Epoch 0/10] [Batch 188/350] [D loss: 0.251840, acc:  48%] [G loss: 1.019278] time: 0:20:15.386455\n",
      "[Epoch 0/10] [Batch 189/350] [D loss: 0.251916, acc:  53%] [G loss: 1.174078] time: 0:20:21.691597\n",
      "[Epoch 0/10] [Batch 190/350] [D loss: 0.251702, acc:  50%] [G loss: 1.450875] time: 0:20:27.972802\n",
      "[Epoch 0/10] [Batch 191/350] [D loss: 0.252053, acc:  46%] [G loss: 1.295390] time: 0:20:34.293901\n",
      "[Epoch 0/10] [Batch 192/350] [D loss: 0.251777, acc:  44%] [G loss: 1.113208] time: 0:20:40.563138\n",
      "[Epoch 0/10] [Batch 193/350] [D loss: 0.252086, acc:  50%] [G loss: 1.266227] time: 0:20:46.845372\n",
      "[Epoch 0/10] [Batch 194/350] [D loss: 0.252118, acc:  49%] [G loss: 1.461515] time: 0:20:53.133559\n",
      "[Epoch 0/10] [Batch 195/350] [D loss: 0.252416, acc:  45%] [G loss: 1.233841] time: 0:20:59.427730\n",
      "[Epoch 0/10] [Batch 196/350] [D loss: 0.253314, acc:  51%] [G loss: 1.246914] time: 0:21:05.698929\n",
      "[Epoch 0/10] [Batch 197/350] [D loss: 0.252548, acc:  50%] [G loss: 1.068108] time: 0:21:12.013047\n",
      "[Epoch 0/10] [Batch 198/350] [D loss: 0.252625, acc:  47%] [G loss: 1.133238] time: 0:21:18.303228\n",
      "[Epoch 0/10] [Batch 199/350] [D loss: 0.253222, acc:  47%] [G loss: 1.163362] time: 0:21:24.607373\n",
      "[Epoch 0/10] [Batch 200/350] [D loss: 0.251999, acc:  44%] [G loss: 1.259986] time: 0:21:30.910519\n",
      "[Epoch 0/10] [Batch 201/350] [D loss: 0.251655, acc:  50%] [G loss: 1.085846] time: 0:21:37.204690\n",
      "[Epoch 0/10] [Batch 202/350] [D loss: 0.251731, acc:  48%] [G loss: 1.251167] time: 0:21:43.520803\n",
      "[Epoch 0/10] [Batch 203/350] [D loss: 0.251505, acc:  47%] [G loss: 1.157063] time: 0:21:49.813010\n",
      "[Epoch 0/10] [Batch 204/350] [D loss: 0.251768, acc:  51%] [G loss: 1.175832] time: 0:21:56.098203\n",
      "[Epoch 0/10] [Batch 205/350] [D loss: 0.251722, acc:  50%] [G loss: 1.143877] time: 0:22:02.386360\n",
      "[Epoch 0/10] [Batch 206/350] [D loss: 0.251539, acc:  49%] [G loss: 1.224894] time: 0:22:08.672582\n",
      "[Epoch 0/10] [Batch 207/350] [D loss: 0.251496, acc:  46%] [G loss: 1.364454] time: 0:22:15.033544\n",
      "[Epoch 0/10] [Batch 208/350] [D loss: 0.251707, acc:  48%] [G loss: 1.155914] time: 0:22:21.338685\n",
      "[Epoch 0/10] [Batch 209/350] [D loss: 0.251853, acc:  48%] [G loss: 1.349097] time: 0:22:27.630861\n",
      "[Epoch 0/10] [Batch 210/350] [D loss: 0.251632, acc:  49%] [G loss: 1.272515] time: 0:22:33.934039\n",
      "[Epoch 0/10] [Batch 211/350] [D loss: 0.251520, acc:  48%] [G loss: 1.071866] time: 0:22:40.225186\n",
      "[Epoch 0/10] [Batch 212/350] [D loss: 0.251661, acc:  48%] [G loss: 1.019947] time: 0:22:46.527367\n",
      "[Epoch 0/10] [Batch 213/350] [D loss: 0.251723, acc:  47%] [G loss: 1.150442] time: 0:22:52.830482\n",
      "[Epoch 0/10] [Batch 214/350] [D loss: 0.251478, acc:  48%] [G loss: 1.143949] time: 0:22:59.135623\n",
      "[Epoch 0/10] [Batch 215/350] [D loss: 0.251376, acc:  47%] [G loss: 1.288539] time: 0:23:05.423810\n",
      "[Epoch 0/10] [Batch 216/350] [D loss: 0.251410, acc:  47%] [G loss: 1.111203] time: 0:23:11.717980\n",
      "[Epoch 0/10] [Batch 217/350] [D loss: 0.251589, acc:  47%] [G loss: 1.029248] time: 0:23:18.022124\n",
      "[Epoch 0/10] [Batch 218/350] [D loss: 0.251568, acc:  48%] [G loss: 1.181452] time: 0:23:24.338237\n",
      "[Epoch 0/10] [Batch 219/350] [D loss: 0.252638, acc:  42%] [G loss: 1.179010] time: 0:23:30.655345\n",
      "[Epoch 0/10] [Batch 220/350] [D loss: 0.252629, acc:  48%] [G loss: 1.495181] time: 0:23:36.962482\n",
      "[Epoch 0/10] [Batch 221/350] [D loss: 0.251860, acc:  46%] [G loss: 1.072767] time: 0:23:43.282614\n",
      "[Epoch 0/10] [Batch 222/350] [D loss: 0.251549, acc:  51%] [G loss: 1.156115] time: 0:23:49.560796\n",
      "[Epoch 0/10] [Batch 223/350] [D loss: 0.252021, acc:  50%] [G loss: 1.360921] time: 0:23:55.862947\n",
      "[Epoch 0/10] [Batch 224/350] [D loss: 0.251748, acc:  48%] [G loss: 1.360172] time: 0:24:02.152162\n",
      "[Epoch 0/10] [Batch 225/350] [D loss: 0.251244, acc:  48%] [G loss: 1.243749] time: 0:24:08.447329\n",
      "[Epoch 0/10] [Batch 226/350] [D loss: 0.251438, acc:  48%] [G loss: 1.285158] time: 0:24:14.748450\n",
      "[Epoch 0/10] [Batch 227/350] [D loss: 0.251533, acc:  47%] [G loss: 1.313260] time: 0:24:21.053623\n",
      "[Epoch 0/10] [Batch 228/350] [D loss: 0.251729, acc:  49%] [G loss: 1.197263] time: 0:24:27.320865\n",
      "[Epoch 0/10] [Batch 229/350] [D loss: 0.251483, acc:  46%] [G loss: 1.208677] time: 0:24:33.668895\n",
      "[Epoch 0/10] [Batch 230/350] [D loss: 0.251620, acc:  50%] [G loss: 1.258736] time: 0:24:39.957047\n",
      "[Epoch 0/10] [Batch 231/350] [D loss: 0.251770, acc:  45%] [G loss: 1.429738] time: 0:24:46.211325\n",
      "[Epoch 0/10] [Batch 232/350] [D loss: 0.251854, acc:  54%] [G loss: 1.170753] time: 0:24:52.490566\n",
      "[Epoch 0/10] [Batch 233/350] [D loss: 0.251878, acc:  47%] [G loss: 1.162789] time: 0:24:58.766754\n",
      "[Epoch 0/10] [Batch 234/350] [D loss: 0.251709, acc:  49%] [G loss: 1.297922] time: 0:25:05.068903\n",
      "[Epoch 0/10] [Batch 235/350] [D loss: 0.251657, acc:  48%] [G loss: 1.251440] time: 0:25:11.359084\n",
      "[Epoch 0/10] [Batch 236/350] [D loss: 0.251788, acc:  45%] [G loss: 1.149917] time: 0:25:17.660269\n",
      "[Epoch 0/10] [Batch 237/350] [D loss: 0.251898, acc:  48%] [G loss: 1.272895] time: 0:25:23.980338\n",
      "[Epoch 0/10] [Batch 238/350] [D loss: 0.251556, acc:  49%] [G loss: 1.222490] time: 0:25:30.273543\n",
      "[Epoch 0/10] [Batch 239/350] [D loss: 0.251361, acc:  47%] [G loss: 1.192015] time: 0:25:36.574695\n",
      "[Epoch 0/10] [Batch 240/350] [D loss: 0.251601, acc:  47%] [G loss: 1.301418] time: 0:25:42.901746\n",
      "[Epoch 0/10] [Batch 241/350] [D loss: 0.251601, acc:  47%] [G loss: 1.265092] time: 0:25:49.303629\n",
      "[Epoch 0/10] [Batch 242/350] [D loss: 0.251520, acc:  48%] [G loss: 1.168400] time: 0:25:55.572897\n",
      "[Epoch 0/10] [Batch 243/350] [D loss: 0.252215, acc:  42%] [G loss: 1.496006] time: 0:26:01.893965\n",
      "[Epoch 0/10] [Batch 244/350] [D loss: 0.251821, acc:  48%] [G loss: 1.145294] time: 0:26:08.217090\n",
      "[Epoch 0/10] [Batch 245/350] [D loss: 0.251480, acc:  49%] [G loss: 1.388078] time: 0:26:14.526188\n",
      "[Epoch 0/10] [Batch 246/350] [D loss: 0.251607, acc:  51%] [G loss: 1.282739] time: 0:26:20.826343\n",
      "[Epoch 0/10] [Batch 247/350] [D loss: 0.251660, acc:  47%] [G loss: 1.163237] time: 0:26:27.124503\n",
      "[Epoch 0/10] [Batch 248/350] [D loss: 0.251535, acc:  50%] [G loss: 1.396494] time: 0:26:33.395735\n",
      "[Epoch 0/10] [Batch 249/350] [D loss: 0.251673, acc:  50%] [G loss: 1.522348] time: 0:26:39.691901\n",
      "[Epoch 0/10] [Batch 250/350] [D loss: 0.251632, acc:  47%] [G loss: 1.371068] time: 0:26:45.992055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 251/350] [D loss: 0.251599, acc:  53%] [G loss: 1.163249] time: 0:26:52.283234\n",
      "[Epoch 0/10] [Batch 252/350] [D loss: 0.251892, acc:  48%] [G loss: 1.111408] time: 0:26:58.585383\n",
      "[Epoch 0/10] [Batch 253/350] [D loss: 0.251546, acc:  51%] [G loss: 1.392333] time: 0:27:04.890556\n",
      "[Epoch 0/10] [Batch 254/350] [D loss: 0.251568, acc:  47%] [G loss: 1.203114] time: 0:27:11.199655\n",
      "[Epoch 0/10] [Batch 255/350] [D loss: 0.251503, acc:  47%] [G loss: 1.240811] time: 0:27:17.565665\n",
      "[Epoch 0/10] [Batch 256/350] [D loss: 0.251796, acc:  42%] [G loss: 1.112741] time: 0:27:23.889756\n",
      "[Epoch 0/10] [Batch 257/350] [D loss: 0.251649, acc:  47%] [G loss: 1.273514] time: 0:27:30.203842\n",
      "[Epoch 0/10] [Batch 258/350] [D loss: 0.251356, acc:  45%] [G loss: 1.315136] time: 0:27:36.493026\n",
      "[Epoch 0/10] [Batch 259/350] [D loss: 0.251243, acc:  47%] [G loss: 1.023920] time: 0:27:42.837063\n",
      "[Epoch 0/10] [Batch 260/350] [D loss: 0.251273, acc:  49%] [G loss: 1.192757] time: 0:27:49.137218\n",
      "[Epoch 0/10] [Batch 261/350] [D loss: 0.251451, acc:  49%] [G loss: 1.111913] time: 0:27:55.438370\n",
      "[Epoch 0/10] [Batch 262/350] [D loss: 0.251426, acc:  47%] [G loss: 1.486451] time: 0:28:01.736551\n",
      "[Epoch 0/10] [Batch 263/350] [D loss: 0.251441, acc:  47%] [G loss: 1.234638] time: 0:28:08.031698\n",
      "[Epoch 0/10] [Batch 264/350] [D loss: 0.251449, acc:  47%] [G loss: 1.211640] time: 0:28:14.332850\n",
      "[Epoch 0/10] [Batch 265/350] [D loss: 0.251737, acc:  46%] [G loss: 1.086035] time: 0:28:20.636994\n",
      "[Epoch 0/10] [Batch 266/350] [D loss: 0.251894, acc:  50%] [G loss: 1.145516] time: 0:28:26.940172\n",
      "[Epoch 0/10] [Batch 267/350] [D loss: 0.251639, acc:  50%] [G loss: 1.114016] time: 0:28:33.252293\n",
      "[Epoch 0/10] [Batch 268/350] [D loss: 0.251897, acc:  51%] [G loss: 1.260300] time: 0:28:39.520503\n",
      "[Epoch 0/10] [Batch 269/350] [D loss: 0.251897, acc:  47%] [G loss: 1.267567] time: 0:28:45.813683\n",
      "[Epoch 0/10] [Batch 270/350] [D loss: 0.251688, acc:  40%] [G loss: 1.318818] time: 0:28:52.094883\n",
      "[Epoch 0/10] [Batch 271/350] [D loss: 0.251670, acc:  48%] [G loss: 1.086582] time: 0:28:58.397031\n",
      "[Epoch 0/10] [Batch 272/350] [D loss: 0.251683, acc:  49%] [G loss: 1.282688] time: 0:29:04.701207\n",
      "[Epoch 0/10] [Batch 273/350] [D loss: 0.251404, acc:  47%] [G loss: 1.407139] time: 0:29:10.998365\n",
      "[Epoch 0/10] [Batch 274/350] [D loss: 0.251341, acc:  49%] [G loss: 1.378339] time: 0:29:17.306502\n",
      "[Epoch 0/10] [Batch 275/350] [D loss: 0.251748, acc:  49%] [G loss: 1.263434] time: 0:29:23.621586\n",
      "[Epoch 0/10] [Batch 276/350] [D loss: 0.251733, acc:  53%] [G loss: 1.122219] time: 0:29:29.908775\n",
      "[Epoch 0/10] [Batch 277/350] [D loss: 0.251902, acc:  47%] [G loss: 1.102854] time: 0:29:36.217905\n",
      "[Epoch 0/10] [Batch 278/350] [D loss: 0.251520, acc:  47%] [G loss: 1.190692] time: 0:29:42.564966\n",
      "[Epoch 0/10] [Batch 279/350] [D loss: 0.251533, acc:  47%] [G loss: 1.234945] time: 0:29:48.869110\n",
      "[Epoch 0/10] [Batch 280/350] [D loss: 0.251379, acc:  48%] [G loss: 1.198558] time: 0:29:55.165276\n",
      "[Epoch 0/10] [Batch 281/350] [D loss: 0.251458, acc:  48%] [G loss: 1.170141] time: 0:30:01.466428\n",
      "[Epoch 0/10] [Batch 282/350] [D loss: 0.251767, acc:  51%] [G loss: 1.275452] time: 0:30:07.747602\n",
      "[Epoch 0/10] [Batch 283/350] [D loss: 0.251831, acc:  46%] [G loss: 1.116338] time: 0:30:14.033827\n",
      "[Epoch 0/10] [Batch 284/350] [D loss: 0.251848, acc:  49%] [G loss: 1.191125] time: 0:30:20.348940\n",
      "[Epoch 0/10] [Batch 285/350] [D loss: 0.251575, acc:  46%] [G loss: 1.130131] time: 0:30:26.651090\n",
      "[Epoch 0/10] [Batch 286/350] [D loss: 0.251444, acc:  47%] [G loss: 1.130422] time: 0:30:32.939244\n",
      "[Epoch 0/10] [Batch 287/350] [D loss: 0.251273, acc:  47%] [G loss: 1.187423] time: 0:30:39.254359\n",
      "[Epoch 0/10] [Batch 288/350] [D loss: 0.251540, acc:  46%] [G loss: 1.271977] time: 0:30:45.575489\n",
      "[Epoch 0/10] [Batch 289/350] [D loss: 0.251583, acc:  52%] [G loss: 1.428999] time: 0:30:51.838711\n",
      "[Epoch 0/10] [Batch 290/350] [D loss: 0.251574, acc:  48%] [G loss: 1.086887] time: 0:30:58.155853\n",
      "[Epoch 0/10] [Batch 291/350] [D loss: 0.251754, acc:  44%] [G loss: 1.350555] time: 0:31:04.477918\n",
      "[Epoch 0/10] [Batch 292/350] [D loss: 0.251590, acc:  50%] [G loss: 1.132933] time: 0:31:10.778103\n",
      "[Epoch 0/10] [Batch 293/350] [D loss: 0.251527, acc:  49%] [G loss: 1.525136] time: 0:31:17.086205\n",
      "[Epoch 0/10] [Batch 294/350] [D loss: 0.251579, acc:  52%] [G loss: 1.248671] time: 0:31:23.395335\n",
      "[Epoch 0/10] [Batch 295/350] [D loss: 0.251787, acc:  49%] [G loss: 1.194131] time: 0:31:29.666567\n",
      "[Epoch 0/10] [Batch 296/350] [D loss: 0.251510, acc:  45%] [G loss: 1.293794] time: 0:31:35.972706\n",
      "[Epoch 0/10] [Batch 297/350] [D loss: 0.251372, acc:  50%] [G loss: 1.228172] time: 0:31:42.297794\n",
      "[Epoch 0/10] [Batch 298/350] [D loss: 0.251500, acc:  50%] [G loss: 1.253970] time: 0:31:48.590967\n",
      "[Epoch 0/10] [Batch 299/350] [D loss: 0.251523, acc:  49%] [G loss: 1.473686] time: 0:31:54.882146\n",
      "[Epoch 0/10] [Batch 300/350] [D loss: 0.251946, acc:  48%] [G loss: 1.454174] time: 0:32:01.172327\n",
      "[Epoch 0/10] [Batch 301/350] [D loss: 0.252311, acc:  49%] [G loss: 1.380207] time: 0:32:07.450573\n",
      "[Epoch 0/10] [Batch 302/350] [D loss: 0.252066, acc:  49%] [G loss: 1.122292] time: 0:32:13.755683\n",
      "[Epoch 0/10] [Batch 303/350] [D loss: 0.251689, acc:  51%] [G loss: 1.183584] time: 0:32:20.100716\n",
      "[Epoch 0/10] [Batch 304/350] [D loss: 0.252218, acc:  48%] [G loss: 1.031707] time: 0:32:26.408850\n",
      "[Epoch 0/10] [Batch 305/350] [D loss: 0.252144, acc:  50%] [G loss: 1.164254] time: 0:32:32.694076\n",
      "[Epoch 0/10] [Batch 306/350] [D loss: 0.251437, acc:  50%] [G loss: 1.174388] time: 0:32:38.991207\n",
      "[Epoch 0/10] [Batch 307/350] [D loss: 0.251513, acc:  48%] [G loss: 1.314448] time: 0:32:45.295351\n",
      "[Epoch 0/10] [Batch 308/350] [D loss: 0.251401, acc:  46%] [G loss: 1.235924] time: 0:32:51.596535\n",
      "[Epoch 0/10] [Batch 309/350] [D loss: 0.251430, acc:  47%] [G loss: 1.231482] time: 0:32:57.898653\n",
      "[Epoch 0/10] [Batch 310/350] [D loss: 0.251484, acc:  47%] [G loss: 1.246423] time: 0:33:04.211804\n",
      "[Epoch 0/10] [Batch 311/350] [D loss: 0.251289, acc:  47%] [G loss: 1.305303] time: 0:33:10.519906\n",
      "[Epoch 0/10] [Batch 312/350] [D loss: 0.252357, acc:  50%] [G loss: 1.176694] time: 0:33:16.783159\n",
      "[Epoch 0/10] [Batch 313/350] [D loss: 0.252221, acc:  49%] [G loss: 1.032250] time: 0:33:23.119217\n",
      "[Epoch 0/10] [Batch 314/350] [D loss: 0.252475, acc:  47%] [G loss: 1.317765] time: 0:33:29.428348\n",
      "[Epoch 0/10] [Batch 315/350] [D loss: 0.252032, acc:  44%] [G loss: 1.250860] time: 0:33:35.733490\n",
      "[Epoch 0/10] [Batch 316/350] [D loss: 0.252024, acc:  52%] [G loss: 1.331632] time: 0:33:42.060572\n",
      "[Epoch 0/10] [Batch 317/350] [D loss: 0.252826, acc:  51%] [G loss: 1.262440] time: 0:33:48.360727\n",
      "[Epoch 0/10] [Batch 318/350] [D loss: 0.252330, acc:  45%] [G loss: 1.286630] time: 0:33:54.645925\n",
      "[Epoch 0/10] [Batch 319/350] [D loss: 0.251537, acc:  50%] [G loss: 1.176005] time: 0:34:00.927158\n",
      "[Epoch 0/10] [Batch 320/350] [D loss: 0.251796, acc:  49%] [G loss: 1.196552] time: 0:34:07.232268\n",
      "[Epoch 0/10] [Batch 321/350] [D loss: 0.252023, acc:  48%] [G loss: 1.236413] time: 0:34:13.536443\n",
      "[Epoch 0/10] [Batch 322/350] [D loss: 0.251591, acc:  47%] [G loss: 1.400357] time: 0:34:19.843580\n",
      "[Epoch 0/10] [Batch 323/350] [D loss: 0.251572, acc:  51%] [G loss: 1.230779] time: 0:34:26.169634\n",
      "[Epoch 0/10] [Batch 324/350] [D loss: 0.251518, acc:  49%] [G loss: 1.185670] time: 0:34:32.488769\n",
      "[Epoch 0/10] [Batch 325/350] [D loss: 0.251386, acc:  46%] [G loss: 1.327575] time: 0:34:38.773964\n",
      "[Epoch 0/10] [Batch 326/350] [D loss: 0.251888, acc:  51%] [G loss: 1.189255] time: 0:34:45.038215\n",
      "[Epoch 0/10] [Batch 327/350] [D loss: 0.251727, acc:  45%] [G loss: 1.176815] time: 0:34:51.337372\n",
      "[Epoch 0/10] [Batch 328/350] [D loss: 0.251679, acc:  46%] [G loss: 1.141655] time: 0:34:57.635532\n",
      "[Epoch 0/10] [Batch 329/350] [D loss: 0.251427, acc:  48%] [G loss: 1.240993] time: 0:35:03.923687\n",
      "[Epoch 0/10] [Batch 330/350] [D loss: 0.251505, acc:  48%] [G loss: 1.257242] time: 0:35:10.204892\n",
      "[Epoch 0/10] [Batch 331/350] [D loss: 0.251542, acc:  47%] [G loss: 1.428636] time: 0:35:16.508071\n",
      "[Epoch 0/10] [Batch 332/350] [D loss: 0.251793, acc:  46%] [G loss: 1.318853] time: 0:35:22.784258\n",
      "[Epoch 0/10] [Batch 333/350] [D loss: 0.251717, acc:  46%] [G loss: 1.089953] time: 0:35:29.094417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 334/350] [D loss: 0.251547, acc:  46%] [G loss: 1.135541] time: 0:35:35.387559\n",
      "[Epoch 0/10] [Batch 335/350] [D loss: 0.251757, acc:  44%] [G loss: 1.285571] time: 0:35:41.714642\n",
      "[Epoch 0/10] [Batch 336/350] [D loss: 0.251759, acc:  50%] [G loss: 1.254876] time: 0:35:48.025767\n",
      "[Epoch 0/10] [Batch 337/350] [D loss: 0.251453, acc:  51%] [G loss: 1.174063] time: 0:35:54.311959\n",
      "[Epoch 0/10] [Batch 338/350] [D loss: 0.251442, acc:  48%] [G loss: 1.334368] time: 0:36:00.607159\n",
      "[Epoch 0/10] [Batch 339/350] [D loss: 0.251203, acc:  46%] [G loss: 1.116696] time: 0:36:06.904290\n",
      "[Epoch 0/10] [Batch 340/350] [D loss: 0.251740, acc:  41%] [G loss: 1.060272] time: 0:36:13.202481\n",
      "[Epoch 0/10] [Batch 341/350] [D loss: 0.251793, acc:  48%] [G loss: 1.109616] time: 0:36:19.474711\n",
      "[Epoch 0/10] [Batch 342/350] [D loss: 0.251696, acc:  42%] [G loss: 1.486851] time: 0:36:25.760871\n",
      "[Epoch 0/10] [Batch 343/350] [D loss: 0.251787, acc:  45%] [G loss: 1.201709] time: 0:36:32.067041\n",
      "[Epoch 0/10] [Batch 344/350] [D loss: 0.252200, acc:  47%] [G loss: 1.362062] time: 0:36:38.348215\n",
      "[Epoch 0/10] [Batch 345/350] [D loss: 0.251924, acc:  50%] [G loss: 1.145266] time: 0:36:44.643415\n",
      "[Epoch 0/10] [Batch 346/350] [D loss: 0.251771, acc:  48%] [G loss: 1.162810] time: 0:36:50.939579\n",
      "[Epoch 0/10] [Batch 347/350] [D loss: 0.252078, acc:  52%] [G loss: 1.173220] time: 0:36:57.214770\n",
      "[Epoch 0/10] [Batch 348/350] [D loss: 0.251894, acc:  49%] [G loss: 1.118788] time: 0:37:03.503954\n",
      "weights saved...\n",
      "[Epoch 1/10] [Batch 0/350] [D loss: 0.251376, acc:  48%] [G loss: 1.153749] time: 0:37:10.839411\n",
      "[Epoch 1/10] [Batch 1/350] [D loss: 0.251302, acc:  47%] [G loss: 1.123433] time: 0:37:22.717651\n",
      "[Epoch 1/10] [Batch 2/350] [D loss: 0.251508, acc:  47%] [G loss: 1.269597] time: 0:37:29.013816\n",
      "[Epoch 1/10] [Batch 3/350] [D loss: 0.251810, acc:  52%] [G loss: 1.456188] time: 0:37:35.298045\n",
      "[Epoch 1/10] [Batch 4/350] [D loss: 0.251721, acc:  48%] [G loss: 1.327204] time: 0:37:41.613128\n",
      "[Epoch 1/10] [Batch 5/350] [D loss: 0.251483, acc:  50%] [G loss: 1.328667] time: 0:37:47.900352\n",
      "[Epoch 1/10] [Batch 6/350] [D loss: 0.251718, acc:  43%] [G loss: 1.309380] time: 0:37:54.204496\n",
      "[Epoch 1/10] [Batch 7/350] [D loss: 0.251609, acc:  47%] [G loss: 1.311422] time: 0:38:00.475725\n",
      "[Epoch 1/10] [Batch 8/350] [D loss: 0.251760, acc:  44%] [G loss: 1.113104] time: 0:38:06.787847\n",
      "[Epoch 1/10] [Batch 9/350] [D loss: 0.251865, acc:  48%] [G loss: 1.203730] time: 0:38:13.048077\n",
      "[Epoch 1/10] [Batch 10/350] [D loss: 0.251699, acc:  41%] [G loss: 1.302787] time: 0:38:19.322302\n",
      "[Epoch 1/10] [Batch 11/350] [D loss: 0.251972, acc:  50%] [G loss: 1.469289] time: 0:38:25.611486\n",
      "[Epoch 1/10] [Batch 12/350] [D loss: 0.252325, acc:  51%] [G loss: 1.215810] time: 0:38:31.907651\n",
      "[Epoch 1/10] [Batch 13/350] [D loss: 0.252126, acc:  46%] [G loss: 1.117820] time: 0:38:38.189854\n",
      "[Epoch 1/10] [Batch 14/350] [D loss: 0.251413, acc:  45%] [G loss: 1.149385] time: 0:38:44.474051\n",
      "[Epoch 1/10] [Batch 15/350] [D loss: 0.251413, acc:  48%] [G loss: 1.127076] time: 0:38:50.750270\n",
      "[Epoch 1/10] [Batch 16/350] [D loss: 0.251489, acc:  47%] [G loss: 1.108776] time: 0:38:57.037459\n",
      "[Epoch 1/10] [Batch 17/350] [D loss: 0.251571, acc:  51%] [G loss: 1.532990] time: 0:39:03.297752\n",
      "[Epoch 1/10] [Batch 18/350] [D loss: 0.251527, acc:  47%] [G loss: 1.281833] time: 0:39:09.579954\n",
      "[Epoch 1/10] [Batch 19/350] [D loss: 0.251534, acc:  46%] [G loss: 1.234775] time: 0:39:15.861128\n",
      "[Epoch 1/10] [Batch 20/350] [D loss: 0.251588, acc:  44%] [G loss: 1.404046] time: 0:39:22.158291\n",
      "[Epoch 1/10] [Batch 21/350] [D loss: 0.251649, acc:  49%] [G loss: 1.254864] time: 0:39:28.443517\n",
      "[Epoch 1/10] [Batch 22/350] [D loss: 0.251457, acc:  47%] [G loss: 1.133098] time: 0:39:34.734697\n",
      "[Epoch 1/10] [Batch 23/350] [D loss: 0.251218, acc:  47%] [G loss: 1.383368] time: 0:39:41.049810\n",
      "[Epoch 1/10] [Batch 24/350] [D loss: 0.251521, acc:  48%] [G loss: 1.122641] time: 0:39:47.326029\n",
      "[Epoch 1/10] [Batch 25/350] [D loss: 0.251414, acc:  45%] [G loss: 1.125804] time: 0:39:53.624158\n",
      "[Epoch 1/10] [Batch 26/350] [D loss: 0.251401, acc:  48%] [G loss: 1.186963] time: 0:39:59.897384\n",
      "[Epoch 1/10] [Batch 27/350] [D loss: 0.251421, acc:  45%] [G loss: 1.237835] time: 0:40:06.173603\n",
      "[Epoch 1/10] [Batch 28/350] [D loss: 0.251615, acc:  42%] [G loss: 1.134387] time: 0:40:12.464782\n",
      "[Epoch 1/10] [Batch 29/350] [D loss: 0.251546, acc:  46%] [G loss: 1.191416] time: 0:40:18.741000\n",
      "[Epoch 1/10] [Batch 30/350] [D loss: 0.251444, acc:  49%] [G loss: 1.146752] time: 0:40:25.029218\n",
      "[Epoch 1/10] [Batch 31/350] [D loss: 0.251348, acc:  47%] [G loss: 1.223806] time: 0:40:31.315379\n",
      "[Epoch 1/10] [Batch 32/350] [D loss: 0.251391, acc:  45%] [G loss: 1.177024] time: 0:40:37.625507\n",
      "[Epoch 1/10] [Batch 33/350] [D loss: 0.251422, acc:  47%] [G loss: 1.224842] time: 0:40:43.906712\n",
      "[Epoch 1/10] [Batch 34/350] [D loss: 0.251636, acc:  52%] [G loss: 1.182192] time: 0:40:50.184926\n",
      "[Epoch 1/10] [Batch 35/350] [D loss: 0.251568, acc:  50%] [G loss: 1.070679] time: 0:40:56.465133\n",
      "[Epoch 1/10] [Batch 36/350] [D loss: 0.251385, acc:  50%] [G loss: 1.049537] time: 0:41:02.751325\n",
      "[Epoch 1/10] [Batch 37/350] [D loss: 0.251449, acc:  49%] [G loss: 1.333739] time: 0:41:09.024552\n",
      "[Epoch 1/10] [Batch 38/350] [D loss: 0.251689, acc:  48%] [G loss: 1.352098] time: 0:41:15.308749\n",
      "[Epoch 1/10] [Batch 39/350] [D loss: 0.251497, acc:  48%] [G loss: 1.163368] time: 0:41:21.578984\n",
      "[Epoch 1/10] [Batch 40/350] [D loss: 0.251521, acc:  47%] [G loss: 1.316506] time: 0:41:27.874184\n",
      "[Epoch 1/10] [Batch 41/350] [D loss: 0.252045, acc:  46%] [G loss: 1.281026] time: 0:41:34.171346\n",
      "[Epoch 1/10] [Batch 42/350] [D loss: 0.251687, acc:  50%] [G loss: 1.065903] time: 0:41:40.467512\n",
      "[Epoch 1/10] [Batch 43/350] [D loss: 0.251871, acc:  49%] [G loss: 1.264249] time: 0:41:46.757662\n",
      "[Epoch 1/10] [Batch 44/350] [D loss: 0.251496, acc:  47%] [G loss: 1.245538] time: 0:41:53.039896\n",
      "[Epoch 1/10] [Batch 45/350] [D loss: 0.251748, acc:  48%] [G loss: 1.215323] time: 0:41:59.323096\n",
      "[Epoch 1/10] [Batch 46/350] [D loss: 0.251274, acc:  48%] [G loss: 1.092620] time: 0:42:05.618232\n",
      "[Epoch 1/10] [Batch 47/350] [D loss: 0.251314, acc:  47%] [G loss: 1.206186] time: 0:42:11.895448\n",
      "[Epoch 1/10] [Batch 48/350] [D loss: 0.251392, acc:  46%] [G loss: 1.298064] time: 0:42:18.247495\n",
      "[Epoch 1/10] [Batch 49/350] [D loss: 0.251395, acc:  49%] [G loss: 1.059723] time: 0:42:24.558589\n",
      "[Epoch 1/10] [Batch 50/350] [D loss: 0.251388, acc:  48%] [G loss: 1.088778] time: 0:42:30.852760\n",
      "[Epoch 1/10] [Batch 51/350] [D loss: 0.251667, acc:  45%] [G loss: 1.070559] time: 0:42:37.150951\n",
      "[Epoch 1/10] [Batch 52/350] [D loss: 0.251703, acc:  48%] [G loss: 1.065485] time: 0:42:43.457095\n",
      "[Epoch 1/10] [Batch 53/350] [D loss: 0.251816, acc:  51%] [G loss: 1.051615] time: 0:42:49.768184\n",
      "[Epoch 1/10] [Batch 54/350] [D loss: 0.251501, acc:  52%] [G loss: 1.233891] time: 0:42:56.043406\n",
      "[Epoch 1/10] [Batch 55/350] [D loss: 0.251503, acc:  49%] [G loss: 1.187433] time: 0:43:02.334584\n",
      "[Epoch 1/10] [Batch 56/350] [D loss: 0.251273, acc:  50%] [G loss: 1.407088] time: 0:43:08.612798\n",
      "[Epoch 1/10] [Batch 57/350] [D loss: 0.251487, acc:  54%] [G loss: 1.275870] time: 0:43:14.867106\n",
      "[Epoch 1/10] [Batch 58/350] [D loss: 0.251551, acc:  52%] [G loss: 1.318786] time: 0:43:21.174211\n",
      "[Epoch 1/10] [Batch 59/350] [D loss: 0.251563, acc:  52%] [G loss: 1.285385] time: 0:43:27.452424\n",
      "[Epoch 1/10] [Batch 60/350] [D loss: 0.251759, acc:  51%] [G loss: 1.288119] time: 0:43:33.745629\n",
      "[Epoch 1/10] [Batch 61/350] [D loss: 0.251801, acc:  47%] [G loss: 1.457056] time: 0:43:40.050739\n",
      "[Epoch 1/10] [Batch 62/350] [D loss: 0.251639, acc:  43%] [G loss: 1.250365] time: 0:43:46.339923\n",
      "[Epoch 1/10] [Batch 63/350] [D loss: 0.251592, acc:  47%] [G loss: 1.327000] time: 0:43:52.612152\n",
      "[Epoch 1/10] [Batch 64/350] [D loss: 0.251528, acc:  47%] [G loss: 1.415555] time: 0:43:58.881422\n",
      "[Epoch 1/10] [Batch 65/350] [D loss: 0.251841, acc:  45%] [G loss: 1.229037] time: 0:44:05.212462\n",
      "[Epoch 1/10] [Batch 66/350] [D loss: 0.251581, acc:  50%] [G loss: 1.219224] time: 0:44:11.493667\n",
      "[Epoch 1/10] [Batch 67/350] [D loss: 0.251644, acc:  49%] [G loss: 1.536783] time: 0:44:17.771880\n",
      "[Epoch 1/10] [Batch 68/350] [D loss: 0.251986, acc:  47%] [G loss: 1.196471] time: 0:44:24.098995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] [Batch 69/350] [D loss: 0.252044, acc:  46%] [G loss: 1.465897] time: 0:44:30.376179\n",
      "[Epoch 1/10] [Batch 70/350] [D loss: 0.252219, acc:  48%] [G loss: 1.408496] time: 0:44:36.655422\n",
      "[Epoch 1/10] [Batch 71/350] [D loss: 0.251805, acc:  47%] [G loss: 1.350888] time: 0:44:42.929645\n",
      "[Epoch 1/10] [Batch 72/350] [D loss: 0.251997, acc:  51%] [G loss: 1.367497] time: 0:44:49.206829\n",
      "[Epoch 1/10] [Batch 73/350] [D loss: 0.251935, acc:  49%] [G loss: 1.378587] time: 0:44:55.476067\n",
      "[Epoch 1/10] [Batch 74/350] [D loss: 0.252084, acc:  48%] [G loss: 2.102610] time: 0:45:01.758269\n",
      "[Epoch 1/10] [Batch 75/350] [D loss: 0.252747, acc:  49%] [G loss: 1.380114] time: 0:45:08.035486\n",
      "[Epoch 1/10] [Batch 76/350] [D loss: 0.252633, acc:  48%] [G loss: 1.856189] time: 0:45:14.317719\n",
      "[Epoch 1/10] [Batch 77/350] [D loss: 0.251815, acc:  51%] [G loss: 1.334336] time: 0:45:20.611859\n",
      "[Epoch 1/10] [Batch 78/350] [D loss: 0.252068, acc:  53%] [G loss: 1.343354] time: 0:45:26.887111\n",
      "[Epoch 1/10] [Batch 79/350] [D loss: 0.251877, acc:  48%] [G loss: 1.514939] time: 0:45:33.185240\n",
      "[Epoch 1/10] [Batch 80/350] [D loss: 0.251863, acc:  50%] [G loss: 1.459215] time: 0:45:39.501352\n",
      "[Epoch 1/10] [Batch 81/350] [D loss: 0.252667, acc:  53%] [G loss: 1.489911] time: 0:45:45.797517\n",
      "[Epoch 1/10] [Batch 82/350] [D loss: 0.252703, acc:  50%] [G loss: 1.180294] time: 0:45:52.088696\n",
      "[Epoch 1/10] [Batch 83/350] [D loss: 0.252244, acc:  50%] [G loss: 1.435240] time: 0:45:58.376883\n",
      "[Epoch 1/10] [Batch 84/350] [D loss: 0.252416, acc:  47%] [G loss: 1.592314] time: 0:46:04.648146\n",
      "[Epoch 1/10] [Batch 85/350] [D loss: 0.252055, acc:  46%] [G loss: 1.505316] time: 0:46:10.917352\n",
      "[Epoch 1/10] [Batch 86/350] [D loss: 0.251884, acc:  49%] [G loss: 1.245597] time: 0:46:17.204574\n",
      "[Epoch 1/10] [Batch 87/350] [D loss: 0.252475, acc:  52%] [G loss: 1.596138] time: 0:46:23.501705\n",
      "[Epoch 1/10] [Batch 88/350] [D loss: 0.252231, acc:  50%] [G loss: 1.192497] time: 0:46:29.791917\n",
      "[Epoch 1/10] [Batch 89/350] [D loss: 0.251524, acc:  52%] [G loss: 1.341333] time: 0:46:36.096064\n",
      "[Epoch 1/10] [Batch 90/350] [D loss: 0.251482, acc:  50%] [G loss: 1.238446] time: 0:46:42.380227\n",
      "[Epoch 1/10] [Batch 91/350] [D loss: 0.251452, acc:  47%] [G loss: 1.142802] time: 0:46:48.655479\n",
      "[Epoch 1/10] [Batch 92/350] [D loss: 0.251605, acc:  47%] [G loss: 1.211993] time: 0:46:54.948653\n",
      "[Epoch 1/10] [Batch 93/350] [D loss: 0.251365, acc:  48%] [G loss: 1.268181] time: 0:47:01.216862\n",
      "[Epoch 1/10] [Batch 94/350] [D loss: 0.251398, acc:  48%] [G loss: 1.348962] time: 0:47:07.496103\n",
      "[Epoch 1/10] [Batch 95/350] [D loss: 0.251341, acc:  47%] [G loss: 1.333597] time: 0:47:13.787283\n",
      "[Epoch 1/10] [Batch 96/350] [D loss: 0.251379, acc:  51%] [G loss: 1.230846] time: 0:47:20.062472\n",
      "[Epoch 1/10] [Batch 97/350] [D loss: 0.251418, acc:  49%] [G loss: 1.584663] time: 0:47:26.347700\n",
      "[Epoch 1/10] [Batch 98/350] [D loss: 0.251484, acc:  48%] [G loss: 1.310552] time: 0:47:32.612947\n",
      "[Epoch 1/10] [Batch 99/350] [D loss: 0.251298, acc:  45%] [G loss: 1.340428] time: 0:47:38.906088\n",
      "[Epoch 1/10] [Batch 100/350] [D loss: 0.251408, acc:  51%] [G loss: 1.384551] time: 0:47:45.207241\n",
      "[Epoch 1/10] [Batch 101/350] [D loss: 0.251637, acc:  50%] [G loss: 1.207631] time: 0:47:51.511418\n",
      "[Epoch 1/10] [Batch 102/350] [D loss: 0.252422, acc:  55%] [G loss: 1.463722] time: 0:47:57.773672\n",
      "[Epoch 1/10] [Batch 103/350] [D loss: 0.252743, acc:  49%] [G loss: 1.413047] time: 0:48:04.066814\n",
      "[Epoch 1/10] [Batch 104/350] [D loss: 0.252105, acc:  52%] [G loss: 1.321819] time: 0:48:10.370989\n",
      "[Epoch 1/10] [Batch 105/350] [D loss: 0.251871, acc:  43%] [G loss: 1.329582] time: 0:48:16.673107\n",
      "[Epoch 1/10] [Batch 106/350] [D loss: 0.251919, acc:  50%] [G loss: 1.618742] time: 0:48:22.966280\n",
      "[Epoch 1/10] [Batch 107/350] [D loss: 0.251584, acc:  52%] [G loss: 1.132577] time: 0:48:29.276408\n",
      "[Epoch 1/10] [Batch 108/350] [D loss: 0.251798, acc:  47%] [G loss: 1.323952] time: 0:48:35.582547\n",
      "[Epoch 1/10] [Batch 109/350] [D loss: 0.252812, acc:  52%] [G loss: 1.413799] time: 0:48:41.870765\n",
      "[Epoch 1/10] [Batch 110/350] [D loss: 0.252495, acc:  48%] [G loss: 1.511404] time: 0:48:48.137976\n",
      "[Epoch 1/10] [Batch 111/350] [D loss: 0.252029, acc:  46%] [G loss: 1.411275] time: 0:48:54.401230\n",
      "[Epoch 1/10] [Batch 112/350] [D loss: 0.252904, acc:  50%] [G loss: 1.537090] time: 0:49:00.690414\n",
      "[Epoch 1/10] [Batch 113/350] [D loss: 0.252910, acc:  50%] [G loss: 1.325285] time: 0:49:06.987576\n",
      "[Epoch 1/10] [Batch 114/350] [D loss: 0.251894, acc:  46%] [G loss: 1.335984] time: 0:49:13.265790\n",
      "[Epoch 1/10] [Batch 115/350] [D loss: 0.252400, acc:  46%] [G loss: 1.501767] time: 0:49:19.563981\n",
      "[Epoch 1/10] [Batch 116/350] [D loss: 0.252556, acc:  54%] [G loss: 1.428296] time: 0:49:25.872083\n",
      "[Epoch 1/10] [Batch 117/350] [D loss: 0.251984, acc:  52%] [G loss: 1.266730] time: 0:49:32.153319\n",
      "[Epoch 1/10] [Batch 118/350] [D loss: 0.252878, acc:  49%] [G loss: 1.365197] time: 0:49:38.434494\n",
      "[Epoch 1/10] [Batch 119/350] [D loss: 0.251938, acc:  44%] [G loss: 1.296475] time: 0:49:44.781523\n",
      "[Epoch 1/10] [Batch 120/350] [D loss: 0.251622, acc:  52%] [G loss: 1.293080] time: 0:49:51.065720\n",
      "[Epoch 1/10] [Batch 121/350] [D loss: 0.251721, acc:  50%] [G loss: 1.227497] time: 0:49:57.337950\n",
      "[Epoch 1/10] [Batch 122/350] [D loss: 0.251603, acc:  45%] [G loss: 1.212719] time: 0:50:03.618158\n",
      "[Epoch 1/10] [Batch 123/350] [D loss: 0.251927, acc:  50%] [G loss: 1.157440] time: 0:50:09.897400\n",
      "[Epoch 1/10] [Batch 124/350] [D loss: 0.252323, acc:  50%] [G loss: 1.201748] time: 0:50:16.177576\n",
      "[Epoch 1/10] [Batch 125/350] [D loss: 0.252081, acc:  48%] [G loss: 1.125147] time: 0:50:22.473741\n",
      "[Epoch 1/10] [Batch 126/350] [D loss: 0.251724, acc:  46%] [G loss: 1.331306] time: 0:50:28.749992\n",
      "[Epoch 1/10] [Batch 127/350] [D loss: 0.252104, acc:  53%] [G loss: 1.300549] time: 0:50:35.035155\n",
      "[Epoch 1/10] [Batch 128/350] [D loss: 0.252367, acc:  50%] [G loss: 1.122975] time: 0:50:41.335310\n",
      "[Epoch 1/10] [Batch 129/350] [D loss: 0.251762, acc:  47%] [G loss: 1.279262] time: 0:50:47.633470\n",
      "[Epoch 1/10] [Batch 130/350] [D loss: 0.252133, acc:  48%] [G loss: 1.321610] time: 0:50:53.923651\n",
      "[Epoch 1/10] [Batch 131/350] [D loss: 0.252016, acc:  51%] [G loss: 1.172449] time: 0:51:00.217821\n",
      "[Epoch 1/10] [Batch 132/350] [D loss: 0.251648, acc:  48%] [G loss: 1.155600] time: 0:51:06.496035\n",
      "[Epoch 1/10] [Batch 133/350] [D loss: 0.252390, acc:  48%] [G loss: 1.332009] time: 0:51:12.775245\n",
      "[Epoch 1/10] [Batch 134/350] [D loss: 0.252192, acc:  46%] [G loss: 1.238282] time: 0:51:19.044483\n",
      "[Epoch 1/10] [Batch 135/350] [D loss: 0.251441, acc:  44%] [G loss: 1.387580] time: 0:51:25.316745\n",
      "[Epoch 1/10] [Batch 136/350] [D loss: 0.251277, acc:  46%] [G loss: 1.204860] time: 0:51:31.594926\n",
      "[Epoch 1/10] [Batch 137/350] [D loss: 0.251234, acc:  47%] [G loss: 1.384524] time: 0:51:37.893117\n",
      "[Epoch 1/10] [Batch 138/350] [D loss: 0.251467, acc:  53%] [G loss: 1.466189] time: 0:51:44.202248\n",
      "[Epoch 1/10] [Batch 139/350] [D loss: 0.252006, acc:  53%] [G loss: 1.170684] time: 0:51:50.494392\n",
      "[Epoch 1/10] [Batch 140/350] [D loss: 0.252058, acc:  49%] [G loss: 1.334081] time: 0:51:56.770643\n",
      "[Epoch 1/10] [Batch 141/350] [D loss: 0.251783, acc:  43%] [G loss: 1.215257] time: 0:52:03.030904\n",
      "[Epoch 1/10] [Batch 142/350] [D loss: 0.251796, acc:  49%] [G loss: 1.171362] time: 0:52:09.322083\n",
      "[Epoch 1/10] [Batch 143/350] [D loss: 0.251594, acc:  49%] [G loss: 1.321805] time: 0:52:15.668083\n",
      "[Epoch 1/10] [Batch 144/350] [D loss: 0.251443, acc:  49%] [G loss: 1.337744] time: 0:52:21.950286\n",
      "[Epoch 1/10] [Batch 145/350] [D loss: 0.251688, acc:  48%] [G loss: 1.469028] time: 0:52:28.224510\n",
      "[Epoch 1/10] [Batch 146/350] [D loss: 0.251512, acc:  47%] [G loss: 1.365643] time: 0:52:34.512696\n",
      "[Epoch 1/10] [Batch 147/350] [D loss: 0.251483, acc:  46%] [G loss: 1.302355] time: 0:52:40.797891\n",
      "[Epoch 1/10] [Batch 148/350] [D loss: 0.252053, acc:  42%] [G loss: 1.324313] time: 0:52:47.108019\n",
      "[Epoch 1/10] [Batch 149/350] [D loss: 0.251886, acc:  48%] [G loss: 1.107317] time: 0:52:53.411165\n",
      "[Epoch 1/10] [Batch 150/350] [D loss: 0.251583, acc:  51%] [G loss: 1.286955] time: 0:52:59.705336\n",
      "[Epoch 1/10] [Batch 151/350] [D loss: 0.251300, acc:  47%] [G loss: 1.191694] time: 0:53:06.002531\n",
      "[Epoch 1/10] [Batch 152/350] [D loss: 0.251330, acc:  48%] [G loss: 1.362609] time: 0:53:12.286728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] [Batch 153/350] [D loss: 0.251215, acc:  48%] [G loss: 1.145266] time: 0:53:18.585854\n",
      "[Epoch 1/10] [Batch 154/350] [D loss: 0.251634, acc:  50%] [G loss: 1.247143] time: 0:53:24.910973\n",
      "[Epoch 1/10] [Batch 155/350] [D loss: 0.251762, acc:  46%] [G loss: 1.197300] time: 0:53:31.202153\n",
      "[Epoch 1/10] [Batch 156/350] [D loss: 0.251754, acc:  45%] [G loss: 1.169093] time: 0:53:37.480334\n",
      "[Epoch 1/10] [Batch 157/350] [D loss: 0.251677, acc:  50%] [G loss: 1.219302] time: 0:53:43.805453\n",
      "[Epoch 1/10] [Batch 158/350] [D loss: 0.251599, acc:  50%] [G loss: 1.174357] time: 0:53:50.091645\n",
      "[Epoch 1/10] [Batch 159/350] [D loss: 0.251461, acc:  46%] [G loss: 1.376905] time: 0:53:56.376808\n",
      "[Epoch 1/10] [Batch 160/350] [D loss: 0.251614, acc:  51%] [G loss: 1.201590] time: 0:54:02.658047\n",
      "[Epoch 1/10] [Batch 161/350] [D loss: 0.251723, acc:  48%] [G loss: 1.285845] time: 0:54:08.929245\n",
      "[Epoch 1/10] [Batch 162/350] [D loss: 0.251565, acc:  48%] [G loss: 1.179278] time: 0:54:15.217432\n",
      "[Epoch 1/10] [Batch 163/350] [D loss: 0.252112, acc:  45%] [G loss: 1.216888] time: 0:54:21.513597\n",
      "[Epoch 1/10] [Batch 164/350] [D loss: 0.252047, acc:  48%] [G loss: 1.157951] time: 0:54:27.786824\n",
      "[Epoch 1/10] [Batch 165/350] [D loss: 0.251589, acc:  42%] [G loss: 1.172208] time: 0:54:34.076008\n",
      "[Epoch 1/10] [Batch 166/350] [D loss: 0.251569, acc:  47%] [G loss: 1.251396] time: 0:54:40.353224\n",
      "[Epoch 1/10] [Batch 167/350] [D loss: 0.251566, acc:  49%] [G loss: 1.038844] time: 0:54:46.646429\n",
      "[Epoch 1/10] [Batch 168/350] [D loss: 0.251681, acc:  50%] [G loss: 1.242767] time: 0:54:52.942563\n",
      "[Epoch 1/10] [Batch 169/350] [D loss: 0.252421, acc:  55%] [G loss: 1.017703] time: 0:54:59.185870\n",
      "[Epoch 1/10] [Batch 170/350] [D loss: 0.252725, acc:  49%] [G loss: 1.286214] time: 0:55:05.450120\n",
      "[Epoch 1/10] [Batch 171/350] [D loss: 0.252082, acc:  49%] [G loss: 1.246552] time: 0:55:11.745288\n",
      "[Epoch 1/10] [Batch 172/350] [D loss: 0.252717, acc:  53%] [G loss: 1.201589] time: 0:55:18.009571\n",
      "[Epoch 1/10] [Batch 173/350] [D loss: 0.253784, acc:  49%] [G loss: 1.463334] time: 0:55:24.339614\n",
      "[Epoch 1/10] [Batch 174/350] [D loss: 0.252459, acc:  50%] [G loss: 1.264687] time: 0:55:30.627831\n",
      "[Epoch 1/10] [Batch 175/350] [D loss: 0.252706, acc:  46%] [G loss: 1.425960] time: 0:55:36.923966\n",
      "[Epoch 1/10] [Batch 176/350] [D loss: 0.253923, acc:  49%] [G loss: 1.234398] time: 0:55:48.795280\n",
      "[Epoch 1/10] [Batch 177/350] [D loss: 0.252581, acc:  49%] [G loss: 1.370313] time: 0:55:55.056539\n",
      "[Epoch 1/10] [Batch 178/350] [D loss: 0.251369, acc:  49%] [G loss: 1.279662] time: 0:56:01.326773\n",
      "[Epoch 1/10] [Batch 179/350] [D loss: 0.251580, acc:  48%] [G loss: 1.173107] time: 0:56:07.595013\n",
      "[Epoch 1/10] [Batch 180/350] [D loss: 0.251575, acc:  47%] [G loss: 1.144764] time: 0:56:13.880209\n",
      "[Epoch 1/10] [Batch 181/350] [D loss: 0.251550, acc:  49%] [G loss: 1.241797] time: 0:56:20.159418\n",
      "[Epoch 1/10] [Batch 182/350] [D loss: 0.251517, acc:  47%] [G loss: 1.148363] time: 0:56:26.427659\n",
      "[Epoch 1/10] [Batch 183/350] [D loss: 0.251206, acc:  49%] [G loss: 1.323442] time: 0:56:32.693936\n",
      "[Epoch 1/10] [Batch 184/350] [D loss: 0.251372, acc:  50%] [G loss: 1.288646] time: 0:56:38.949179\n",
      "[Epoch 1/10] [Batch 185/350] [D loss: 0.251520, acc:  49%] [G loss: 1.019414] time: 0:56:45.233376\n",
      "[Epoch 1/10] [Batch 186/350] [D loss: 0.251430, acc:  46%] [G loss: 1.324461] time: 0:56:51.491642\n",
      "[Epoch 1/10] [Batch 187/350] [D loss: 0.251358, acc:  46%] [G loss: 1.286850] time: 0:56:57.765866\n",
      "[Epoch 1/10] [Batch 188/350] [D loss: 0.251556, acc:  48%] [G loss: 1.008872] time: 0:57:04.029120\n",
      "[Epoch 1/10] [Batch 189/350] [D loss: 0.251637, acc:  53%] [G loss: 1.168538] time: 0:57:10.299355\n",
      "[Epoch 1/10] [Batch 190/350] [D loss: 0.251505, acc:  50%] [G loss: 1.447549] time: 0:57:16.590533\n",
      "[Epoch 1/10] [Batch 191/350] [D loss: 0.251743, acc:  46%] [G loss: 1.285347] time: 0:57:22.866783\n",
      "[Epoch 1/10] [Batch 192/350] [D loss: 0.251597, acc:  44%] [G loss: 1.115309] time: 0:57:29.118068\n",
      "[Epoch 1/10] [Batch 193/350] [D loss: 0.251849, acc:  49%] [G loss: 1.246377] time: 0:57:35.383317\n",
      "[Epoch 1/10] [Batch 194/350] [D loss: 0.251806, acc:  49%] [G loss: 1.470597] time: 0:57:41.674464\n",
      "[Epoch 1/10] [Batch 195/350] [D loss: 0.252177, acc:  45%] [G loss: 1.226214] time: 0:57:47.957698\n",
      "[Epoch 1/10] [Batch 196/350] [D loss: 0.252776, acc:  53%] [G loss: 1.235015] time: 0:57:54.202965\n",
      "[Epoch 1/10] [Batch 197/350] [D loss: 0.252316, acc:  51%] [G loss: 1.070593] time: 0:58:00.460235\n",
      "[Epoch 1/10] [Batch 198/350] [D loss: 0.252142, acc:  47%] [G loss: 1.137810] time: 0:58:06.715509\n",
      "[Epoch 1/10] [Batch 199/350] [D loss: 0.252692, acc:  46%] [G loss: 1.160415] time: 0:58:12.975770\n",
      "[Epoch 1/10] [Batch 200/350] [D loss: 0.251934, acc:  44%] [G loss: 1.246136] time: 0:58:19.249995\n",
      "[Epoch 1/10] [Batch 201/350] [D loss: 0.251361, acc:  47%] [G loss: 1.077360] time: 0:58:25.521227\n",
      "[Epoch 1/10] [Batch 202/350] [D loss: 0.251574, acc:  48%] [G loss: 1.235161] time: 0:58:31.767557\n",
      "[Epoch 1/10] [Batch 203/350] [D loss: 0.251416, acc:  46%] [G loss: 1.151167] time: 0:58:38.028784\n",
      "[Epoch 1/10] [Batch 204/350] [D loss: 0.251584, acc:  48%] [G loss: 1.166394] time: 0:58:44.280069\n",
      "[Epoch 1/10] [Batch 205/350] [D loss: 0.251644, acc:  50%] [G loss: 1.141020] time: 0:58:50.538336\n",
      "[Epoch 1/10] [Batch 206/350] [D loss: 0.251519, acc:  49%] [G loss: 1.218941] time: 0:58:56.791616\n",
      "[Epoch 1/10] [Batch 207/350] [D loss: 0.251372, acc:  49%] [G loss: 1.363061] time: 0:59:03.054869\n",
      "[Epoch 1/10] [Batch 208/350] [D loss: 0.251650, acc:  50%] [G loss: 1.148583] time: 0:59:09.315131\n",
      "[Epoch 1/10] [Batch 209/350] [D loss: 0.252033, acc:  49%] [G loss: 1.333924] time: 0:59:15.571403\n",
      "[Epoch 1/10] [Batch 210/350] [D loss: 0.251796, acc:  49%] [G loss: 1.251092] time: 0:59:21.825680\n",
      "[Epoch 1/10] [Batch 211/350] [D loss: 0.251524, acc:  46%] [G loss: 1.067431] time: 0:59:28.082949\n",
      "[Epoch 1/10] [Batch 212/350] [D loss: 0.251647, acc:  47%] [G loss: 1.017606] time: 0:59:34.364155\n",
      "[Epoch 1/10] [Batch 213/350] [D loss: 0.251661, acc:  49%] [G loss: 1.136328] time: 0:59:40.661349\n",
      "[Epoch 1/10] [Batch 214/350] [D loss: 0.251369, acc:  47%] [G loss: 1.138252] time: 0:59:46.944517\n",
      "[Epoch 1/10] [Batch 215/350] [D loss: 0.251240, acc:  48%] [G loss: 1.289220] time: 0:59:53.222762\n",
      "[Epoch 1/10] [Batch 216/350] [D loss: 0.251210, acc:  47%] [G loss: 1.099893] time: 0:59:59.482992\n",
      "[Epoch 1/10] [Batch 217/350] [D loss: 0.251445, acc:  49%] [G loss: 1.027772] time: 1:00:05.738267\n",
      "[Epoch 1/10] [Batch 218/350] [D loss: 0.251396, acc:  49%] [G loss: 1.180925] time: 1:00:12.005509\n",
      "[Epoch 1/10] [Batch 219/350] [D loss: 0.252311, acc:  40%] [G loss: 1.173431] time: 1:00:18.281729\n",
      "[Epoch 1/10] [Batch 220/350] [D loss: 0.252563, acc:  47%] [G loss: 1.496534] time: 1:00:24.572938\n",
      "[Epoch 1/10] [Batch 221/350] [D loss: 0.252100, acc:  47%] [G loss: 1.063884] time: 1:00:30.824192\n",
      "[Epoch 1/10] [Batch 222/350] [D loss: 0.251516, acc:  49%] [G loss: 1.148131] time: 1:00:37.081461\n",
      "[Epoch 1/10] [Batch 223/350] [D loss: 0.251893, acc:  50%] [G loss: 1.352727] time: 1:00:43.344715\n",
      "[Epoch 1/10] [Batch 224/350] [D loss: 0.251925, acc:  48%] [G loss: 1.345228] time: 1:00:49.610994\n",
      "[Epoch 1/10] [Batch 225/350] [D loss: 0.251249, acc:  49%] [G loss: 1.233284] time: 1:00:55.893194\n",
      "[Epoch 1/10] [Batch 226/350] [D loss: 0.251319, acc:  46%] [G loss: 1.275044] time: 1:01:02.158442\n",
      "[Epoch 1/10] [Batch 227/350] [D loss: 0.251653, acc:  47%] [G loss: 1.314263] time: 1:01:08.427677\n",
      "[Epoch 1/10] [Batch 228/350] [D loss: 0.251751, acc:  48%] [G loss: 1.180952] time: 1:01:14.659984\n",
      "[Epoch 1/10] [Batch 229/350] [D loss: 0.251455, acc:  48%] [G loss: 1.204938] time: 1:01:20.940192\n",
      "[Epoch 1/10] [Batch 230/350] [D loss: 0.251660, acc:  51%] [G loss: 1.255368] time: 1:01:27.197461\n",
      "[Epoch 1/10] [Batch 231/350] [D loss: 0.251792, acc:  45%] [G loss: 1.421152] time: 1:01:33.430795\n",
      "[Epoch 1/10] [Batch 232/350] [D loss: 0.251749, acc:  53%] [G loss: 1.169739] time: 1:01:39.693050\n",
      "[Epoch 1/10] [Batch 233/350] [D loss: 0.251810, acc:  48%] [G loss: 1.168240] time: 1:01:45.961323\n",
      "[Epoch 1/10] [Batch 234/350] [D loss: 0.251662, acc:  49%] [G loss: 1.290197] time: 1:01:52.231525\n",
      "[Epoch 1/10] [Batch 235/350] [D loss: 0.251499, acc:  48%] [G loss: 1.241049] time: 1:01:58.491818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] [Batch 236/350] [D loss: 0.251553, acc:  45%] [G loss: 1.153846] time: 1:02:04.750053\n",
      "[Epoch 1/10] [Batch 237/350] [D loss: 0.251598, acc:  48%] [G loss: 1.254571] time: 1:02:11.038240\n",
      "[Epoch 1/10] [Batch 238/350] [D loss: 0.251383, acc:  49%] [G loss: 1.199074] time: 1:02:17.354352\n",
      "[Epoch 1/10] [Batch 239/350] [D loss: 0.251220, acc:  47%] [G loss: 1.184391] time: 1:02:23.635557\n",
      "[Epoch 1/10] [Batch 240/350] [D loss: 0.251435, acc:  48%] [G loss: 1.290260] time: 1:02:29.919786\n",
      "[Epoch 1/10] [Batch 241/350] [D loss: 0.251478, acc:  48%] [G loss: 1.251508] time: 1:02:36.189989\n",
      "[Epoch 1/10] [Batch 242/350] [D loss: 0.251403, acc:  45%] [G loss: 1.155939] time: 1:02:42.435324\n",
      "[Epoch 1/10] [Batch 243/350] [D loss: 0.252002, acc:  41%] [G loss: 1.492680] time: 1:02:48.717494\n",
      "[Epoch 1/10] [Batch 244/350] [D loss: 0.251731, acc:  48%] [G loss: 1.141948] time: 1:02:54.985734\n",
      "[Epoch 1/10] [Batch 245/350] [D loss: 0.251420, acc:  49%] [G loss: 1.388081] time: 1:03:01.270928\n",
      "[Epoch 1/10] [Batch 246/350] [D loss: 0.251414, acc:  53%] [G loss: 1.279350] time: 1:03:07.532187\n",
      "[Epoch 1/10] [Batch 247/350] [D loss: 0.251583, acc:  47%] [G loss: 1.159072] time: 1:03:13.809402\n",
      "[Epoch 1/10] [Batch 248/350] [D loss: 0.251407, acc:  46%] [G loss: 1.400543] time: 1:03:20.051712\n",
      "[Epoch 1/10] [Batch 249/350] [D loss: 0.251416, acc:  51%] [G loss: 1.534598] time: 1:03:26.336938\n",
      "[Epoch 1/10] [Batch 250/350] [D loss: 0.251501, acc:  47%] [G loss: 1.384653] time: 1:03:32.593178\n",
      "[Epoch 1/10] [Batch 251/350] [D loss: 0.251365, acc:  51%] [G loss: 1.181422] time: 1:03:38.862449\n",
      "[Epoch 1/10] [Batch 252/350] [D loss: 0.251606, acc:  48%] [G loss: 1.128128] time: 1:03:45.171580\n",
      "[Epoch 1/10] [Batch 253/350] [D loss: 0.251460, acc:  51%] [G loss: 1.364183] time: 1:03:51.444805\n",
      "[Epoch 1/10] [Batch 254/350] [D loss: 0.251489, acc:  47%] [G loss: 1.222608] time: 1:03:57.709024\n",
      "[Epoch 1/10] [Batch 255/350] [D loss: 0.251413, acc:  48%] [G loss: 1.220046] time: 1:04:03.984277\n",
      "[Epoch 1/10] [Batch 256/350] [D loss: 0.251604, acc:  43%] [G loss: 1.095309] time: 1:04:10.265450\n",
      "[Epoch 1/10] [Batch 257/350] [D loss: 0.251453, acc:  47%] [G loss: 1.274128] time: 1:04:16.544661\n",
      "[Epoch 1/10] [Batch 258/350] [D loss: 0.251244, acc:  46%] [G loss: 1.292145] time: 1:04:22.806951\n",
      "[Epoch 1/10] [Batch 259/350] [D loss: 0.251138, acc:  46%] [G loss: 1.012137] time: 1:04:29.228747\n",
      "[Epoch 1/10] [Batch 260/350] [D loss: 0.251169, acc:  49%] [G loss: 1.170479] time: 1:04:35.688506\n",
      "[Epoch 1/10] [Batch 261/350] [D loss: 0.251347, acc:  49%] [G loss: 1.101324] time: 1:04:41.955717\n",
      "[Epoch 1/10] [Batch 262/350] [D loss: 0.251323, acc:  46%] [G loss: 1.478953] time: 1:04:48.235925\n",
      "[Epoch 1/10] [Batch 263/350] [D loss: 0.251348, acc:  47%] [G loss: 1.227847] time: 1:04:54.496186\n",
      "[Epoch 1/10] [Batch 264/350] [D loss: 0.251345, acc:  47%] [G loss: 1.210122] time: 1:05:00.748501\n",
      "[Epoch 1/10] [Batch 265/350] [D loss: 0.251621, acc:  46%] [G loss: 1.075121] time: 1:05:07.027680\n",
      "[Epoch 1/10] [Batch 266/350] [D loss: 0.251757, acc:  50%] [G loss: 1.134835] time: 1:05:13.292960\n",
      "[Epoch 1/10] [Batch 267/350] [D loss: 0.251535, acc:  50%] [G loss: 1.100217] time: 1:05:19.565157\n",
      "[Epoch 1/10] [Batch 268/350] [D loss: 0.251778, acc:  51%] [G loss: 1.249228] time: 1:05:25.822458\n",
      "[Epoch 1/10] [Batch 269/350] [D loss: 0.251790, acc:  46%] [G loss: 1.253222] time: 1:05:32.090666\n",
      "[Epoch 1/10] [Batch 270/350] [D loss: 0.251597, acc:  38%] [G loss: 1.311419] time: 1:05:38.335968\n",
      "[Epoch 1/10] [Batch 271/350] [D loss: 0.251543, acc:  49%] [G loss: 1.075237] time: 1:05:44.665045\n",
      "[Epoch 1/10] [Batch 272/350] [D loss: 0.251552, acc:  48%] [G loss: 1.264868] time: 1:05:50.936277\n",
      "[Epoch 1/10] [Batch 273/350] [D loss: 0.251306, acc:  48%] [G loss: 1.382879] time: 1:05:57.208507\n",
      "[Epoch 1/10] [Batch 274/350] [D loss: 0.251172, acc:  50%] [G loss: 1.373414] time: 1:06:03.473755\n",
      "[Epoch 1/10] [Batch 275/350] [D loss: 0.251608, acc:  49%] [G loss: 1.246804] time: 1:06:09.747979\n",
      "[Epoch 1/10] [Batch 276/350] [D loss: 0.251536, acc:  53%] [G loss: 1.110276] time: 1:06:16.004280\n",
      "[Epoch 1/10] [Batch 277/350] [D loss: 0.251704, acc:  48%] [G loss: 1.094777] time: 1:06:22.281501\n",
      "[Epoch 1/10] [Batch 278/350] [D loss: 0.251408, acc:  47%] [G loss: 1.184375] time: 1:06:28.531755\n",
      "[Epoch 1/10] [Batch 279/350] [D loss: 0.251444, acc:  47%] [G loss: 1.214625] time: 1:06:34.809002\n",
      "[Epoch 1/10] [Batch 280/350] [D loss: 0.251292, acc:  48%] [G loss: 1.190852] time: 1:06:41.069232\n",
      "[Epoch 1/10] [Batch 281/350] [D loss: 0.251345, acc:  48%] [G loss: 1.166770] time: 1:06:47.342493\n",
      "[Epoch 1/10] [Batch 282/350] [D loss: 0.251605, acc:  51%] [G loss: 1.262437] time: 1:06:53.594741\n",
      "[Epoch 1/10] [Batch 283/350] [D loss: 0.251711, acc:  46%] [G loss: 1.106159] time: 1:06:59.856031\n",
      "[Epoch 1/10] [Batch 284/350] [D loss: 0.251763, acc:  49%] [G loss: 1.170643] time: 1:07:06.127232\n",
      "[Epoch 1/10] [Batch 285/350] [D loss: 0.251436, acc:  46%] [G loss: 1.122693] time: 1:07:12.396470\n",
      "[Epoch 1/10] [Batch 286/350] [D loss: 0.251325, acc:  47%] [G loss: 1.122832] time: 1:07:18.655733\n",
      "[Epoch 1/10] [Batch 287/350] [D loss: 0.251169, acc:  47%] [G loss: 1.180333] time: 1:07:24.939931\n",
      "[Epoch 1/10] [Batch 288/350] [D loss: 0.251429, acc:  47%] [G loss: 1.251937] time: 1:07:31.220138\n",
      "[Epoch 1/10] [Batch 289/350] [D loss: 0.251482, acc:  53%] [G loss: 1.411743] time: 1:07:37.457461\n",
      "[Epoch 1/10] [Batch 290/350] [D loss: 0.251501, acc:  48%] [G loss: 1.083254] time: 1:07:43.781552\n",
      "[Epoch 1/10] [Batch 291/350] [D loss: 0.251677, acc:  45%] [G loss: 1.335103] time: 1:07:50.048826\n",
      "[Epoch 1/10] [Batch 292/350] [D loss: 0.251470, acc:  49%] [G loss: 1.120980] time: 1:07:56.313045\n",
      "[Epoch 1/10] [Batch 293/350] [D loss: 0.251409, acc:  49%] [G loss: 1.509817] time: 1:08:02.591258\n",
      "[Epoch 1/10] [Batch 294/350] [D loss: 0.251477, acc:  53%] [G loss: 1.227380] time: 1:08:08.842544\n",
      "[Epoch 1/10] [Batch 295/350] [D loss: 0.251675, acc:  49%] [G loss: 1.184314] time: 1:08:15.073883\n",
      "[Epoch 1/10] [Batch 296/350] [D loss: 0.251403, acc:  45%] [G loss: 1.279147] time: 1:08:21.347109\n",
      "[Epoch 1/10] [Batch 297/350] [D loss: 0.251264, acc:  50%] [G loss: 1.213033] time: 1:08:27.601386\n",
      "[Epoch 1/10] [Batch 298/350] [D loss: 0.251362, acc:  50%] [G loss: 1.249286] time: 1:08:33.864640\n",
      "[Epoch 1/10] [Batch 299/350] [D loss: 0.251396, acc:  50%] [G loss: 1.445755] time: 1:08:40.122907\n",
      "[Epoch 1/10] [Batch 300/350] [D loss: 0.251791, acc:  48%] [G loss: 1.432930] time: 1:08:46.384165\n",
      "[Epoch 1/10] [Batch 301/350] [D loss: 0.252077, acc:  49%] [G loss: 1.363832] time: 1:08:52.646453\n",
      "[Epoch 1/10] [Batch 302/350] [D loss: 0.251914, acc:  49%] [G loss: 1.116506] time: 1:08:58.903691\n",
      "[Epoch 1/10] [Batch 303/350] [D loss: 0.251582, acc:  52%] [G loss: 1.169106] time: 1:09:05.187888\n",
      "[Epoch 1/10] [Batch 304/350] [D loss: 0.252020, acc:  47%] [G loss: 1.027718] time: 1:09:11.454134\n",
      "[Epoch 1/10] [Batch 305/350] [D loss: 0.252008, acc:  50%] [G loss: 1.151368] time: 1:09:17.715392\n",
      "[Epoch 1/10] [Batch 306/350] [D loss: 0.251361, acc:  50%] [G loss: 1.162663] time: 1:09:23.980640\n",
      "[Epoch 1/10] [Batch 307/350] [D loss: 0.251373, acc:  47%] [G loss: 1.295935] time: 1:09:30.243925\n",
      "[Epoch 1/10] [Batch 308/350] [D loss: 0.251277, acc:  47%] [G loss: 1.215669] time: 1:09:36.511168\n",
      "[Epoch 1/10] [Batch 309/350] [D loss: 0.251309, acc:  47%] [G loss: 1.216386] time: 1:09:42.829242\n",
      "[Epoch 1/10] [Batch 310/350] [D loss: 0.251373, acc:  47%] [G loss: 1.230608] time: 1:09:49.096516\n",
      "[Epoch 1/10] [Batch 311/350] [D loss: 0.251187, acc:  47%] [G loss: 1.296982] time: 1:09:55.367749\n",
      "[Epoch 1/10] [Batch 312/350] [D loss: 0.252203, acc:  50%] [G loss: 1.166394] time: 1:10:01.605040\n",
      "[Epoch 1/10] [Batch 313/350] [D loss: 0.252104, acc:  49%] [G loss: 1.026409] time: 1:10:07.874309\n",
      "[Epoch 1/10] [Batch 314/350] [D loss: 0.252384, acc:  47%] [G loss: 1.307860] time: 1:10:14.148533\n",
      "[Epoch 1/10] [Batch 315/350] [D loss: 0.251928, acc:  45%] [G loss: 1.241158] time: 1:10:20.406768\n",
      "[Epoch 1/10] [Batch 316/350] [D loss: 0.251921, acc:  52%] [G loss: 1.322080] time: 1:10:26.671019\n",
      "[Epoch 1/10] [Batch 317/350] [D loss: 0.252728, acc:  51%] [G loss: 1.260047] time: 1:10:32.939259\n",
      "[Epoch 1/10] [Batch 318/350] [D loss: 0.252329, acc:  46%] [G loss: 1.279328] time: 1:10:39.196559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] [Batch 319/350] [D loss: 0.251450, acc:  50%] [G loss: 1.158798] time: 1:10:45.439834\n",
      "[Epoch 1/10] [Batch 320/350] [D loss: 0.251685, acc:  48%] [G loss: 1.180418] time: 1:10:51.707109\n",
      "[Epoch 1/10] [Batch 321/350] [D loss: 0.251995, acc:  48%] [G loss: 1.221863] time: 1:10:57.981302\n",
      "[Epoch 1/10] [Batch 322/350] [D loss: 0.251565, acc:  47%] [G loss: 1.376619] time: 1:11:04.251536\n",
      "[Epoch 1/10] [Batch 323/350] [D loss: 0.251472, acc:  51%] [G loss: 1.229118] time: 1:11:10.509802\n",
      "[Epoch 1/10] [Batch 324/350] [D loss: 0.251442, acc:  49%] [G loss: 1.173980] time: 1:11:16.788024\n",
      "[Epoch 1/10] [Batch 325/350] [D loss: 0.251318, acc:  45%] [G loss: 1.304757] time: 1:11:23.041296\n",
      "[Epoch 1/10] [Batch 326/350] [D loss: 0.251754, acc:  51%] [G loss: 1.210858] time: 1:11:29.263687\n",
      "[Epoch 1/10] [Batch 327/350] [D loss: 0.251625, acc:  45%] [G loss: 1.169813] time: 1:11:35.533893\n",
      "[Epoch 1/10] [Batch 328/350] [D loss: 0.251594, acc:  46%] [G loss: 1.134753] time: 1:11:41.834048\n",
      "[Epoch 1/10] [Batch 329/350] [D loss: 0.251341, acc:  47%] [G loss: 1.223952] time: 1:11:48.097301\n",
      "[Epoch 1/10] [Batch 330/350] [D loss: 0.251394, acc:  48%] [G loss: 1.256039] time: 1:11:54.365541\n",
      "[Epoch 1/10] [Batch 331/350] [D loss: 0.251445, acc:  47%] [G loss: 1.414560] time: 1:12:00.643754\n",
      "[Epoch 1/10] [Batch 332/350] [D loss: 0.251668, acc:  45%] [G loss: 1.290719] time: 1:12:06.889056\n",
      "[Epoch 1/10] [Batch 333/350] [D loss: 0.251610, acc:  46%] [G loss: 1.081225] time: 1:12:13.175279\n",
      "[Epoch 1/10] [Batch 334/350] [D loss: 0.251444, acc:  46%] [G loss: 1.131796] time: 1:12:19.465430\n",
      "[Epoch 1/10] [Batch 335/350] [D loss: 0.251632, acc:  44%] [G loss: 1.278279] time: 1:12:25.734667\n",
      "[Epoch 1/10] [Batch 336/350] [D loss: 0.251646, acc:  49%] [G loss: 1.247658] time: 1:12:32.020858\n",
      "[Epoch 1/10] [Batch 337/350] [D loss: 0.251372, acc:  51%] [G loss: 1.160386] time: 1:12:38.284112\n",
      "[Epoch 1/10] [Batch 338/350] [D loss: 0.251340, acc:  49%] [G loss: 1.332642] time: 1:12:44.556341\n",
      "[Epoch 1/10] [Batch 339/350] [D loss: 0.251100, acc:  46%] [G loss: 1.103878] time: 1:12:50.803637\n",
      "[Epoch 1/10] [Batch 340/350] [D loss: 0.251590, acc:  40%] [G loss: 1.045165] time: 1:12:57.084843\n",
      "[Epoch 1/10] [Batch 341/350] [D loss: 0.251655, acc:  48%] [G loss: 1.089680] time: 1:13:03.344139\n",
      "[Epoch 1/10] [Batch 342/350] [D loss: 0.251599, acc:  43%] [G loss: 1.463533] time: 1:13:09.589408\n",
      "[Epoch 1/10] [Batch 343/350] [D loss: 0.251659, acc:  46%] [G loss: 1.182712] time: 1:13:15.860640\n",
      "[Epoch 1/10] [Batch 344/350] [D loss: 0.252047, acc:  47%] [G loss: 1.337135] time: 1:13:22.133867\n",
      "[Epoch 1/10] [Batch 345/350] [D loss: 0.251850, acc:  51%] [G loss: 1.143096] time: 1:13:28.394160\n",
      "[Epoch 1/10] [Batch 346/350] [D loss: 0.251675, acc:  47%] [G loss: 1.154089] time: 1:13:34.670347\n",
      "[Epoch 1/10] [Batch 347/350] [D loss: 0.251914, acc:  54%] [G loss: 1.154917] time: 1:13:40.928613\n",
      "[Epoch 1/10] [Batch 348/350] [D loss: 0.251831, acc:  49%] [G loss: 1.102055] time: 1:13:47.201872\n",
      "weights saved...\n",
      "[Epoch 2/10] [Batch 0/350] [D loss: 0.251332, acc:  48%] [G loss: 1.147966] time: 1:13:53.769280\n",
      "[Epoch 2/10] [Batch 1/350] [D loss: 0.251211, acc:  48%] [G loss: 1.114542] time: 1:14:05.599648\n",
      "[Epoch 2/10] [Batch 2/350] [D loss: 0.251430, acc:  47%] [G loss: 1.267431] time: 1:14:11.868885\n",
      "[Epoch 2/10] [Batch 3/350] [D loss: 0.251753, acc:  52%] [G loss: 1.441464] time: 1:14:18.123163\n",
      "[Epoch 2/10] [Batch 4/350] [D loss: 0.251666, acc:  49%] [G loss: 1.323052] time: 1:14:24.394395\n",
      "[Epoch 2/10] [Batch 5/350] [D loss: 0.251405, acc:  50%] [G loss: 1.328916] time: 1:14:30.662635\n",
      "[Epoch 2/10] [Batch 6/350] [D loss: 0.251648, acc:  42%] [G loss: 1.300422] time: 1:14:36.957803\n",
      "[Epoch 2/10] [Batch 7/350] [D loss: 0.251521, acc:  46%] [G loss: 1.289047] time: 1:14:43.209088\n",
      "[Epoch 2/10] [Batch 8/350] [D loss: 0.251652, acc:  44%] [G loss: 1.080858] time: 1:14:49.490293\n",
      "[Epoch 2/10] [Batch 9/350] [D loss: 0.251807, acc:  49%] [G loss: 1.184988] time: 1:14:55.735594\n",
      "[Epoch 2/10] [Batch 10/350] [D loss: 0.251633, acc:  42%] [G loss: 1.291873] time: 1:15:02.002869\n",
      "[Epoch 2/10] [Batch 11/350] [D loss: 0.251900, acc:  50%] [G loss: 1.444843] time: 1:15:08.260112\n",
      "[Epoch 2/10] [Batch 12/350] [D loss: 0.252257, acc:  51%] [G loss: 1.192550] time: 1:15:14.525386\n",
      "[Epoch 2/10] [Batch 13/350] [D loss: 0.252116, acc:  47%] [G loss: 1.101091] time: 1:15:20.777637\n",
      "[Epoch 2/10] [Batch 14/350] [D loss: 0.251339, acc:  46%] [G loss: 1.134217] time: 1:15:27.048901\n",
      "[Epoch 2/10] [Batch 15/350] [D loss: 0.251326, acc:  48%] [G loss: 1.113741] time: 1:15:33.318107\n",
      "[Epoch 2/10] [Batch 16/350] [D loss: 0.251371, acc:  46%] [G loss: 1.093219] time: 1:15:39.572384\n",
      "[Epoch 2/10] [Batch 17/350] [D loss: 0.251450, acc:  51%] [G loss: 1.515541] time: 1:15:45.836635\n",
      "[Epoch 2/10] [Batch 18/350] [D loss: 0.251420, acc:  47%] [G loss: 1.264295] time: 1:15:52.087920\n",
      "[Epoch 2/10] [Batch 19/350] [D loss: 0.251425, acc:  46%] [G loss: 1.218255] time: 1:15:58.343226\n",
      "[Epoch 2/10] [Batch 20/350] [D loss: 0.251449, acc:  44%] [G loss: 1.390765] time: 1:16:04.631413\n",
      "[Epoch 2/10] [Batch 21/350] [D loss: 0.251535, acc:  49%] [G loss: 1.249621] time: 1:16:10.889648\n",
      "[Epoch 2/10] [Batch 22/350] [D loss: 0.251377, acc:  47%] [G loss: 1.098110] time: 1:16:17.151904\n",
      "[Epoch 2/10] [Batch 23/350] [D loss: 0.251121, acc:  47%] [G loss: 1.367430] time: 1:16:23.420144\n",
      "[Epoch 2/10] [Batch 24/350] [D loss: 0.251415, acc:  48%] [G loss: 1.126693] time: 1:16:29.662453\n",
      "[Epoch 2/10] [Batch 25/350] [D loss: 0.251299, acc:  45%] [G loss: 1.134802] time: 1:16:35.947652\n",
      "[Epoch 2/10] [Batch 26/350] [D loss: 0.251285, acc:  48%] [G loss: 1.184729] time: 1:16:42.219908\n",
      "[Epoch 2/10] [Batch 27/350] [D loss: 0.251326, acc:  45%] [G loss: 1.249771] time: 1:16:48.492139\n",
      "[Epoch 2/10] [Batch 28/350] [D loss: 0.251493, acc:  42%] [G loss: 1.131682] time: 1:16:54.764336\n",
      "[Epoch 2/10] [Batch 29/350] [D loss: 0.251412, acc:  46%] [G loss: 1.180280] time: 1:17:01.029619\n",
      "[Epoch 2/10] [Batch 30/350] [D loss: 0.251304, acc:  49%] [G loss: 1.141890] time: 1:17:07.291840\n",
      "[Epoch 2/10] [Batch 31/350] [D loss: 0.251239, acc:  47%] [G loss: 1.215135] time: 1:17:13.558085\n",
      "[Epoch 2/10] [Batch 32/350] [D loss: 0.251284, acc:  46%] [G loss: 1.177546] time: 1:17:19.837328\n",
      "[Epoch 2/10] [Batch 33/350] [D loss: 0.251313, acc:  47%] [G loss: 1.221719] time: 1:17:26.123519\n",
      "[Epoch 2/10] [Batch 34/350] [D loss: 0.251512, acc:  52%] [G loss: 1.152100] time: 1:17:32.387739\n",
      "[Epoch 2/10] [Batch 35/350] [D loss: 0.251429, acc:  51%] [G loss: 1.033106] time: 1:17:38.648997\n",
      "[Epoch 2/10] [Batch 36/350] [D loss: 0.251298, acc:  50%] [G loss: 1.036650] time: 1:17:44.953141\n",
      "[Epoch 2/10] [Batch 37/350] [D loss: 0.251331, acc:  48%] [G loss: 1.306176] time: 1:17:51.207419\n",
      "[Epoch 2/10] [Batch 38/350] [D loss: 0.251588, acc:  48%] [G loss: 1.326443] time: 1:17:57.499595\n",
      "[Epoch 2/10] [Batch 39/350] [D loss: 0.251369, acc:  48%] [G loss: 1.159297] time: 1:18:03.765840\n",
      "[Epoch 2/10] [Batch 40/350] [D loss: 0.251421, acc:  47%] [G loss: 1.300708] time: 1:18:10.030091\n",
      "[Epoch 2/10] [Batch 41/350] [D loss: 0.251856, acc:  46%] [G loss: 1.268082] time: 1:18:16.302320\n",
      "[Epoch 2/10] [Batch 42/350] [D loss: 0.251546, acc:  50%] [G loss: 1.055589] time: 1:18:22.562581\n",
      "[Epoch 2/10] [Batch 43/350] [D loss: 0.251715, acc:  48%] [G loss: 1.259896] time: 1:18:28.842789\n",
      "[Epoch 2/10] [Batch 44/350] [D loss: 0.251398, acc:  46%] [G loss: 1.236056] time: 1:18:35.108037\n",
      "[Epoch 2/10] [Batch 45/350] [D loss: 0.251621, acc:  48%] [G loss: 1.197202] time: 1:18:41.363344\n",
      "[Epoch 2/10] [Batch 46/350] [D loss: 0.251184, acc:  48%] [G loss: 1.084110] time: 1:18:47.611634\n",
      "[Epoch 2/10] [Batch 47/350] [D loss: 0.251213, acc:  47%] [G loss: 1.194218] time: 1:18:53.869872\n",
      "[Epoch 2/10] [Batch 48/350] [D loss: 0.251312, acc:  46%] [G loss: 1.278814] time: 1:19:00.141104\n",
      "[Epoch 2/10] [Batch 49/350] [D loss: 0.251300, acc:  49%] [G loss: 1.049985] time: 1:19:06.427296\n",
      "[Epoch 2/10] [Batch 50/350] [D loss: 0.251293, acc:  49%] [G loss: 1.082108] time: 1:19:12.693542\n",
      "[Epoch 2/10] [Batch 51/350] [D loss: 0.251573, acc:  45%] [G loss: 1.062098] time: 1:19:18.954800\n",
      "[Epoch 2/10] [Batch 52/350] [D loss: 0.251593, acc:  48%] [G loss: 1.054794] time: 1:19:25.231018\n",
      "[Epoch 2/10] [Batch 53/350] [D loss: 0.251706, acc:  51%] [G loss: 1.043249] time: 1:19:31.514219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/10] [Batch 54/350] [D loss: 0.251423, acc:  52%] [G loss: 1.224285] time: 1:19:37.768496\n",
      "[Epoch 2/10] [Batch 55/350] [D loss: 0.251420, acc:  50%] [G loss: 1.168746] time: 1:19:44.062667\n",
      "[Epoch 2/10] [Batch 56/350] [D loss: 0.251175, acc:  49%] [G loss: 1.382823] time: 1:19:50.322928\n",
      "[Epoch 2/10] [Batch 57/350] [D loss: 0.251403, acc:  55%] [G loss: 1.254145] time: 1:19:56.573247\n",
      "[Epoch 2/10] [Batch 58/350] [D loss: 0.251483, acc:  51%] [G loss: 1.314556] time: 1:20:02.851461\n",
      "[Epoch 2/10] [Batch 59/350] [D loss: 0.251474, acc:  52%] [G loss: 1.251340] time: 1:20:09.121664\n",
      "[Epoch 2/10] [Batch 60/350] [D loss: 0.251677, acc:  51%] [G loss: 1.273456] time: 1:20:15.374944\n",
      "[Epoch 2/10] [Batch 61/350] [D loss: 0.251685, acc:  47%] [G loss: 1.434997] time: 1:20:21.653157\n",
      "[Epoch 2/10] [Batch 62/350] [D loss: 0.251506, acc:  42%] [G loss: 1.233867] time: 1:20:27.911424\n",
      "[Epoch 2/10] [Batch 63/350] [D loss: 0.251474, acc:  48%] [G loss: 1.301301] time: 1:20:34.166733\n",
      "[Epoch 2/10] [Batch 64/350] [D loss: 0.251417, acc:  47%] [G loss: 1.373626] time: 1:20:40.406016\n",
      "[Epoch 2/10] [Batch 65/350] [D loss: 0.251719, acc:  45%] [G loss: 1.181715] time: 1:20:46.696231\n",
      "[Epoch 2/10] [Batch 66/350] [D loss: 0.251477, acc:  49%] [G loss: 1.200519] time: 1:20:52.965435\n",
      "[Epoch 2/10] [Batch 67/350] [D loss: 0.251539, acc:  49%] [G loss: 1.349188] time: 1:20:59.216720\n",
      "[Epoch 2/10] [Batch 68/350] [D loss: 0.251905, acc:  46%] [G loss: 1.114556] time: 1:21:05.504907\n",
      "[Epoch 2/10] [Batch 69/350] [D loss: 0.251970, acc:  45%] [G loss: 1.287619] time: 1:21:11.777136\n",
      "[Epoch 2/10] [Batch 70/350] [D loss: 0.252110, acc:  48%] [G loss: 1.244371] time: 1:21:18.021440\n",
      "[Epoch 2/10] [Batch 71/350] [D loss: 0.251726, acc:  48%] [G loss: 1.231606] time: 1:21:24.287685\n",
      "[Epoch 2/10] [Batch 72/350] [D loss: 0.251898, acc:  51%] [G loss: 1.238257] time: 1:21:30.544955\n",
      "[Epoch 2/10] [Batch 73/350] [D loss: 0.251849, acc:  50%] [G loss: 1.196475] time: 1:21:36.815189\n",
      "[Epoch 2/10] [Batch 74/350] [D loss: 0.252010, acc:  48%] [G loss: 1.425953] time: 1:21:43.121328\n",
      "[Epoch 2/10] [Batch 75/350] [D loss: 0.252647, acc:  49%] [G loss: 1.343030] time: 1:21:49.366662\n",
      "[Epoch 2/10] [Batch 76/350] [D loss: 0.252515, acc:  49%] [G loss: 1.590408] time: 1:21:55.624896\n",
      "[Epoch 2/10] [Batch 77/350] [D loss: 0.251696, acc:  51%] [G loss: 1.235165] time: 1:22:01.904107\n",
      "[Epoch 2/10] [Batch 78/350] [D loss: 0.251984, acc:  53%] [G loss: 1.225137] time: 1:22:08.172346\n",
      "[Epoch 2/10] [Batch 79/350] [D loss: 0.251781, acc:  48%] [G loss: 1.397240] time: 1:22:14.508405\n",
      "[Epoch 2/10] [Batch 80/350] [D loss: 0.251786, acc:  50%] [G loss: 1.311210] time: 1:22:20.774650\n",
      "[Epoch 2/10] [Batch 81/350] [D loss: 0.252571, acc:  53%] [G loss: 1.390402] time: 1:22:27.035909\n",
      "[Epoch 2/10] [Batch 82/350] [D loss: 0.252608, acc:  50%] [G loss: 1.093539] time: 1:22:33.323132\n",
      "[Epoch 2/10] [Batch 83/350] [D loss: 0.252170, acc:  50%] [G loss: 1.319696] time: 1:22:39.581366\n",
      "[Epoch 2/10] [Batch 84/350] [D loss: 0.252343, acc:  46%] [G loss: 1.515471] time: 1:22:45.835642\n",
      "[Epoch 2/10] [Batch 85/350] [D loss: 0.252003, acc:  46%] [G loss: 1.345852] time: 1:22:52.089920\n",
      "[Epoch 2/10] [Batch 86/350] [D loss: 0.251786, acc:  49%] [G loss: 1.154313] time: 1:22:58.342202\n",
      "[Epoch 2/10] [Batch 87/350] [D loss: 0.252358, acc:  52%] [G loss: 1.466848] time: 1:23:04.602465\n",
      "[Epoch 2/10] [Batch 88/350] [D loss: 0.252153, acc:  50%] [G loss: 1.110938] time: 1:23:10.882672\n",
      "[Epoch 2/10] [Batch 89/350] [D loss: 0.251441, acc:  52%] [G loss: 1.241413] time: 1:23:17.163878\n",
      "[Epoch 2/10] [Batch 90/350] [D loss: 0.251396, acc:  50%] [G loss: 1.160607] time: 1:23:23.437104\n",
      "[Epoch 2/10] [Batch 91/350] [D loss: 0.251340, acc:  48%] [G loss: 1.076573] time: 1:23:29.693376\n",
      "[Epoch 2/10] [Batch 92/350] [D loss: 0.251508, acc:  47%] [G loss: 1.126464] time: 1:23:35.957626\n",
      "[Epoch 2/10] [Batch 93/350] [D loss: 0.251269, acc:  48%] [G loss: 1.185672] time: 1:23:42.262768\n",
      "[Epoch 2/10] [Batch 94/350] [D loss: 0.251307, acc:  48%] [G loss: 1.259405] time: 1:23:48.531008\n",
      "[Epoch 2/10] [Batch 95/350] [D loss: 0.251259, acc:  47%] [G loss: 1.230398] time: 1:23:54.801242\n",
      "[Epoch 2/10] [Batch 96/350] [D loss: 0.251303, acc:  51%] [G loss: 1.092206] time: 1:24:01.056518\n",
      "[Epoch 2/10] [Batch 97/350] [D loss: 0.251333, acc:  49%] [G loss: 1.384729] time: 1:24:07.351685\n",
      "[Epoch 2/10] [Batch 98/350] [D loss: 0.251393, acc:  48%] [G loss: 1.129747] time: 1:24:13.597984\n",
      "[Epoch 2/10] [Batch 99/350] [D loss: 0.251230, acc:  45%] [G loss: 1.197458] time: 1:24:19.884176\n",
      "[Epoch 2/10] [Batch 100/350] [D loss: 0.251321, acc:  52%] [G loss: 1.305756] time: 1:24:26.130504\n",
      "[Epoch 2/10] [Batch 101/350] [D loss: 0.251546, acc:  50%] [G loss: 1.117851] time: 1:24:32.443626\n",
      "[Epoch 2/10] [Batch 102/350] [D loss: 0.252342, acc:  55%] [G loss: 1.403870] time: 1:24:38.693882\n",
      "[Epoch 2/10] [Batch 103/350] [D loss: 0.252700, acc:  49%] [G loss: 1.334481] time: 1:24:44.956139\n",
      "[Epoch 2/10] [Batch 104/350] [D loss: 0.252034, acc:  52%] [G loss: 1.308960] time: 1:24:51.230394\n",
      "[Epoch 2/10] [Batch 105/350] [D loss: 0.251788, acc:  43%] [G loss: 1.240253] time: 1:24:57.516555\n",
      "[Epoch 2/10] [Batch 106/350] [D loss: 0.251866, acc:  50%] [G loss: 1.485471] time: 1:25:03.810757\n",
      "[Epoch 2/10] [Batch 107/350] [D loss: 0.251527, acc:  52%] [G loss: 1.059767] time: 1:25:10.112906\n",
      "[Epoch 2/10] [Batch 108/350] [D loss: 0.251723, acc:  47%] [G loss: 1.236733] time: 1:25:16.381115\n",
      "[Epoch 2/10] [Batch 109/350] [D loss: 0.252744, acc:  52%] [G loss: 1.222428] time: 1:25:22.657333\n",
      "[Epoch 2/10] [Batch 110/350] [D loss: 0.252418, acc:  48%] [G loss: 1.361320] time: 1:25:28.912639\n",
      "[Epoch 2/10] [Batch 111/350] [D loss: 0.251925, acc:  46%] [G loss: 1.210590] time: 1:25:35.175861\n",
      "[Epoch 2/10] [Batch 112/350] [D loss: 0.252785, acc:  50%] [G loss: 1.463072] time: 1:25:41.467040\n",
      "[Epoch 2/10] [Batch 113/350] [D loss: 0.252803, acc:  50%] [G loss: 1.213951] time: 1:25:47.743259\n",
      "[Epoch 2/10] [Batch 114/350] [D loss: 0.251812, acc:  46%] [G loss: 1.234417] time: 1:25:54.010535\n",
      "[Epoch 2/10] [Batch 115/350] [D loss: 0.252288, acc:  46%] [G loss: 1.398153] time: 1:26:00.293701\n",
      "[Epoch 2/10] [Batch 116/350] [D loss: 0.252464, acc:  54%] [G loss: 1.297038] time: 1:26:06.582885\n",
      "[Epoch 2/10] [Batch 117/350] [D loss: 0.251883, acc:  52%] [G loss: 1.205378] time: 1:26:12.855146\n",
      "[Epoch 2/10] [Batch 118/350] [D loss: 0.252747, acc:  49%] [G loss: 1.317436] time: 1:26:19.105402\n",
      "[Epoch 2/10] [Batch 119/350] [D loss: 0.251854, acc:  44%] [G loss: 1.258682] time: 1:26:25.381621\n",
      "[Epoch 2/10] [Batch 120/350] [D loss: 0.251521, acc:  52%] [G loss: 1.257140] time: 1:26:31.645872\n",
      "[Epoch 2/10] [Batch 121/350] [D loss: 0.251615, acc:  50%] [G loss: 1.198725] time: 1:26:37.898155\n",
      "[Epoch 2/10] [Batch 122/350] [D loss: 0.251509, acc:  45%] [G loss: 1.199131] time: 1:26:44.171381\n",
      "[Epoch 2/10] [Batch 123/350] [D loss: 0.251795, acc:  50%] [G loss: 1.159169] time: 1:26:50.432640\n",
      "[Epoch 2/10] [Batch 124/350] [D loss: 0.252242, acc:  50%] [G loss: 1.194360] time: 1:26:56.680933\n",
      "[Epoch 2/10] [Batch 125/350] [D loss: 0.252017, acc:  48%] [G loss: 1.114660] time: 1:27:02.927232\n",
      "[Epoch 2/10] [Batch 126/350] [D loss: 0.251636, acc:  47%] [G loss: 1.285642] time: 1:27:09.197499\n",
      "[Epoch 2/10] [Batch 127/350] [D loss: 0.252007, acc:  53%] [G loss: 1.271324] time: 1:27:15.516570\n",
      "[Epoch 2/10] [Batch 128/350] [D loss: 0.252291, acc:  50%] [G loss: 1.104615] time: 1:27:21.799771\n",
      "[Epoch 2/10] [Batch 129/350] [D loss: 0.251667, acc:  48%] [G loss: 1.265587] time: 1:27:28.088988\n",
      "[Epoch 2/10] [Batch 130/350] [D loss: 0.252036, acc:  48%] [G loss: 1.291041] time: 1:27:34.368200\n",
      "[Epoch 2/10] [Batch 131/350] [D loss: 0.251941, acc:  51%] [G loss: 1.151905] time: 1:27:40.657349\n",
      "[Epoch 2/10] [Batch 132/350] [D loss: 0.251553, acc:  47%] [G loss: 1.134502] time: 1:27:46.927616\n",
      "[Epoch 2/10] [Batch 133/350] [D loss: 0.252305, acc:  48%] [G loss: 1.301269] time: 1:27:53.204800\n",
      "[Epoch 2/10] [Batch 134/350] [D loss: 0.252144, acc:  47%] [G loss: 1.221654] time: 1:27:59.450132\n",
      "[Epoch 2/10] [Batch 135/350] [D loss: 0.251380, acc:  43%] [G loss: 1.356096] time: 1:28:05.718341\n",
      "[Epoch 2/10] [Batch 136/350] [D loss: 0.251178, acc:  47%] [G loss: 1.162800] time: 1:28:11.984587\n",
      "[Epoch 2/10] [Batch 137/350] [D loss: 0.251161, acc:  47%] [G loss: 1.349555] time: 1:28:18.268816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/10] [Batch 138/350] [D loss: 0.251405, acc:  54%] [G loss: 1.439442] time: 1:28:24.537024\n",
      "[Epoch 2/10] [Batch 139/350] [D loss: 0.251887, acc:  53%] [G loss: 1.144077] time: 1:28:30.809285\n",
      "[Epoch 2/10] [Batch 140/350] [D loss: 0.251893, acc:  49%] [G loss: 1.304783] time: 1:28:37.069547\n",
      "[Epoch 2/10] [Batch 141/350] [D loss: 0.251653, acc:  44%] [G loss: 1.185641] time: 1:28:43.318805\n",
      "[Epoch 2/10] [Batch 142/350] [D loss: 0.251685, acc:  49%] [G loss: 1.131518] time: 1:28:49.588042\n",
      "[Epoch 2/10] [Batch 143/350] [D loss: 0.251486, acc:  48%] [G loss: 1.276233] time: 1:28:55.846309\n",
      "[Epoch 2/10] [Batch 144/350] [D loss: 0.251379, acc:  49%] [G loss: 1.288510] time: 1:29:02.101618\n",
      "[Epoch 2/10] [Batch 145/350] [D loss: 0.251603, acc:  48%] [G loss: 1.458862] time: 1:29:08.373813\n",
      "[Epoch 2/10] [Batch 146/350] [D loss: 0.251421, acc:  47%] [G loss: 1.338024] time: 1:29:14.649035\n",
      "[Epoch 2/10] [Batch 147/350] [D loss: 0.251399, acc:  46%] [G loss: 1.306980] time: 1:29:20.915280\n",
      "[Epoch 2/10] [Batch 148/350] [D loss: 0.251990, acc:  42%] [G loss: 1.313844] time: 1:29:27.215435\n",
      "[Epoch 2/10] [Batch 149/350] [D loss: 0.251862, acc:  48%] [G loss: 1.071309] time: 1:29:33.515590\n",
      "[Epoch 2/10] [Batch 150/350] [D loss: 0.251539, acc:  51%] [G loss: 1.267027] time: 1:29:39.808762\n",
      "[Epoch 2/10] [Batch 151/350] [D loss: 0.251222, acc:  47%] [G loss: 1.159743] time: 1:29:46.102933\n",
      "[Epoch 2/10] [Batch 152/350] [D loss: 0.251236, acc:  48%] [G loss: 1.326610] time: 1:29:52.358239\n",
      "[Epoch 2/10] [Batch 153/350] [D loss: 0.251120, acc:  48%] [G loss: 1.128891] time: 1:29:58.635424\n",
      "[Epoch 2/10] [Batch 154/350] [D loss: 0.251542, acc:  50%] [G loss: 1.253806] time: 1:30:04.917626\n",
      "[Epoch 2/10] [Batch 155/350] [D loss: 0.251648, acc:  46%] [G loss: 1.180576] time: 1:30:11.197835\n",
      "[Epoch 2/10] [Batch 156/350] [D loss: 0.251646, acc:  46%] [G loss: 1.156418] time: 1:30:17.466108\n",
      "[Epoch 2/10] [Batch 157/350] [D loss: 0.251587, acc:  49%] [G loss: 1.201481] time: 1:30:23.745286\n",
      "[Epoch 2/10] [Batch 158/350] [D loss: 0.251495, acc:  50%] [G loss: 1.161557] time: 1:30:30.009536\n",
      "[Epoch 2/10] [Batch 159/350] [D loss: 0.251356, acc:  45%] [G loss: 1.355167] time: 1:30:36.282763\n",
      "[Epoch 2/10] [Batch 160/350] [D loss: 0.251453, acc:  51%] [G loss: 1.184177] time: 1:30:42.542058\n",
      "[Epoch 2/10] [Batch 161/350] [D loss: 0.251597, acc:  48%] [G loss: 1.265994] time: 1:30:48.803285\n",
      "[Epoch 2/10] [Batch 162/350] [D loss: 0.251431, acc:  48%] [G loss: 1.169565] time: 1:30:55.056566\n",
      "[Epoch 2/10] [Batch 163/350] [D loss: 0.251906, acc:  45%] [G loss: 1.206485] time: 1:31:01.326800\n",
      "[Epoch 2/10] [Batch 164/350] [D loss: 0.251897, acc:  48%] [G loss: 1.142075] time: 1:31:07.567115\n",
      "[Epoch 2/10] [Batch 165/350] [D loss: 0.251488, acc:  41%] [G loss: 1.166407] time: 1:31:13.829377\n",
      "[Epoch 2/10] [Batch 166/350] [D loss: 0.251437, acc:  48%] [G loss: 1.238026] time: 1:31:20.096613\n",
      "[Epoch 2/10] [Batch 167/350] [D loss: 0.251440, acc:  49%] [G loss: 1.020800] time: 1:31:26.365882\n",
      "[Epoch 2/10] [Batch 168/350] [D loss: 0.251557, acc:  50%] [G loss: 1.208734] time: 1:31:32.640106\n",
      "[Epoch 2/10] [Batch 169/350] [D loss: 0.252235, acc:  56%] [G loss: 1.002902] time: 1:31:38.882416\n",
      "[Epoch 2/10] [Batch 170/350] [D loss: 0.252570, acc:  49%] [G loss: 1.275170] time: 1:31:45.183568\n",
      "[Epoch 2/10] [Batch 171/350] [D loss: 0.251973, acc:  49%] [G loss: 1.232013] time: 1:31:51.456762\n",
      "[Epoch 2/10] [Batch 172/350] [D loss: 0.252512, acc:  53%] [G loss: 1.182638] time: 1:31:57.708048\n",
      "[Epoch 2/10] [Batch 173/350] [D loss: 0.253588, acc:  49%] [G loss: 1.439653] time: 1:32:03.987265\n",
      "[Epoch 2/10] [Batch 174/350] [D loss: 0.252393, acc:  50%] [G loss: 1.228371] time: 1:32:10.262512\n",
      "[Epoch 2/10] [Batch 175/350] [D loss: 0.252520, acc:  47%] [G loss: 1.328619] time: 1:32:16.619483\n",
      "[Epoch 2/10] [Batch 176/350] [D loss: 0.253650, acc:  49%] [G loss: 1.201371] time: 1:32:28.417936\n",
      "[Epoch 2/10] [Batch 177/350] [D loss: 0.252536, acc:  50%] [G loss: 1.306365] time: 1:32:34.676203\n",
      "[Epoch 2/10] [Batch 178/350] [D loss: 0.251284, acc:  49%] [G loss: 1.222619] time: 1:32:40.967381\n",
      "[Epoch 2/10] [Batch 179/350] [D loss: 0.251443, acc:  48%] [G loss: 1.143571] time: 1:32:47.237616\n",
      "[Epoch 2/10] [Batch 180/350] [D loss: 0.251501, acc:  47%] [G loss: 1.120191] time: 1:32:53.512837\n",
      "[Epoch 2/10] [Batch 181/350] [D loss: 0.251492, acc:  49%] [G loss: 1.211967] time: 1:32:59.790085\n",
      "[Epoch 2/10] [Batch 182/350] [D loss: 0.251453, acc:  47%] [G loss: 1.121703] time: 1:33:06.056299\n",
      "[Epoch 2/10] [Batch 183/350] [D loss: 0.251153, acc:  50%] [G loss: 1.318389] time: 1:33:12.328528\n",
      "[Epoch 2/10] [Batch 184/350] [D loss: 0.251319, acc:  50%] [G loss: 1.268251] time: 1:33:18.592779\n",
      "[Epoch 2/10] [Batch 185/350] [D loss: 0.251467, acc:  49%] [G loss: 1.005706] time: 1:33:24.870993\n",
      "[Epoch 2/10] [Batch 186/350] [D loss: 0.251344, acc:  46%] [G loss: 1.288123] time: 1:33:31.119317\n",
      "[Epoch 2/10] [Batch 187/350] [D loss: 0.251281, acc:  46%] [G loss: 1.260715] time: 1:33:37.386528\n",
      "[Epoch 2/10] [Batch 188/350] [D loss: 0.251471, acc:  47%] [G loss: 1.008007] time: 1:33:43.680698\n",
      "[Epoch 2/10] [Batch 189/350] [D loss: 0.251539, acc:  54%] [G loss: 1.162731] time: 1:33:49.949936\n",
      "[Epoch 2/10] [Batch 190/350] [D loss: 0.251433, acc:  50%] [G loss: 1.419286] time: 1:33:56.194240\n",
      "[Epoch 2/10] [Batch 191/350] [D loss: 0.251681, acc:  45%] [G loss: 1.265138] time: 1:34:02.476443\n",
      "[Epoch 2/10] [Batch 192/350] [D loss: 0.251521, acc:  44%] [G loss: 1.102611] time: 1:34:08.724737\n",
      "[Epoch 2/10] [Batch 193/350] [D loss: 0.251781, acc:  49%] [G loss: 1.227239] time: 1:34:14.984997\n",
      "[Epoch 2/10] [Batch 194/350] [D loss: 0.251749, acc:  49%] [G loss: 1.443327] time: 1:34:21.245258\n",
      "[Epoch 2/10] [Batch 195/350] [D loss: 0.252103, acc:  45%] [G loss: 1.215796] time: 1:34:27.505520\n",
      "[Epoch 2/10] [Batch 196/350] [D loss: 0.252649, acc:  54%] [G loss: 1.243866] time: 1:34:33.749824\n",
      "[Epoch 2/10] [Batch 197/350] [D loss: 0.252234, acc:  51%] [G loss: 1.054320] time: 1:34:40.007124\n",
      "[Epoch 2/10] [Batch 198/350] [D loss: 0.252002, acc:  47%] [G loss: 1.125167] time: 1:34:46.260373\n",
      "[Epoch 2/10] [Batch 199/350] [D loss: 0.252503, acc:  46%] [G loss: 1.147380] time: 1:34:52.530608\n",
      "[Epoch 2/10] [Batch 200/350] [D loss: 0.251865, acc:  45%] [G loss: 1.235569] time: 1:34:58.787877\n",
      "[Epoch 2/10] [Batch 201/350] [D loss: 0.251258, acc:  48%] [G loss: 1.066446] time: 1:35:05.053125\n",
      "[Epoch 2/10] [Batch 202/350] [D loss: 0.251473, acc:  48%] [G loss: 1.217395] time: 1:35:11.316378\n",
      "[Epoch 2/10] [Batch 203/350] [D loss: 0.251332, acc:  46%] [G loss: 1.134623] time: 1:35:17.588608\n",
      "[Epoch 2/10] [Batch 204/350] [D loss: 0.251500, acc:  47%] [G loss: 1.150211] time: 1:35:23.867850\n",
      "[Epoch 2/10] [Batch 205/350] [D loss: 0.251535, acc:  50%] [G loss: 1.116429] time: 1:35:30.116112\n",
      "[Epoch 2/10] [Batch 206/350] [D loss: 0.251436, acc:  49%] [G loss: 1.206699] time: 1:35:36.378369\n",
      "[Epoch 2/10] [Batch 207/350] [D loss: 0.251307, acc:  50%] [G loss: 1.333230] time: 1:35:42.694514\n",
      "[Epoch 2/10] [Batch 208/350] [D loss: 0.251552, acc:  50%] [G loss: 1.132668] time: 1:35:48.973691\n",
      "[Epoch 2/10] [Batch 209/350] [D loss: 0.252002, acc:  48%] [G loss: 1.328172] time: 1:35:55.228965\n",
      "[Epoch 2/10] [Batch 210/350] [D loss: 0.251780, acc:  49%] [G loss: 1.226459] time: 1:36:01.492218\n",
      "[Epoch 2/10] [Batch 211/350] [D loss: 0.251486, acc:  46%] [G loss: 1.058305] time: 1:36:07.745531\n",
      "[Epoch 2/10] [Batch 212/350] [D loss: 0.251543, acc:  47%] [G loss: 0.998775] time: 1:36:14.026735\n",
      "[Epoch 2/10] [Batch 213/350] [D loss: 0.251610, acc:  49%] [G loss: 1.135601] time: 1:36:20.290955\n",
      "[Epoch 2/10] [Batch 214/350] [D loss: 0.251272, acc:  48%] [G loss: 1.124872] time: 1:36:26.565178\n",
      "[Epoch 2/10] [Batch 215/350] [D loss: 0.251168, acc:  48%] [G loss: 1.264891] time: 1:36:32.827435\n",
      "[Epoch 2/10] [Batch 216/350] [D loss: 0.251112, acc:  48%] [G loss: 1.078848] time: 1:36:39.085701\n",
      "[Epoch 2/10] [Batch 217/350] [D loss: 0.251332, acc:  49%] [G loss: 1.016488] time: 1:36:45.341974\n",
      "[Epoch 2/10] [Batch 218/350] [D loss: 0.251297, acc:  48%] [G loss: 1.164189] time: 1:36:51.611211\n",
      "[Epoch 2/10] [Batch 219/350] [D loss: 0.252189, acc:  39%] [G loss: 1.156637] time: 1:36:57.905381\n",
      "[Epoch 2/10] [Batch 220/350] [D loss: 0.252460, acc:  47%] [G loss: 1.478755] time: 1:37:04.188581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/10] [Batch 221/350] [D loss: 0.252032, acc:  47%] [G loss: 1.054479] time: 1:37:10.432886\n",
      "[Epoch 2/10] [Batch 222/350] [D loss: 0.251453, acc:  49%] [G loss: 1.134661] time: 1:37:16.732043\n",
      "[Epoch 2/10] [Batch 223/350] [D loss: 0.251764, acc:  50%] [G loss: 1.330676] time: 1:37:23.012250\n",
      "[Epoch 2/10] [Batch 224/350] [D loss: 0.251858, acc:  49%] [G loss: 1.325657] time: 1:37:29.286475\n",
      "[Epoch 2/10] [Batch 225/350] [D loss: 0.251203, acc:  50%] [G loss: 1.207649] time: 1:37:35.551723\n",
      "[Epoch 2/10] [Batch 226/350] [D loss: 0.251223, acc:  46%] [G loss: 1.251581] time: 1:37:41.866837\n",
      "[Epoch 2/10] [Batch 227/350] [D loss: 0.251597, acc:  47%] [G loss: 1.292880] time: 1:37:48.149040\n",
      "[Epoch 2/10] [Batch 228/350] [D loss: 0.251677, acc:  48%] [G loss: 1.179078] time: 1:37:54.390352\n",
      "[Epoch 2/10] [Batch 229/350] [D loss: 0.251376, acc:  48%] [G loss: 1.187268] time: 1:38:00.668565\n",
      "[Epoch 2/10] [Batch 230/350] [D loss: 0.251577, acc:  52%] [G loss: 1.231208] time: 1:38:06.926832\n",
      "[Epoch 2/10] [Batch 231/350] [D loss: 0.251714, acc:  45%] [G loss: 1.393935] time: 1:38:13.153184\n",
      "[Epoch 2/10] [Batch 232/350] [D loss: 0.251636, acc:  52%] [G loss: 1.146143] time: 1:38:19.406496\n",
      "[Epoch 2/10] [Batch 233/350] [D loss: 0.251682, acc:  48%] [G loss: 1.131791] time: 1:38:25.680688\n",
      "[Epoch 2/10] [Batch 234/350] [D loss: 0.251585, acc:  49%] [G loss: 1.268446] time: 1:38:31.952917\n",
      "[Epoch 2/10] [Batch 235/350] [D loss: 0.251395, acc:  48%] [G loss: 1.218699] time: 1:38:38.213179\n",
      "[Epoch 2/10] [Batch 236/350] [D loss: 0.251450, acc:  45%] [G loss: 1.135744] time: 1:38:44.490427\n",
      "[Epoch 2/10] [Batch 237/350] [D loss: 0.251484, acc:  48%] [G loss: 1.233541] time: 1:38:50.761627\n",
      "[Epoch 2/10] [Batch 238/350] [D loss: 0.251282, acc:  50%] [G loss: 1.180916] time: 1:38:57.017898\n",
      "[Epoch 2/10] [Batch 239/350] [D loss: 0.251133, acc:  47%] [G loss: 1.165043] time: 1:39:03.286172\n",
      "[Epoch 2/10] [Batch 240/350] [D loss: 0.251347, acc:  47%] [G loss: 1.270191] time: 1:39:09.579312\n",
      "[Epoch 2/10] [Batch 241/350] [D loss: 0.251392, acc:  48%] [G loss: 1.231459] time: 1:39:15.839573\n",
      "[Epoch 2/10] [Batch 242/350] [D loss: 0.251324, acc:  45%] [G loss: 1.147859] time: 1:39:22.095877\n",
      "[Epoch 2/10] [Batch 243/350] [D loss: 0.251893, acc:  41%] [G loss: 1.476962] time: 1:39:28.387024\n",
      "[Epoch 2/10] [Batch 244/350] [D loss: 0.251660, acc:  48%] [G loss: 1.127061] time: 1:39:34.659254\n",
      "[Epoch 2/10] [Batch 245/350] [D loss: 0.251344, acc:  50%] [G loss: 1.347997] time: 1:39:40.941488\n",
      "[Epoch 2/10] [Batch 246/350] [D loss: 0.251336, acc:  53%] [G loss: 1.252739] time: 1:39:47.245600\n",
      "[Epoch 2/10] [Batch 247/350] [D loss: 0.251511, acc:  47%] [G loss: 1.140053] time: 1:39:53.517829\n",
      "[Epoch 2/10] [Batch 248/350] [D loss: 0.251325, acc:  45%] [G loss: 1.369652] time: 1:39:59.746176\n",
      "[Epoch 2/10] [Batch 249/350] [D loss: 0.251318, acc:  51%] [G loss: 1.477752] time: 1:40:06.015413\n",
      "[Epoch 2/10] [Batch 250/350] [D loss: 0.251426, acc:  47%] [G loss: 1.331387] time: 1:40:12.277669\n",
      "[Epoch 2/10] [Batch 251/350] [D loss: 0.251278, acc:  51%] [G loss: 1.142580] time: 1:40:18.538962\n",
      "[Epoch 2/10] [Batch 252/350] [D loss: 0.251497, acc:  49%] [G loss: 1.093611] time: 1:40:24.834096\n",
      "[Epoch 2/10] [Batch 253/350] [D loss: 0.251381, acc:  51%] [G loss: 1.340629] time: 1:40:31.100373\n",
      "[Epoch 2/10] [Batch 254/350] [D loss: 0.251435, acc:  47%] [G loss: 1.184065] time: 1:40:37.379552\n",
      "[Epoch 2/10] [Batch 255/350] [D loss: 0.251341, acc:  48%] [G loss: 1.205576] time: 1:40:43.638816\n",
      "[Epoch 2/10] [Batch 256/350] [D loss: 0.251525, acc:  43%] [G loss: 1.100483] time: 1:40:49.926005\n",
      "[Epoch 2/10] [Batch 257/350] [D loss: 0.251380, acc:  47%] [G loss: 1.313274] time: 1:40:56.208208\n",
      "[Epoch 2/10] [Batch 258/350] [D loss: 0.251190, acc:  46%] [G loss: 1.248597] time: 1:41:02.452512\n",
      "[Epoch 2/10] [Batch 259/350] [D loss: 0.251043, acc:  46%] [G loss: 1.010244] time: 1:41:08.732752\n",
      "[Epoch 2/10] [Batch 260/350] [D loss: 0.251096, acc:  49%] [G loss: 1.147029] time: 1:41:15.001957\n",
      "[Epoch 2/10] [Batch 261/350] [D loss: 0.251278, acc:  49%] [G loss: 1.091681] time: 1:41:21.251248\n",
      "[Epoch 2/10] [Batch 262/350] [D loss: 0.251251, acc:  46%] [G loss: 1.467201] time: 1:41:27.519517\n",
      "[Epoch 2/10] [Batch 263/350] [D loss: 0.251281, acc:  47%] [G loss: 1.208206] time: 1:41:33.802688\n",
      "[Epoch 2/10] [Batch 264/350] [D loss: 0.251271, acc:  47%] [G loss: 1.198711] time: 1:41:40.083894\n",
      "[Epoch 2/10] [Batch 265/350] [D loss: 0.251560, acc:  47%] [G loss: 1.060543] time: 1:41:46.369120\n",
      "[Epoch 2/10] [Batch 266/350] [D loss: 0.251662, acc:  50%] [G loss: 1.113513] time: 1:41:52.629350\n",
      "[Epoch 2/10] [Batch 267/350] [D loss: 0.251469, acc:  50%] [G loss: 1.079400] time: 1:41:58.904570\n",
      "[Epoch 2/10] [Batch 268/350] [D loss: 0.251696, acc:  51%] [G loss: 1.233698] time: 1:42:05.149872\n",
      "[Epoch 2/10] [Batch 269/350] [D loss: 0.251744, acc:  47%] [G loss: 1.230191] time: 1:42:11.412159\n",
      "[Epoch 2/10] [Batch 270/350] [D loss: 0.251523, acc:  38%] [G loss: 1.302270] time: 1:42:17.767167\n",
      "[Epoch 2/10] [Batch 271/350] [D loss: 0.251482, acc:  49%] [G loss: 1.064412] time: 1:42:24.068319\n",
      "[Epoch 2/10] [Batch 272/350] [D loss: 0.251470, acc:  48%] [G loss: 1.257260] time: 1:42:30.353483\n",
      "[Epoch 2/10] [Batch 273/350] [D loss: 0.251252, acc:  49%] [G loss: 1.357237] time: 1:42:36.639706\n",
      "[Epoch 2/10] [Batch 274/350] [D loss: 0.251072, acc:  50%] [G loss: 1.370378] time: 1:42:42.904923\n",
      "[Epoch 2/10] [Batch 275/350] [D loss: 0.251527, acc:  49%] [G loss: 1.245142] time: 1:42:49.181173\n",
      "[Epoch 2/10] [Batch 276/350] [D loss: 0.251435, acc:  54%] [G loss: 1.109603] time: 1:42:55.435419\n",
      "[Epoch 2/10] [Batch 277/350] [D loss: 0.251600, acc:  48%] [G loss: 1.084962] time: 1:43:01.698672\n",
      "[Epoch 2/10] [Batch 278/350] [D loss: 0.251313, acc:  47%] [G loss: 1.167932] time: 1:43:07.969904\n",
      "[Epoch 2/10] [Batch 279/350] [D loss: 0.251358, acc:  47%] [G loss: 1.198769] time: 1:43:14.246122\n",
      "[Epoch 2/10] [Batch 280/350] [D loss: 0.251225, acc:  48%] [G loss: 1.170473] time: 1:43:20.507382\n",
      "[Epoch 2/10] [Batch 281/350] [D loss: 0.251269, acc:  48%] [G loss: 1.149513] time: 1:43:26.805541\n",
      "[Epoch 2/10] [Batch 282/350] [D loss: 0.251528, acc:  50%] [G loss: 1.243093] time: 1:43:33.055829\n",
      "[Epoch 2/10] [Batch 283/350] [D loss: 0.251646, acc:  46%] [G loss: 1.089850] time: 1:43:39.330054\n",
      "[Epoch 2/10] [Batch 284/350] [D loss: 0.251703, acc:  49%] [G loss: 1.152706] time: 1:43:45.641178\n",
      "[Epoch 2/10] [Batch 285/350] [D loss: 0.251350, acc:  46%] [G loss: 1.114178] time: 1:43:51.912411\n",
      "[Epoch 2/10] [Batch 286/350] [D loss: 0.251252, acc:  47%] [G loss: 1.105245] time: 1:43:58.173669\n",
      "[Epoch 2/10] [Batch 287/350] [D loss: 0.251089, acc:  47%] [G loss: 1.167825] time: 1:44:04.449920\n",
      "[Epoch 2/10] [Batch 288/350] [D loss: 0.251340, acc:  47%] [G loss: 1.236580] time: 1:44:10.737077\n",
      "[Epoch 2/10] [Batch 289/350] [D loss: 0.251398, acc:  53%] [G loss: 1.391047] time: 1:44:16.974401\n",
      "[Epoch 2/10] [Batch 290/350] [D loss: 0.251423, acc:  49%] [G loss: 1.071116] time: 1:44:23.276549\n",
      "[Epoch 2/10] [Batch 291/350] [D loss: 0.251592, acc:  45%] [G loss: 1.315866] time: 1:44:29.551771\n",
      "[Epoch 2/10] [Batch 292/350] [D loss: 0.251366, acc:  49%] [G loss: 1.112534] time: 1:44:35.828987\n",
      "[Epoch 2/10] [Batch 293/350] [D loss: 0.251312, acc:  48%] [G loss: 1.491000] time: 1:44:42.293701\n",
      "[Epoch 2/10] [Batch 294/350] [D loss: 0.251396, acc:  53%] [G loss: 1.218341] time: 1:44:48.571915\n",
      "[Epoch 2/10] [Batch 295/350] [D loss: 0.251570, acc:  49%] [G loss: 1.169966] time: 1:44:54.812229\n",
      "[Epoch 2/10] [Batch 296/350] [D loss: 0.251309, acc:  45%] [G loss: 1.251275] time: 1:45:01.083493\n",
      "[Epoch 2/10] [Batch 297/350] [D loss: 0.251181, acc:  49%] [G loss: 1.205879] time: 1:45:07.334758\n",
      "[Epoch 2/10] [Batch 298/350] [D loss: 0.251257, acc:  50%] [G loss: 1.232345] time: 1:45:13.590021\n",
      "[Epoch 2/10] [Batch 299/350] [D loss: 0.251299, acc:  49%] [G loss: 1.442272] time: 1:45:19.855301\n",
      "[Epoch 2/10] [Batch 300/350] [D loss: 0.251675, acc:  48%] [G loss: 1.419149] time: 1:45:26.137472\n",
      "[Epoch 2/10] [Batch 301/350] [D loss: 0.251890, acc:  49%] [G loss: 1.357410] time: 1:45:32.397733\n",
      "[Epoch 2/10] [Batch 302/350] [D loss: 0.251762, acc:  49%] [G loss: 1.097284] time: 1:45:38.648021\n",
      "[Epoch 2/10] [Batch 303/350] [D loss: 0.251483, acc:  52%] [G loss: 1.162368] time: 1:45:44.986106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/10] [Batch 304/350] [D loss: 0.251877, acc:  47%] [G loss: 1.014306] time: 1:45:51.274292\n",
      "[Epoch 2/10] [Batch 305/350] [D loss: 0.251868, acc:  50%] [G loss: 1.138414] time: 1:45:57.531531\n",
      "[Epoch 2/10] [Batch 306/350] [D loss: 0.251274, acc:  49%] [G loss: 1.148926] time: 1:46:03.814731\n",
      "[Epoch 2/10] [Batch 307/350] [D loss: 0.251281, acc:  47%] [G loss: 1.276605] time: 1:46:10.075989\n",
      "[Epoch 2/10] [Batch 308/350] [D loss: 0.251201, acc:  48%] [G loss: 1.194409] time: 1:46:16.335285\n",
      "[Epoch 2/10] [Batch 309/350] [D loss: 0.251233, acc:  48%] [G loss: 1.199515] time: 1:46:22.615461\n",
      "[Epoch 2/10] [Batch 310/350] [D loss: 0.251296, acc:  47%] [G loss: 1.224649] time: 1:46:28.892709\n",
      "[Epoch 2/10] [Batch 311/350] [D loss: 0.251121, acc:  46%] [G loss: 1.273026] time: 1:46:35.176909\n",
      "[Epoch 2/10] [Batch 312/350] [D loss: 0.252068, acc:  50%] [G loss: 1.150464] time: 1:46:41.417189\n",
      "[Epoch 2/10] [Batch 313/350] [D loss: 0.252008, acc:  49%] [G loss: 1.012935] time: 1:46:47.682437\n",
      "[Epoch 2/10] [Batch 314/350] [D loss: 0.252325, acc:  48%] [G loss: 1.289349] time: 1:46:53.954666\n",
      "[Epoch 2/10] [Batch 315/350] [D loss: 0.251845, acc:  46%] [G loss: 1.223839] time: 1:47:00.212933\n",
      "[Epoch 2/10] [Batch 316/350] [D loss: 0.251853, acc:  52%] [G loss: 1.302630] time: 1:47:06.472231\n",
      "[Epoch 2/10] [Batch 317/350] [D loss: 0.252660, acc:  51%] [G loss: 1.246611] time: 1:47:12.736448\n",
      "[Epoch 2/10] [Batch 318/350] [D loss: 0.252282, acc:  46%] [G loss: 1.252129] time: 1:47:18.982747\n",
      "[Epoch 2/10] [Batch 319/350] [D loss: 0.251368, acc:  50%] [G loss: 1.140357] time: 1:47:25.241014\n",
      "[Epoch 2/10] [Batch 320/350] [D loss: 0.251614, acc:  48%] [G loss: 1.163060] time: 1:47:31.513243\n",
      "[Epoch 2/10] [Batch 321/350] [D loss: 0.251928, acc:  48%] [G loss: 1.201609] time: 1:47:37.787467\n",
      "[Epoch 2/10] [Batch 322/350] [D loss: 0.251506, acc:  47%] [G loss: 1.353500] time: 1:47:44.093605\n",
      "[Epoch 2/10] [Batch 323/350] [D loss: 0.251409, acc:  51%] [G loss: 1.208857] time: 1:47:50.376805\n",
      "[Epoch 2/10] [Batch 324/350] [D loss: 0.251376, acc:  48%] [G loss: 1.160111] time: 1:47:56.658010\n",
      "[Epoch 2/10] [Batch 325/350] [D loss: 0.251240, acc:  45%] [G loss: 1.299628] time: 1:48:02.916277\n",
      "[Epoch 2/10] [Batch 326/350] [D loss: 0.251650, acc:  51%] [G loss: 1.214587] time: 1:48:09.145654\n",
      "[Epoch 2/10] [Batch 327/350] [D loss: 0.251537, acc:  44%] [G loss: 1.164582] time: 1:48:15.412864\n",
      "[Epoch 2/10] [Batch 328/350] [D loss: 0.251509, acc:  46%] [G loss: 1.127424] time: 1:48:21.703079\n",
      "[Epoch 2/10] [Batch 329/350] [D loss: 0.251264, acc:  47%] [G loss: 1.216561] time: 1:48:27.985248\n",
      "[Epoch 2/10] [Batch 330/350] [D loss: 0.251304, acc:  49%] [G loss: 1.248469] time: 1:48:34.244512\n",
      "[Epoch 2/10] [Batch 331/350] [D loss: 0.251362, acc:  47%] [G loss: 1.408687] time: 1:48:40.503810\n",
      "[Epoch 2/10] [Batch 332/350] [D loss: 0.251555, acc:  45%] [G loss: 1.284983] time: 1:48:46.757056\n",
      "[Epoch 2/10] [Batch 333/350] [D loss: 0.251525, acc:  46%] [G loss: 1.098569] time: 1:48:53.029285\n",
      "[Epoch 2/10] [Batch 334/350] [D loss: 0.251372, acc:  46%] [G loss: 1.125955] time: 1:48:59.295530\n",
      "[Epoch 2/10] [Batch 335/350] [D loss: 0.251552, acc:  43%] [G loss: 1.260698] time: 1:49:05.566762\n",
      "[Epoch 2/10] [Batch 336/350] [D loss: 0.251574, acc:  49%] [G loss: 1.242765] time: 1:49:11.836997\n",
      "[Epoch 2/10] [Batch 337/350] [D loss: 0.251299, acc:  51%] [G loss: 1.151145] time: 1:49:18.110224\n",
      "[Epoch 2/10] [Batch 338/350] [D loss: 0.251255, acc:  49%] [G loss: 1.320802] time: 1:49:24.383451\n",
      "[Epoch 2/10] [Batch 339/350] [D loss: 0.251032, acc:  46%] [G loss: 1.094630] time: 1:49:30.663658\n",
      "[Epoch 2/10] [Batch 340/350] [D loss: 0.251504, acc:  40%] [G loss: 1.040208] time: 1:49:36.946859\n",
      "[Epoch 2/10] [Batch 341/350] [D loss: 0.251586, acc:  48%] [G loss: 1.086000] time: 1:49:43.237040\n",
      "[Epoch 2/10] [Batch 342/350] [D loss: 0.251532, acc:  43%] [G loss: 1.459411] time: 1:49:49.490320\n",
      "[Epoch 2/10] [Batch 343/350] [D loss: 0.251579, acc:  47%] [G loss: 1.164420] time: 1:49:55.758560\n",
      "[Epoch 2/10] [Batch 344/350] [D loss: 0.251960, acc:  46%] [G loss: 1.320065] time: 1:50:02.017856\n",
      "[Epoch 2/10] [Batch 345/350] [D loss: 0.251789, acc:  51%] [G loss: 1.157994] time: 1:50:08.290087\n",
      "[Epoch 2/10] [Batch 346/350] [D loss: 0.251606, acc:  47%] [G loss: 1.149693] time: 1:50:14.555302\n",
      "[Epoch 2/10] [Batch 347/350] [D loss: 0.251820, acc:  54%] [G loss: 1.173071] time: 1:50:20.802597\n",
      "[Epoch 2/10] [Batch 348/350] [D loss: 0.251776, acc:  49%] [G loss: 1.089179] time: 1:50:27.073829\n",
      "weights saved...\n",
      "[Epoch 3/10] [Batch 0/350] [D loss: 0.251277, acc:  48%] [G loss: 1.133031] time: 1:50:33.655264\n",
      "[Epoch 3/10] [Batch 1/350] [D loss: 0.251139, acc:  48%] [G loss: 1.105056] time: 1:50:45.464690\n",
      "[Epoch 3/10] [Batch 2/350] [D loss: 0.251358, acc:  47%] [G loss: 1.251117] time: 1:50:51.734891\n",
      "[Epoch 3/10] [Batch 3/350] [D loss: 0.251660, acc:  52%] [G loss: 1.411757] time: 1:50:57.984181\n",
      "[Epoch 3/10] [Batch 4/350] [D loss: 0.251593, acc:  49%] [G loss: 1.301780] time: 1:51:04.241482\n",
      "[Epoch 3/10] [Batch 5/350] [D loss: 0.251324, acc:  51%] [G loss: 1.294574] time: 1:51:10.510720\n",
      "[Epoch 3/10] [Batch 6/350] [D loss: 0.251576, acc:  41%] [G loss: 1.278537] time: 1:51:16.794886\n",
      "[Epoch 3/10] [Batch 7/350] [D loss: 0.251444, acc:  46%] [G loss: 1.244927] time: 1:51:23.044208\n",
      "[Epoch 3/10] [Batch 8/350] [D loss: 0.251570, acc:  44%] [G loss: 1.068123] time: 1:51:29.338379\n",
      "[Epoch 3/10] [Batch 9/350] [D loss: 0.251729, acc:  49%] [G loss: 1.174664] time: 1:51:35.588635\n",
      "[Epoch 3/10] [Batch 10/350] [D loss: 0.251556, acc:  43%] [G loss: 1.282981] time: 1:51:41.878816\n",
      "[Epoch 3/10] [Batch 11/350] [D loss: 0.251843, acc:  50%] [G loss: 1.422487] time: 1:51:48.136085\n",
      "[Epoch 3/10] [Batch 12/350] [D loss: 0.252198, acc:  51%] [G loss: 1.179731] time: 1:51:54.409317\n",
      "[Epoch 3/10] [Batch 13/350] [D loss: 0.252041, acc:  47%] [G loss: 1.081319] time: 1:52:00.657605\n",
      "[Epoch 3/10] [Batch 14/350] [D loss: 0.251255, acc:  47%] [G loss: 1.111677] time: 1:52:06.920859\n",
      "[Epoch 3/10] [Batch 15/350] [D loss: 0.251261, acc:  49%] [G loss: 1.095524] time: 1:52:13.201066\n",
      "[Epoch 3/10] [Batch 16/350] [D loss: 0.251280, acc:  46%] [G loss: 1.073854] time: 1:52:19.473328\n",
      "[Epoch 3/10] [Batch 17/350] [D loss: 0.251358, acc:  50%] [G loss: 1.497960] time: 1:52:25.719626\n",
      "[Epoch 3/10] [Batch 18/350] [D loss: 0.251338, acc:  48%] [G loss: 1.253940] time: 1:52:32.002795\n",
      "[Epoch 3/10] [Batch 19/350] [D loss: 0.251343, acc:  46%] [G loss: 1.216301] time: 1:52:38.329877\n",
      "[Epoch 3/10] [Batch 20/350] [D loss: 0.251356, acc:  44%] [G loss: 1.383117] time: 1:52:44.665936\n",
      "[Epoch 3/10] [Batch 21/350] [D loss: 0.251460, acc:  49%] [G loss: 1.231401] time: 1:52:50.932213\n",
      "[Epoch 3/10] [Batch 22/350] [D loss: 0.251321, acc:  47%] [G loss: 1.092791] time: 1:52:57.269269\n",
      "[Epoch 3/10] [Batch 23/350] [D loss: 0.251037, acc:  47%] [G loss: 1.348049] time: 1:53:03.634250\n",
      "[Epoch 3/10] [Batch 24/350] [D loss: 0.251327, acc:  48%] [G loss: 1.102069] time: 1:53:09.910437\n",
      "[Epoch 3/10] [Batch 25/350] [D loss: 0.251225, acc:  45%] [G loss: 1.119620] time: 1:53:16.272426\n",
      "[Epoch 3/10] [Batch 26/350] [D loss: 0.251207, acc:  48%] [G loss: 1.174690] time: 1:53:22.614469\n",
      "[Epoch 3/10] [Batch 27/350] [D loss: 0.251261, acc:  46%] [G loss: 1.230179] time: 1:53:28.933573\n",
      "[Epoch 3/10] [Batch 28/350] [D loss: 0.251411, acc:  42%] [G loss: 1.112340] time: 1:53:35.274650\n",
      "[Epoch 3/10] [Batch 29/350] [D loss: 0.251323, acc:  46%] [G loss: 1.165873] time: 1:53:41.625637\n",
      "[Epoch 3/10] [Batch 30/350] [D loss: 0.251208, acc:  49%] [G loss: 1.120681] time: 1:53:48.000592\n",
      "[Epoch 3/10] [Batch 31/350] [D loss: 0.251154, acc:  47%] [G loss: 1.194051] time: 1:53:54.320693\n",
      "[Epoch 3/10] [Batch 32/350] [D loss: 0.251201, acc:  46%] [G loss: 1.156943] time: 1:54:00.778427\n",
      "[Epoch 3/10] [Batch 33/350] [D loss: 0.251230, acc:  47%] [G loss: 1.195178] time: 1:54:07.218208\n",
      "[Epoch 3/10] [Batch 34/350] [D loss: 0.251429, acc:  51%] [G loss: 1.146886] time: 1:54:13.608154\n",
      "[Epoch 3/10] [Batch 35/350] [D loss: 0.251344, acc:  51%] [G loss: 1.022342] time: 1:54:19.901297\n",
      "[Epoch 3/10] [Batch 36/350] [D loss: 0.251234, acc:  50%] [G loss: 1.023948] time: 1:54:26.222395\n",
      "[Epoch 3/10] [Batch 37/350] [D loss: 0.251241, acc:  48%] [G loss: 1.289169] time: 1:54:32.535515\n",
      "[Epoch 3/10] [Batch 38/350] [D loss: 0.251499, acc:  48%] [G loss: 1.307346] time: 1:54:38.834672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/10] [Batch 39/350] [D loss: 0.251276, acc:  48%] [G loss: 1.157353] time: 1:54:45.113883\n",
      "[Epoch 3/10] [Batch 40/350] [D loss: 0.251349, acc:  47%] [G loss: 1.294454] time: 1:54:51.426006\n",
      "[Epoch 3/10] [Batch 41/350] [D loss: 0.251715, acc:  46%] [G loss: 1.274419] time: 1:54:57.778022\n",
      "[Epoch 3/10] [Batch 42/350] [D loss: 0.251434, acc:  50%] [G loss: 1.050223] time: 1:55:04.074187\n",
      "[Epoch 3/10] [Batch 43/350] [D loss: 0.251594, acc:  48%] [G loss: 1.246764] time: 1:55:10.371349\n",
      "[Epoch 3/10] [Batch 44/350] [D loss: 0.251331, acc:  46%] [G loss: 1.222144] time: 1:55:16.672502\n",
      "[Epoch 3/10] [Batch 45/350] [D loss: 0.251522, acc:  48%] [G loss: 1.186008] time: 1:55:22.992602\n",
      "[Epoch 3/10] [Batch 46/350] [D loss: 0.251116, acc:  48%] [G loss: 1.074885] time: 1:55:29.285777\n",
      "[Epoch 3/10] [Batch 47/350] [D loss: 0.251133, acc:  47%] [G loss: 1.187333] time: 1:55:35.583936\n",
      "[Epoch 3/10] [Batch 48/350] [D loss: 0.251253, acc:  46%] [G loss: 1.254107] time: 1:55:41.923984\n",
      "[Epoch 3/10] [Batch 49/350] [D loss: 0.251228, acc:  49%] [G loss: 1.038929] time: 1:55:48.241094\n",
      "[Epoch 3/10] [Batch 50/350] [D loss: 0.251216, acc:  49%] [G loss: 1.067944] time: 1:55:54.524294\n",
      "[Epoch 3/10] [Batch 51/350] [D loss: 0.251501, acc:  45%] [G loss: 1.051835] time: 1:56:00.823451\n",
      "[Epoch 3/10] [Batch 52/350] [D loss: 0.251511, acc:  49%] [G loss: 1.048767] time: 1:56:07.120613\n",
      "[Epoch 3/10] [Batch 53/350] [D loss: 0.251620, acc:  51%] [G loss: 1.031264] time: 1:56:13.430741\n",
      "[Epoch 3/10] [Batch 54/350] [D loss: 0.251365, acc:  52%] [G loss: 1.213109] time: 1:56:19.709953\n",
      "[Epoch 3/10] [Batch 55/350] [D loss: 0.251357, acc:  50%] [G loss: 1.147908] time: 1:56:26.011104\n",
      "[Epoch 3/10] [Batch 56/350] [D loss: 0.251105, acc:  49%] [G loss: 1.363500] time: 1:56:32.297297\n",
      "[Epoch 3/10] [Batch 57/350] [D loss: 0.251341, acc:  56%] [G loss: 1.235627] time: 1:56:38.556560\n",
      "[Epoch 3/10] [Batch 58/350] [D loss: 0.251432, acc:  51%] [G loss: 1.295755] time: 1:56:44.851728\n",
      "[Epoch 3/10] [Batch 59/350] [D loss: 0.251406, acc:  52%] [G loss: 1.230984] time: 1:56:51.142907\n",
      "[Epoch 3/10] [Batch 60/350] [D loss: 0.251612, acc:  51%] [G loss: 1.259729] time: 1:56:57.427104\n",
      "[Epoch 3/10] [Batch 61/350] [D loss: 0.251598, acc:  47%] [G loss: 1.413475] time: 1:57:03.724267\n",
      "[Epoch 3/10] [Batch 62/350] [D loss: 0.251397, acc:  42%] [G loss: 1.212268] time: 1:57:09.994501\n",
      "[Epoch 3/10] [Batch 63/350] [D loss: 0.251380, acc:  49%] [G loss: 1.278095] time: 1:57:16.306624\n",
      "[Epoch 3/10] [Batch 64/350] [D loss: 0.251330, acc:  47%] [G loss: 1.393074] time: 1:57:22.590821\n",
      "[Epoch 3/10] [Batch 65/350] [D loss: 0.251634, acc:  45%] [G loss: 1.197337] time: 1:57:28.903941\n",
      "[Epoch 3/10] [Batch 66/350] [D loss: 0.251393, acc:  49%] [G loss: 1.172412] time: 1:57:35.207088\n",
      "[Epoch 3/10] [Batch 67/350] [D loss: 0.251453, acc:  49%] [G loss: 1.327946] time: 1:57:41.519243\n",
      "[Epoch 3/10] [Batch 68/350] [D loss: 0.251817, acc:  47%] [G loss: 1.126455] time: 1:57:47.829339\n",
      "[Epoch 3/10] [Batch 69/350] [D loss: 0.251911, acc:  46%] [G loss: 1.303277] time: 1:57:54.119520\n",
      "[Epoch 3/10] [Batch 70/350] [D loss: 0.252037, acc:  48%] [G loss: 1.236559] time: 1:58:00.393744\n",
      "[Epoch 3/10] [Batch 71/350] [D loss: 0.251666, acc:  48%] [G loss: 1.223725] time: 1:58:06.676944\n",
      "[Epoch 3/10] [Batch 72/350] [D loss: 0.251838, acc:  51%] [G loss: 1.223189] time: 1:58:12.955157\n",
      "[Epoch 3/10] [Batch 73/350] [D loss: 0.251781, acc:  50%] [G loss: 1.186889] time: 1:58:19.244341\n",
      "[Epoch 3/10] [Batch 74/350] [D loss: 0.251939, acc:  48%] [G loss: 1.420563] time: 1:58:25.536517\n",
      "[Epoch 3/10] [Batch 75/350] [D loss: 0.252564, acc:  48%] [G loss: 1.298206] time: 1:58:31.807750\n",
      "[Epoch 3/10] [Batch 76/350] [D loss: 0.252416, acc:  48%] [G loss: 1.554052] time: 1:58:38.096933\n",
      "[Epoch 3/10] [Batch 77/350] [D loss: 0.251619, acc:  51%] [G loss: 1.203218] time: 1:58:44.385120\n",
      "[Epoch 3/10] [Batch 78/350] [D loss: 0.251922, acc:  53%] [G loss: 1.204462] time: 1:58:50.657381\n",
      "[Epoch 3/10] [Batch 79/350] [D loss: 0.251703, acc:  48%] [G loss: 1.375068] time: 1:58:56.961493\n",
      "[Epoch 3/10] [Batch 80/350] [D loss: 0.251731, acc:  50%] [G loss: 1.285431] time: 1:59:03.260651\n",
      "[Epoch 3/10] [Batch 81/350] [D loss: 0.252509, acc:  53%] [G loss: 1.375425] time: 1:59:09.540859\n",
      "[Epoch 3/10] [Batch 82/350] [D loss: 0.252534, acc:  50%] [G loss: 1.085703] time: 1:59:15.827051\n",
      "[Epoch 3/10] [Batch 83/350] [D loss: 0.252113, acc:  50%] [G loss: 1.301069] time: 1:59:22.123216\n",
      "[Epoch 3/10] [Batch 84/350] [D loss: 0.252304, acc:  46%] [G loss: 1.486289] time: 1:59:28.406417\n",
      "[Epoch 3/10] [Batch 85/350] [D loss: 0.251954, acc:  46%] [G loss: 1.309852] time: 1:59:34.694603\n",
      "[Epoch 3/10] [Batch 86/350] [D loss: 0.251723, acc:  49%] [G loss: 1.132257] time: 1:59:40.978800\n",
      "[Epoch 3/10] [Batch 87/350] [D loss: 0.252276, acc:  52%] [G loss: 1.432473] time: 1:59:47.271973\n",
      "[Epoch 3/10] [Batch 88/350] [D loss: 0.252086, acc:  50%] [G loss: 1.101795] time: 1:59:53.571164\n",
      "[Epoch 3/10] [Batch 89/350] [D loss: 0.251368, acc:  52%] [G loss: 1.216642] time: 1:59:59.870288\n",
      "[Epoch 3/10] [Batch 90/350] [D loss: 0.251329, acc:  50%] [G loss: 1.149647] time: 2:00:06.162495\n",
      "[Epoch 3/10] [Batch 91/350] [D loss: 0.251258, acc:  48%] [G loss: 1.071659] time: 2:00:12.434693\n",
      "[Epoch 3/10] [Batch 92/350] [D loss: 0.251434, acc:  47%] [G loss: 1.113868] time: 2:00:18.724875\n",
      "[Epoch 3/10] [Batch 93/350] [D loss: 0.251202, acc:  49%] [G loss: 1.169956] time: 2:00:25.029019\n",
      "[Epoch 3/10] [Batch 94/350] [D loss: 0.251232, acc:  48%] [G loss: 1.243049] time: 2:00:31.310224\n",
      "[Epoch 3/10] [Batch 95/350] [D loss: 0.251194, acc:  47%] [G loss: 1.222603] time: 2:00:37.605392\n",
      "[Epoch 3/10] [Batch 96/350] [D loss: 0.251228, acc:  51%] [G loss: 1.091055] time: 2:00:43.882608\n",
      "[Epoch 3/10] [Batch 97/350] [D loss: 0.251280, acc:  49%] [G loss: 1.366420] time: 2:00:50.159824\n",
      "[Epoch 3/10] [Batch 98/350] [D loss: 0.251320, acc:  48%] [G loss: 1.113606] time: 2:00:56.424074\n",
      "[Epoch 3/10] [Batch 99/350] [D loss: 0.251172, acc:  45%] [G loss: 1.189832] time: 2:01:02.723232\n",
      "[Epoch 3/10] [Batch 100/350] [D loss: 0.251245, acc:  52%] [G loss: 1.291226] time: 2:01:08.987516\n",
      "[Epoch 3/10] [Batch 101/350] [D loss: 0.251478, acc:  50%] [G loss: 1.106445] time: 2:01:15.277664\n",
      "[Epoch 3/10] [Batch 102/350] [D loss: 0.252301, acc:  56%] [G loss: 1.388176] time: 2:01:21.543909\n",
      "[Epoch 3/10] [Batch 103/350] [D loss: 0.252677, acc:  49%] [G loss: 1.316785] time: 2:01:27.850048\n",
      "[Epoch 3/10] [Batch 104/350] [D loss: 0.251974, acc:  52%] [G loss: 1.297742] time: 2:01:34.159179\n",
      "[Epoch 3/10] [Batch 105/350] [D loss: 0.251737, acc:  42%] [G loss: 1.224533] time: 2:01:40.477286\n",
      "[Epoch 3/10] [Batch 106/350] [D loss: 0.251846, acc:  50%] [G loss: 1.468715] time: 2:01:46.786416\n",
      "[Epoch 3/10] [Batch 107/350] [D loss: 0.251480, acc:  52%] [G loss: 1.045694] time: 2:01:53.096544\n",
      "[Epoch 3/10] [Batch 108/350] [D loss: 0.251676, acc:  47%] [G loss: 1.218095] time: 2:01:59.389718\n",
      "[Epoch 3/10] [Batch 109/350] [D loss: 0.252706, acc:  52%] [G loss: 1.207472] time: 2:02:05.687878\n",
      "[Epoch 3/10] [Batch 110/350] [D loss: 0.252348, acc:  48%] [G loss: 1.346786] time: 2:02:11.964096\n",
      "[Epoch 3/10] [Batch 111/350] [D loss: 0.251849, acc:  46%] [G loss: 1.189085] time: 2:02:18.298160\n",
      "[Epoch 3/10] [Batch 112/350] [D loss: 0.252712, acc:  50%] [G loss: 1.436274] time: 2:02:24.607290\n",
      "[Epoch 3/10] [Batch 113/350] [D loss: 0.252701, acc:  50%] [G loss: 1.199832] time: 2:02:30.896506\n",
      "[Epoch 3/10] [Batch 114/350] [D loss: 0.251736, acc:  46%] [G loss: 1.214412] time: 2:02:37.202614\n",
      "[Epoch 3/10] [Batch 115/350] [D loss: 0.252226, acc:  47%] [G loss: 1.382373] time: 2:02:43.501771\n",
      "[Epoch 3/10] [Batch 116/350] [D loss: 0.252390, acc:  54%] [G loss: 1.274191] time: 2:02:49.791984\n",
      "[Epoch 3/10] [Batch 117/350] [D loss: 0.251843, acc:  52%] [G loss: 1.190774] time: 2:02:56.068171\n",
      "[Epoch 3/10] [Batch 118/350] [D loss: 0.252698, acc:  49%] [G loss: 1.297295] time: 2:03:02.352368\n",
      "[Epoch 3/10] [Batch 119/350] [D loss: 0.251778, acc:  44%] [G loss: 1.236714] time: 2:03:08.644544\n",
      "[Epoch 3/10] [Batch 120/350] [D loss: 0.251465, acc:  53%] [G loss: 1.248501] time: 2:03:14.942704\n",
      "[Epoch 3/10] [Batch 121/350] [D loss: 0.251571, acc:  50%] [G loss: 1.173425] time: 2:03:21.209947\n",
      "[Epoch 3/10] [Batch 122/350] [D loss: 0.251439, acc:  45%] [G loss: 1.198722] time: 2:03:27.491152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/10] [Batch 123/350] [D loss: 0.251724, acc:  50%] [G loss: 1.151904] time: 2:03:33.785323\n",
      "[Epoch 3/10] [Batch 124/350] [D loss: 0.252196, acc:  50%] [G loss: 1.176420] time: 2:03:40.081520\n",
      "[Epoch 3/10] [Batch 125/350] [D loss: 0.251937, acc:  48%] [G loss: 1.108673] time: 2:03:46.379649\n",
      "[Epoch 3/10] [Batch 126/350] [D loss: 0.251563, acc:  47%] [G loss: 1.274590] time: 2:03:52.665840\n",
      "[Epoch 3/10] [Batch 127/350] [D loss: 0.251948, acc:  53%] [G loss: 1.264686] time: 2:03:58.949040\n",
      "[Epoch 3/10] [Batch 128/350] [D loss: 0.252218, acc:  50%] [G loss: 1.098827] time: 2:04:05.255179\n",
      "[Epoch 3/10] [Batch 129/350] [D loss: 0.251601, acc:  48%] [G loss: 1.262365] time: 2:04:11.544363\n",
      "[Epoch 3/10] [Batch 130/350] [D loss: 0.251990, acc:  48%] [G loss: 1.275494] time: 2:04:17.830555\n",
      "[Epoch 3/10] [Batch 131/350] [D loss: 0.251867, acc:  50%] [G loss: 1.140262] time: 2:04:24.149659\n",
      "[Epoch 3/10] [Batch 132/350] [D loss: 0.251499, acc:  48%] [G loss: 1.128429] time: 2:04:30.492698\n",
      "[Epoch 3/10] [Batch 133/350] [D loss: 0.252272, acc:  48%] [G loss: 1.284158] time: 2:04:36.837733\n",
      "[Epoch 3/10] [Batch 134/350] [D loss: 0.252070, acc:  47%] [G loss: 1.210704] time: 2:04:43.106004\n",
      "[Epoch 3/10] [Batch 135/350] [D loss: 0.251312, acc:  43%] [G loss: 1.342590] time: 2:04:49.385184\n",
      "[Epoch 3/10] [Batch 136/350] [D loss: 0.251120, acc:  47%] [G loss: 1.143792] time: 2:04:55.664395\n",
      "[Epoch 3/10] [Batch 137/350] [D loss: 0.251093, acc:  47%] [G loss: 1.328036] time: 2:05:01.974522\n",
      "[Epoch 3/10] [Batch 138/350] [D loss: 0.251334, acc:  54%] [G loss: 1.423617] time: 2:05:08.256725\n",
      "[Epoch 3/10] [Batch 139/350] [D loss: 0.251772, acc:  53%] [G loss: 1.135204] time: 2:05:14.552890\n",
      "[Epoch 3/10] [Batch 140/350] [D loss: 0.251778, acc:  49%] [G loss: 1.279016] time: 2:05:20.844069\n",
      "[Epoch 3/10] [Batch 141/350] [D loss: 0.251559, acc:  44%] [G loss: 1.161675] time: 2:05:27.115302\n",
      "[Epoch 3/10] [Batch 142/350] [D loss: 0.251587, acc:  49%] [G loss: 1.122931] time: 2:05:33.420443\n",
      "[Epoch 3/10] [Batch 143/350] [D loss: 0.251395, acc:  48%] [G loss: 1.267324] time: 2:05:39.691675\n",
      "[Epoch 3/10] [Batch 144/350] [D loss: 0.251319, acc:  49%] [G loss: 1.273386] time: 2:05:45.986843\n",
      "[Epoch 3/10] [Batch 145/350] [D loss: 0.251530, acc:  48%] [G loss: 1.439050] time: 2:05:52.272037\n",
      "[Epoch 3/10] [Batch 146/350] [D loss: 0.251347, acc:  47%] [G loss: 1.327133] time: 2:05:58.560224\n",
      "[Epoch 3/10] [Batch 147/350] [D loss: 0.251332, acc:  47%] [G loss: 1.300356] time: 2:06:04.857386\n",
      "[Epoch 3/10] [Batch 148/350] [D loss: 0.251935, acc:  41%] [G loss: 1.296836] time: 2:06:11.155547\n",
      "[Epoch 3/10] [Batch 149/350] [D loss: 0.251831, acc:  48%] [G loss: 1.056712] time: 2:06:17.451712\n",
      "[Epoch 3/10] [Batch 150/350] [D loss: 0.251492, acc:  51%] [G loss: 1.248265] time: 2:06:23.761840\n",
      "[Epoch 3/10] [Batch 151/350] [D loss: 0.251155, acc:  47%] [G loss: 1.150343] time: 2:06:30.043045\n",
      "[Epoch 3/10] [Batch 152/350] [D loss: 0.251167, acc:  47%] [G loss: 1.299489] time: 2:06:36.326245\n",
      "[Epoch 3/10] [Batch 153/350] [D loss: 0.251053, acc:  48%] [G loss: 1.125840] time: 2:06:42.621413\n",
      "[Epoch 3/10] [Batch 154/350] [D loss: 0.251473, acc:  50%] [G loss: 1.225761] time: 2:06:48.928549\n",
      "[Epoch 3/10] [Batch 155/350] [D loss: 0.251574, acc:  46%] [G loss: 1.164281] time: 2:06:55.225744\n",
      "[Epoch 3/10] [Batch 156/350] [D loss: 0.251575, acc:  46%] [G loss: 1.144320] time: 2:07:01.507946\n",
      "[Epoch 3/10] [Batch 157/350] [D loss: 0.251528, acc:  49%] [G loss: 1.173114] time: 2:07:07.786129\n",
      "[Epoch 3/10] [Batch 158/350] [D loss: 0.251421, acc:  50%] [G loss: 1.151971] time: 2:07:14.094262\n",
      "[Epoch 3/10] [Batch 159/350] [D loss: 0.251281, acc:  45%] [G loss: 1.333602] time: 2:07:20.390427\n",
      "[Epoch 3/10] [Batch 160/350] [D loss: 0.251342, acc:  51%] [G loss: 1.173416] time: 2:07:26.687589\n",
      "[Epoch 3/10] [Batch 161/350] [D loss: 0.251508, acc:  48%] [G loss: 1.247889] time: 2:07:32.960816\n",
      "[Epoch 3/10] [Batch 162/350] [D loss: 0.251336, acc:  47%] [G loss: 1.158827] time: 2:07:39.257978\n",
      "[Epoch 3/10] [Batch 163/350] [D loss: 0.251764, acc:  44%] [G loss: 1.201325] time: 2:07:45.596032\n",
      "[Epoch 3/10] [Batch 164/350] [D loss: 0.251781, acc:  48%] [G loss: 1.128054] time: 2:07:51.865270\n",
      "[Epoch 3/10] [Batch 165/350] [D loss: 0.251406, acc:  41%] [G loss: 1.158530] time: 2:07:58.145509\n",
      "[Epoch 3/10] [Batch 166/350] [D loss: 0.251341, acc:  48%] [G loss: 1.223763] time: 2:08:04.431669\n",
      "[Epoch 3/10] [Batch 167/350] [D loss: 0.251344, acc:  49%] [G loss: 1.010781] time: 2:08:10.724874\n",
      "[Epoch 3/10] [Batch 168/350] [D loss: 0.251465, acc:  50%] [G loss: 1.190603] time: 2:08:17.033973\n",
      "[Epoch 3/10] [Batch 169/350] [D loss: 0.252108, acc:  56%] [G loss: 0.990309] time: 2:08:23.297227\n",
      "[Epoch 3/10] [Batch 170/350] [D loss: 0.252438, acc:  49%] [G loss: 1.262124] time: 2:08:29.578464\n",
      "[Epoch 3/10] [Batch 171/350] [D loss: 0.251874, acc:  49%] [G loss: 1.216631] time: 2:08:35.874597\n",
      "[Epoch 3/10] [Batch 172/350] [D loss: 0.252383, acc:  54%] [G loss: 1.171254] time: 2:08:42.144832\n",
      "[Epoch 3/10] [Batch 173/350] [D loss: 0.253410, acc:  49%] [G loss: 1.422568] time: 2:08:48.428032\n",
      "[Epoch 3/10] [Batch 174/350] [D loss: 0.252279, acc:  50%] [G loss: 1.212771] time: 2:08:54.708241\n",
      "[Epoch 3/10] [Batch 175/350] [D loss: 0.252388, acc:  47%] [G loss: 1.303665] time: 2:09:01.003408\n",
      "[Epoch 3/10] [Batch 176/350] [D loss: 0.253422, acc:  49%] [G loss: 1.182209] time: 2:09:12.848736\n",
      "[Epoch 3/10] [Batch 177/350] [D loss: 0.252407, acc:  49%] [G loss: 1.278038] time: 2:09:19.127947\n",
      "[Epoch 3/10] [Batch 178/350] [D loss: 0.251221, acc:  49%] [G loss: 1.219405] time: 2:09:25.433089\n",
      "[Epoch 3/10] [Batch 179/350] [D loss: 0.251348, acc:  48%] [G loss: 1.139475] time: 2:09:31.720277\n",
      "[Epoch 3/10] [Batch 180/350] [D loss: 0.251411, acc:  47%] [G loss: 1.111245] time: 2:09:38.009461\n",
      "[Epoch 3/10] [Batch 181/350] [D loss: 0.251425, acc:  49%] [G loss: 1.199400] time: 2:09:44.340533\n",
      "[Epoch 3/10] [Batch 182/350] [D loss: 0.251399, acc:  47%] [G loss: 1.102624] time: 2:09:50.629718\n",
      "[Epoch 3/10] [Batch 183/350] [D loss: 0.251095, acc:  50%] [G loss: 1.310545] time: 2:09:56.917904\n",
      "[Epoch 3/10] [Batch 184/350] [D loss: 0.251246, acc:  50%] [G loss: 1.256351] time: 2:10:03.198112\n",
      "[Epoch 3/10] [Batch 185/350] [D loss: 0.251412, acc:  49%] [G loss: 0.999016] time: 2:10:09.498267\n",
      "[Epoch 3/10] [Batch 186/350] [D loss: 0.251284, acc:  46%] [G loss: 1.272189] time: 2:10:15.759525\n",
      "[Epoch 3/10] [Batch 187/350] [D loss: 0.251221, acc:  46%] [G loss: 1.249808] time: 2:10:22.058682\n",
      "[Epoch 3/10] [Batch 188/350] [D loss: 0.251405, acc:  47%] [G loss: 1.003452] time: 2:10:28.335899\n",
      "[Epoch 3/10] [Batch 189/350] [D loss: 0.251463, acc:  55%] [G loss: 1.151648] time: 2:10:34.681963\n",
      "[Epoch 3/10] [Batch 190/350] [D loss: 0.251373, acc:  51%] [G loss: 1.407818] time: 2:10:40.953162\n",
      "[Epoch 3/10] [Batch 191/350] [D loss: 0.251630, acc:  45%] [G loss: 1.250079] time: 2:10:47.290219\n",
      "[Epoch 3/10] [Batch 192/350] [D loss: 0.251465, acc:  44%] [G loss: 1.101305] time: 2:10:53.555467\n",
      "[Epoch 3/10] [Batch 193/350] [D loss: 0.251732, acc:  50%] [G loss: 1.201753] time: 2:10:59.860608\n",
      "[Epoch 3/10] [Batch 194/350] [D loss: 0.251703, acc:  49%] [G loss: 1.425135] time: 2:11:06.152784\n",
      "[Epoch 3/10] [Batch 195/350] [D loss: 0.252040, acc:  45%] [G loss: 1.195967] time: 2:11:12.440005\n",
      "[Epoch 3/10] [Batch 196/350] [D loss: 0.252551, acc:  54%] [G loss: 1.224582] time: 2:11:18.707216\n",
      "[Epoch 3/10] [Batch 197/350] [D loss: 0.252165, acc:  52%] [G loss: 1.027716] time: 2:11:25.002384\n",
      "[Epoch 3/10] [Batch 198/350] [D loss: 0.251905, acc:  48%] [G loss: 1.109444] time: 2:11:31.276608\n",
      "[Epoch 3/10] [Batch 199/350] [D loss: 0.252374, acc:  46%] [G loss: 1.132456] time: 2:11:37.560805\n",
      "[Epoch 3/10] [Batch 200/350] [D loss: 0.251804, acc:  45%] [G loss: 1.212901] time: 2:11:43.883898\n",
      "[Epoch 3/10] [Batch 201/350] [D loss: 0.251182, acc:  48%] [G loss: 1.049231] time: 2:11:50.166101\n",
      "[Epoch 3/10] [Batch 202/350] [D loss: 0.251387, acc:  48%] [G loss: 1.204714] time: 2:11:56.434341\n",
      "[Epoch 3/10] [Batch 203/350] [D loss: 0.251269, acc:  45%] [G loss: 1.116014] time: 2:12:02.709562\n",
      "[Epoch 3/10] [Batch 204/350] [D loss: 0.251433, acc:  47%] [G loss: 1.138328] time: 2:12:08.975808\n",
      "[Epoch 3/10] [Batch 205/350] [D loss: 0.251449, acc:  51%] [G loss: 1.103695] time: 2:12:15.373701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/10] [Batch 206/350] [D loss: 0.251362, acc:  50%] [G loss: 1.194870] time: 2:12:21.645931\n",
      "[Epoch 3/10] [Batch 207/350] [D loss: 0.251259, acc:  50%] [G loss: 1.314413] time: 2:12:27.946085\n",
      "[Epoch 3/10] [Batch 208/350] [D loss: 0.251471, acc:  50%] [G loss: 1.126182] time: 2:12:34.234304\n",
      "[Epoch 3/10] [Batch 209/350] [D loss: 0.251958, acc:  48%] [G loss: 1.312440] time: 2:12:40.518469\n",
      "[Epoch 3/10] [Batch 210/350] [D loss: 0.251728, acc:  49%] [G loss: 1.206291] time: 2:12:46.796683\n",
      "[Epoch 3/10] [Batch 211/350] [D loss: 0.251446, acc:  46%] [G loss: 1.050442] time: 2:12:53.066917\n",
      "[Epoch 3/10] [Batch 212/350] [D loss: 0.251450, acc:  47%] [G loss: 0.984480] time: 2:12:59.357098\n",
      "[Epoch 3/10] [Batch 213/350] [D loss: 0.251563, acc:  49%] [G loss: 1.134167] time: 2:13:05.646283\n",
      "[Epoch 3/10] [Batch 214/350] [D loss: 0.251197, acc:  48%] [G loss: 1.107342] time: 2:13:11.931477\n",
      "[Epoch 3/10] [Batch 215/350] [D loss: 0.251119, acc:  48%] [G loss: 1.252643] time: 2:13:18.221659\n",
      "[Epoch 3/10] [Batch 216/350] [D loss: 0.251052, acc:  48%] [G loss: 1.067267] time: 2:13:24.510842\n",
      "[Epoch 3/10] [Batch 217/350] [D loss: 0.251249, acc:  49%] [G loss: 1.010069] time: 2:13:30.785067\n",
      "[Epoch 3/10] [Batch 218/350] [D loss: 0.251233, acc:  48%] [G loss: 1.155300] time: 2:13:37.099184\n",
      "[Epoch 3/10] [Batch 219/350] [D loss: 0.252115, acc:  39%] [G loss: 1.145761] time: 2:13:43.446214\n",
      "[Epoch 3/10] [Batch 220/350] [D loss: 0.252399, acc:  47%] [G loss: 1.464030] time: 2:13:49.734400\n",
      "[Epoch 3/10] [Batch 221/350] [D loss: 0.251972, acc:  46%] [G loss: 1.043396] time: 2:13:56.001642\n",
      "[Epoch 3/10] [Batch 222/350] [D loss: 0.251404, acc:  49%] [G loss: 1.120110] time: 2:14:02.271909\n",
      "[Epoch 3/10] [Batch 223/350] [D loss: 0.251678, acc:  51%] [G loss: 1.314313] time: 2:14:08.548096\n",
      "[Epoch 3/10] [Batch 224/350] [D loss: 0.251789, acc:  49%] [G loss: 1.302359] time: 2:14:14.819328\n",
      "[Epoch 3/10] [Batch 225/350] [D loss: 0.251151, acc:  50%] [G loss: 1.188335] time: 2:14:21.123472\n",
      "[Epoch 3/10] [Batch 226/350] [D loss: 0.251157, acc:  46%] [G loss: 1.236650] time: 2:14:27.401685\n",
      "[Epoch 3/10] [Batch 227/350] [D loss: 0.251531, acc:  47%] [G loss: 1.275203] time: 2:14:33.704832\n",
      "[Epoch 3/10] [Batch 228/350] [D loss: 0.251598, acc:  48%] [G loss: 1.166017] time: 2:14:39.962101\n",
      "[Epoch 3/10] [Batch 229/350] [D loss: 0.251303, acc:  48%] [G loss: 1.182788] time: 2:14:46.257270\n",
      "[Epoch 3/10] [Batch 230/350] [D loss: 0.251504, acc:  52%] [G loss: 1.222315] time: 2:14:52.526506\n",
      "[Epoch 3/10] [Batch 231/350] [D loss: 0.251633, acc:  45%] [G loss: 1.371623] time: 2:14:58.775797\n",
      "[Epoch 3/10] [Batch 232/350] [D loss: 0.251547, acc:  51%] [G loss: 1.137086] time: 2:15:05.044037\n",
      "[Epoch 3/10] [Batch 233/350] [D loss: 0.251580, acc:  47%] [G loss: 1.106186] time: 2:15:11.314304\n",
      "[Epoch 3/10] [Batch 234/350] [D loss: 0.251514, acc:  49%] [G loss: 1.254996] time: 2:15:17.600464\n",
      "[Epoch 3/10] [Batch 235/350] [D loss: 0.251314, acc:  48%] [G loss: 1.211697] time: 2:15:23.904640\n",
      "[Epoch 3/10] [Batch 236/350] [D loss: 0.251382, acc:  44%] [G loss: 1.122331] time: 2:15:30.203765\n",
      "[Epoch 3/10] [Batch 237/350] [D loss: 0.251402, acc:  48%] [G loss: 1.214102] time: 2:15:36.507909\n",
      "[Epoch 3/10] [Batch 238/350] [D loss: 0.251214, acc:  50%] [G loss: 1.172259] time: 2:15:42.833995\n",
      "[Epoch 3/10] [Batch 239/350] [D loss: 0.251068, acc:  46%] [G loss: 1.145919] time: 2:15:49.109216\n",
      "[Epoch 3/10] [Batch 240/350] [D loss: 0.251288, acc:  47%] [G loss: 1.239799] time: 2:15:55.389424\n",
      "[Epoch 3/10] [Batch 241/350] [D loss: 0.251330, acc:  48%] [G loss: 1.218631] time: 2:16:01.671627\n",
      "[Epoch 3/10] [Batch 242/350] [D loss: 0.251266, acc:  45%] [G loss: 1.137718] time: 2:16:07.936874\n",
      "[Epoch 3/10] [Batch 243/350] [D loss: 0.251816, acc:  41%] [G loss: 1.460807] time: 2:16:14.244011\n",
      "[Epoch 3/10] [Batch 244/350] [D loss: 0.251613, acc:  48%] [G loss: 1.111003] time: 2:16:20.518234\n",
      "[Epoch 3/10] [Batch 245/350] [D loss: 0.251279, acc:  50%] [G loss: 1.310460] time: 2:16:26.834347\n",
      "[Epoch 3/10] [Batch 246/350] [D loss: 0.251284, acc:  53%] [G loss: 1.239455] time: 2:16:33.126523\n",
      "[Epoch 3/10] [Batch 247/350] [D loss: 0.251459, acc:  48%] [G loss: 1.125248] time: 2:16:39.409723\n",
      "[Epoch 3/10] [Batch 248/350] [D loss: 0.251266, acc:  45%] [G loss: 1.351856] time: 2:16:45.664997\n",
      "[Epoch 3/10] [Batch 249/350] [D loss: 0.251252, acc:  51%] [G loss: 1.460439] time: 2:16:51.952186\n",
      "[Epoch 3/10] [Batch 250/350] [D loss: 0.251368, acc:  47%] [G loss: 1.337914] time: 2:16:58.230400\n",
      "[Epoch 3/10] [Batch 251/350] [D loss: 0.251216, acc:  51%] [G loss: 1.142983] time: 2:17:04.515595\n",
      "[Epoch 3/10] [Batch 252/350] [D loss: 0.251435, acc:  49%] [G loss: 1.065231] time: 2:17:10.795835\n",
      "[Epoch 3/10] [Batch 253/350] [D loss: 0.251322, acc:  50%] [G loss: 1.313311] time: 2:17:17.105931\n",
      "[Epoch 3/10] [Batch 254/350] [D loss: 0.251383, acc:  47%] [G loss: 1.163311] time: 2:17:23.402096\n",
      "[Epoch 3/10] [Batch 255/350] [D loss: 0.251284, acc:  48%] [G loss: 1.198850] time: 2:17:29.685296\n",
      "[Epoch 3/10] [Batch 256/350] [D loss: 0.251463, acc:  43%] [G loss: 1.084864] time: 2:17:35.983456\n",
      "[Epoch 3/10] [Batch 257/350] [D loss: 0.251308, acc:  46%] [G loss: 1.285028] time: 2:17:42.323504\n",
      "[Epoch 3/10] [Batch 258/350] [D loss: 0.251132, acc:  46%] [G loss: 1.258941] time: 2:17:48.591744\n",
      "[Epoch 3/10] [Batch 259/350] [D loss: 0.251005, acc:  46%] [G loss: 0.991708] time: 2:17:54.887909\n",
      "[Epoch 3/10] [Batch 260/350] [D loss: 0.251049, acc:  49%] [G loss: 1.140574] time: 2:18:01.175098\n",
      "[Epoch 3/10] [Batch 261/350] [D loss: 0.251217, acc:  49%] [G loss: 1.098013] time: 2:18:07.469270\n",
      "[Epoch 3/10] [Batch 262/350] [D loss: 0.251190, acc:  46%] [G loss: 1.467632] time: 2:18:13.743493\n",
      "[Epoch 3/10] [Batch 263/350] [D loss: 0.251228, acc:  47%] [G loss: 1.205975] time: 2:18:20.033675\n",
      "[Epoch 3/10] [Batch 264/350] [D loss: 0.251211, acc:  47%] [G loss: 1.188678] time: 2:18:26.323856\n",
      "[Epoch 3/10] [Batch 265/350] [D loss: 0.251513, acc:  47%] [G loss: 1.055945] time: 2:18:32.639968\n",
      "[Epoch 3/10] [Batch 266/350] [D loss: 0.251587, acc:  49%] [G loss: 1.101746] time: 2:18:38.927157\n",
      "[Epoch 3/10] [Batch 267/350] [D loss: 0.251421, acc:  49%] [G loss: 1.069618] time: 2:18:45.223323\n",
      "[Epoch 3/10] [Batch 268/350] [D loss: 0.251630, acc:  52%] [G loss: 1.222126] time: 2:18:51.476603\n",
      "[Epoch 3/10] [Batch 269/350] [D loss: 0.251715, acc:  47%] [G loss: 1.212675] time: 2:18:57.758805\n",
      "[Epoch 3/10] [Batch 270/350] [D loss: 0.251463, acc:  37%] [G loss: 1.290636] time: 2:19:04.025051\n",
      "[Epoch 3/10] [Batch 271/350] [D loss: 0.251441, acc:  50%] [G loss: 1.054817] time: 2:19:10.318255\n",
      "[Epoch 3/10] [Batch 272/350] [D loss: 0.251411, acc:  48%] [G loss: 1.245850] time: 2:19:16.608405\n",
      "[Epoch 3/10] [Batch 273/350] [D loss: 0.251214, acc:  50%] [G loss: 1.335981] time: 2:19:22.894597\n",
      "[Epoch 3/10] [Batch 274/350] [D loss: 0.251000, acc:  50%] [G loss: 1.363622] time: 2:19:29.177797\n",
      "[Epoch 3/10] [Batch 275/350] [D loss: 0.251469, acc:  49%] [G loss: 1.247512] time: 2:19:35.470971\n",
      "[Epoch 3/10] [Batch 276/350] [D loss: 0.251364, acc:  54%] [G loss: 1.115064] time: 2:19:41.777110\n",
      "[Epoch 3/10] [Batch 277/350] [D loss: 0.251523, acc:  48%] [G loss: 1.083267] time: 2:19:48.062304\n",
      "[Epoch 3/10] [Batch 278/350] [D loss: 0.251239, acc:  47%] [G loss: 1.161637] time: 2:19:54.345535\n",
      "[Epoch 3/10] [Batch 279/350] [D loss: 0.251288, acc:  47%] [G loss: 1.184385] time: 2:20:00.636683\n",
      "[Epoch 3/10] [Batch 280/350] [D loss: 0.251172, acc:  49%] [G loss: 1.156161] time: 2:20:06.911904\n",
      "[Epoch 3/10] [Batch 281/350] [D loss: 0.251211, acc:  48%] [G loss: 1.143680] time: 2:20:13.205077\n",
      "[Epoch 3/10] [Batch 282/350] [D loss: 0.251472, acc:  50%] [G loss: 1.219658] time: 2:20:19.470325\n",
      "[Epoch 3/10] [Batch 283/350] [D loss: 0.251599, acc:  46%] [G loss: 1.073871] time: 2:20:25.766491\n",
      "[Epoch 3/10] [Batch 284/350] [D loss: 0.251661, acc:  49%] [G loss: 1.142908] time: 2:20:32.060661\n",
      "[Epoch 3/10] [Batch 285/350] [D loss: 0.251289, acc:  46%] [G loss: 1.104409] time: 2:20:38.346885\n",
      "[Epoch 3/10] [Batch 286/350] [D loss: 0.251197, acc:  47%] [G loss: 1.099008] time: 2:20:44.607115\n",
      "[Epoch 3/10] [Batch 287/350] [D loss: 0.251028, acc:  46%] [G loss: 1.153528] time: 2:20:50.895333\n",
      "[Epoch 3/10] [Batch 288/350] [D loss: 0.251268, acc:  47%] [G loss: 1.216846] time: 2:20:57.194459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/10] [Batch 289/350] [D loss: 0.251335, acc:  54%] [G loss: 1.368708] time: 2:21:03.447739\n",
      "[Epoch 3/10] [Batch 290/350] [D loss: 0.251357, acc:  49%] [G loss: 1.056015] time: 2:21:09.737920\n",
      "[Epoch 3/10] [Batch 291/350] [D loss: 0.251524, acc:  45%] [G loss: 1.294779] time: 2:21:16.027104\n",
      "[Epoch 3/10] [Batch 292/350] [D loss: 0.251281, acc:  49%] [G loss: 1.097316] time: 2:21:22.315291\n",
      "[Epoch 3/10] [Batch 293/350] [D loss: 0.251235, acc:  48%] [G loss: 1.479895] time: 2:21:28.606469\n",
      "[Epoch 3/10] [Batch 294/350] [D loss: 0.251327, acc:  53%] [G loss: 1.201839] time: 2:21:34.885680\n",
      "[Epoch 3/10] [Batch 295/350] [D loss: 0.251491, acc:  49%] [G loss: 1.156588] time: 2:21:41.154917\n",
      "[Epoch 3/10] [Batch 296/350] [D loss: 0.251236, acc:  45%] [G loss: 1.241935] time: 2:21:47.439115\n",
      "[Epoch 3/10] [Batch 297/350] [D loss: 0.251119, acc:  49%] [G loss: 1.214428] time: 2:21:53.710347\n",
      "[Epoch 3/10] [Batch 298/350] [D loss: 0.251172, acc:  50%] [G loss: 1.229276] time: 2:21:59.989558\n",
      "[Epoch 3/10] [Batch 299/350] [D loss: 0.251225, acc:  49%] [G loss: 1.429936] time: 2:22:06.268768\n",
      "[Epoch 3/10] [Batch 300/350] [D loss: 0.251584, acc:  49%] [G loss: 1.402940] time: 2:22:12.536011\n",
      "[Epoch 3/10] [Batch 301/350] [D loss: 0.251743, acc:  49%] [G loss: 1.351902] time: 2:22:18.850128\n",
      "[Epoch 3/10] [Batch 302/350] [D loss: 0.251637, acc:  49%] [G loss: 1.084982] time: 2:22:25.146294\n",
      "[Epoch 3/10] [Batch 303/350] [D loss: 0.251399, acc:  52%] [G loss: 1.150884] time: 2:22:31.446449\n",
      "[Epoch 3/10] [Batch 304/350] [D loss: 0.251764, acc:  47%] [G loss: 1.003056] time: 2:22:37.737627\n",
      "[Epoch 3/10] [Batch 305/350] [D loss: 0.251751, acc:  50%] [G loss: 1.126145] time: 2:22:44.005898\n",
      "[Epoch 3/10] [Batch 306/350] [D loss: 0.251200, acc:  49%] [G loss: 1.136953] time: 2:22:50.280091\n",
      "[Epoch 3/10] [Batch 307/350] [D loss: 0.251215, acc:  47%] [G loss: 1.262055] time: 2:22:56.563290\n",
      "[Epoch 3/10] [Batch 308/350] [D loss: 0.251146, acc:  49%] [G loss: 1.178024] time: 2:23:02.836518\n",
      "[Epoch 3/10] [Batch 309/350] [D loss: 0.251180, acc:  48%] [G loss: 1.174844] time: 2:23:09.123707\n",
      "[Epoch 3/10] [Batch 310/350] [D loss: 0.251239, acc:  47%] [G loss: 1.204118] time: 2:23:15.413888\n",
      "[Epoch 3/10] [Batch 311/350] [D loss: 0.251071, acc:  46%] [G loss: 1.251936] time: 2:23:21.710053\n",
      "[Epoch 3/10] [Batch 312/350] [D loss: 0.251956, acc:  49%] [G loss: 1.143321] time: 2:23:27.973307\n",
      "[Epoch 3/10] [Batch 313/350] [D loss: 0.251934, acc:  50%] [G loss: 0.994469] time: 2:23:34.281440\n",
      "[Epoch 3/10] [Batch 314/350] [D loss: 0.252272, acc:  48%] [G loss: 1.279757] time: 2:23:40.590571\n",
      "[Epoch 3/10] [Batch 315/350] [D loss: 0.251779, acc:  47%] [G loss: 1.209346] time: 2:23:46.890725\n",
      "[Epoch 3/10] [Batch 316/350] [D loss: 0.251799, acc:  51%] [G loss: 1.281153] time: 2:23:53.172928\n",
      "[Epoch 3/10] [Batch 317/350] [D loss: 0.252603, acc:  51%] [G loss: 1.234880] time: 2:23:59.455130\n",
      "[Epoch 3/10] [Batch 318/350] [D loss: 0.252235, acc:  47%] [G loss: 1.239604] time: 2:24:05.731382\n",
      "[Epoch 3/10] [Batch 319/350] [D loss: 0.251301, acc:  50%] [G loss: 1.131595] time: 2:24:11.978645\n",
      "[Epoch 3/10] [Batch 320/350] [D loss: 0.251552, acc:  48%] [G loss: 1.150831] time: 2:24:18.265834\n",
      "[Epoch 3/10] [Batch 321/350] [D loss: 0.251868, acc:  48%] [G loss: 1.181752] time: 2:24:24.572970\n",
      "[Epoch 3/10] [Batch 322/350] [D loss: 0.251458, acc:  48%] [G loss: 1.323196] time: 2:24:30.898059\n",
      "[Epoch 3/10] [Batch 323/350] [D loss: 0.251362, acc:  50%] [G loss: 1.193826] time: 2:24:37.193227\n",
      "[Epoch 3/10] [Batch 324/350] [D loss: 0.251323, acc:  48%] [G loss: 1.134725] time: 2:24:43.481413\n",
      "[Epoch 3/10] [Batch 325/350] [D loss: 0.251176, acc:  45%] [G loss: 1.259649] time: 2:24:49.754640\n",
      "[Epoch 3/10] [Batch 326/350] [D loss: 0.251565, acc:  51%] [G loss: 1.182621] time: 2:24:56.005925\n",
      "[Epoch 3/10] [Batch 327/350] [D loss: 0.251468, acc:  44%] [G loss: 1.137127] time: 2:25:02.290122\n",
      "[Epoch 3/10] [Batch 328/350] [D loss: 0.251439, acc:  46%] [G loss: 1.128253] time: 2:25:08.572325\n",
      "[Epoch 3/10] [Batch 329/350] [D loss: 0.251208, acc:  47%] [G loss: 1.193449] time: 2:25:14.854528\n",
      "[Epoch 3/10] [Batch 330/350] [D loss: 0.251230, acc:  49%] [G loss: 1.242291] time: 2:25:21.112795\n",
      "[Epoch 3/10] [Batch 331/350] [D loss: 0.251294, acc:  47%] [G loss: 1.370485] time: 2:25:27.408960\n",
      "[Epoch 3/10] [Batch 332/350] [D loss: 0.251461, acc:  45%] [G loss: 1.276756] time: 2:25:33.678197\n",
      "[Epoch 3/10] [Batch 333/350] [D loss: 0.251466, acc:  46%] [G loss: 1.071147] time: 2:25:39.987357\n",
      "[Epoch 3/10] [Batch 334/350] [D loss: 0.251319, acc:  46%] [G loss: 1.129972] time: 2:25:46.299451\n",
      "[Epoch 3/10] [Batch 335/350] [D loss: 0.251492, acc:  43%] [G loss: 1.244738] time: 2:25:52.582650\n",
      "[Epoch 3/10] [Batch 336/350] [D loss: 0.251519, acc:  49%] [G loss: 1.236954] time: 2:25:58.870837\n",
      "[Epoch 3/10] [Batch 337/350] [D loss: 0.251239, acc:  51%] [G loss: 1.153299] time: 2:26:05.201909\n",
      "[Epoch 3/10] [Batch 338/350] [D loss: 0.251185, acc:  49%] [G loss: 1.321424] time: 2:26:11.490097\n",
      "[Epoch 3/10] [Batch 339/350] [D loss: 0.250981, acc:  46%] [G loss: 1.069912] time: 2:26:17.765349\n",
      "[Epoch 3/10] [Batch 340/350] [D loss: 0.251442, acc:  40%] [G loss: 1.034932] time: 2:26:24.076442\n",
      "[Epoch 3/10] [Batch 341/350] [D loss: 0.251539, acc:  48%] [G loss: 1.072135] time: 2:26:30.352662\n",
      "[Epoch 3/10] [Batch 342/350] [D loss: 0.251486, acc:  44%] [G loss: 1.424277] time: 2:26:36.630876\n",
      "[Epoch 3/10] [Batch 343/350] [D loss: 0.251513, acc:  47%] [G loss: 1.172031] time: 2:26:42.924048\n",
      "[Epoch 3/10] [Batch 344/350] [D loss: 0.251903, acc:  46%] [G loss: 1.317353] time: 2:26:49.213232\n",
      "[Epoch 3/10] [Batch 345/350] [D loss: 0.251746, acc:  51%] [G loss: 1.132593] time: 2:26:55.498426\n",
      "[Epoch 3/10] [Batch 346/350] [D loss: 0.251545, acc:  47%] [G loss: 1.137134] time: 2:27:01.789605\n",
      "[Epoch 3/10] [Batch 347/350] [D loss: 0.251748, acc:  54%] [G loss: 1.130926] time: 2:27:08.052859\n",
      "[Epoch 3/10] [Batch 348/350] [D loss: 0.251727, acc:  49%] [G loss: 1.068701] time: 2:27:14.367974\n",
      "weights saved...\n",
      "[Epoch 4/10] [Batch 0/350] [D loss: 0.251233, acc:  49%] [G loss: 1.105628] time: 2:27:20.961344\n",
      "[Epoch 4/10] [Batch 1/350] [D loss: 0.251081, acc:  49%] [G loss: 1.084130] time: 2:27:32.832603\n",
      "[Epoch 4/10] [Batch 2/350] [D loss: 0.251304, acc:  47%] [G loss: 1.242459] time: 2:27:39.113808\n",
      "[Epoch 4/10] [Batch 3/350] [D loss: 0.251591, acc:  51%] [G loss: 1.383601] time: 2:27:45.419947\n",
      "[Epoch 4/10] [Batch 4/350] [D loss: 0.251527, acc:  49%] [G loss: 1.302114] time: 2:27:51.696165\n",
      "[Epoch 4/10] [Batch 5/350] [D loss: 0.251267, acc:  51%] [G loss: 1.295355] time: 2:27:57.984352\n",
      "[Epoch 4/10] [Batch 6/350] [D loss: 0.251520, acc:  41%] [G loss: 1.255736] time: 2:28:04.291488\n",
      "[Epoch 4/10] [Batch 7/350] [D loss: 0.251365, acc:  45%] [G loss: 1.236866] time: 2:28:10.560725\n",
      "[Epoch 4/10] [Batch 8/350] [D loss: 0.251516, acc:  44%] [G loss: 1.069249] time: 2:28:16.863872\n",
      "[Epoch 4/10] [Batch 9/350] [D loss: 0.251679, acc:  50%] [G loss: 1.164275] time: 2:28:23.133109\n",
      "[Epoch 4/10] [Batch 10/350] [D loss: 0.251489, acc:  43%] [G loss: 1.266049] time: 2:28:29.415344\n",
      "[Epoch 4/10] [Batch 11/350] [D loss: 0.251788, acc:  50%] [G loss: 1.390836] time: 2:28:35.703499\n",
      "[Epoch 4/10] [Batch 12/350] [D loss: 0.252149, acc:  51%] [G loss: 1.168532] time: 2:28:41.990688\n",
      "[Epoch 4/10] [Batch 13/350] [D loss: 0.251978, acc:  47%] [G loss: 1.067707] time: 2:28:48.263914\n",
      "[Epoch 4/10] [Batch 14/350] [D loss: 0.251185, acc:  47%] [G loss: 1.089853] time: 2:28:54.551104\n",
      "[Epoch 4/10] [Batch 15/350] [D loss: 0.251205, acc:  49%] [G loss: 1.066177] time: 2:29:00.835302\n",
      "[Epoch 4/10] [Batch 16/350] [D loss: 0.251214, acc:  45%] [G loss: 1.054168] time: 2:29:07.098555\n",
      "[Epoch 4/10] [Batch 17/350] [D loss: 0.251287, acc:  50%] [G loss: 1.472066] time: 2:29:13.344853\n",
      "[Epoch 4/10] [Batch 18/350] [D loss: 0.251274, acc:  48%] [G loss: 1.241522] time: 2:29:19.619077\n",
      "[Epoch 4/10] [Batch 19/350] [D loss: 0.251277, acc:  45%] [G loss: 1.196827] time: 2:29:25.909259\n",
      "[Epoch 4/10] [Batch 20/350] [D loss: 0.251285, acc:  44%] [G loss: 1.365073] time: 2:29:32.220384\n",
      "[Epoch 4/10] [Batch 21/350] [D loss: 0.251399, acc:  49%] [G loss: 1.228959] time: 2:29:38.498597\n",
      "[Epoch 4/10] [Batch 22/350] [D loss: 0.251274, acc:  48%] [G loss: 1.061638] time: 2:29:44.850614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/10] [Batch 23/350] [D loss: 0.250979, acc:  47%] [G loss: 1.304015] time: 2:29:51.140794\n",
      "[Epoch 4/10] [Batch 24/350] [D loss: 0.251256, acc:  48%] [G loss: 1.091525] time: 2:29:57.404048\n",
      "[Epoch 4/10] [Batch 25/350] [D loss: 0.251165, acc:  44%] [G loss: 1.106404] time: 2:30:03.693263\n",
      "[Epoch 4/10] [Batch 26/350] [D loss: 0.251143, acc:  48%] [G loss: 1.166537] time: 2:30:09.965461\n",
      "[Epoch 4/10] [Batch 27/350] [D loss: 0.251207, acc:  46%] [G loss: 1.207830] time: 2:30:16.252651\n",
      "[Epoch 4/10] [Batch 28/350] [D loss: 0.251350, acc:  42%] [G loss: 1.096724] time: 2:30:22.550811\n",
      "[Epoch 4/10] [Batch 29/350] [D loss: 0.251256, acc:  46%] [G loss: 1.156532] time: 2:30:28.838998\n",
      "[Epoch 4/10] [Batch 30/350] [D loss: 0.251131, acc:  49%] [G loss: 1.106366] time: 2:30:35.133200\n",
      "[Epoch 4/10] [Batch 31/350] [D loss: 0.251089, acc:  47%] [G loss: 1.173837] time: 2:30:41.414405\n",
      "[Epoch 4/10] [Batch 32/350] [D loss: 0.251133, acc:  46%] [G loss: 1.136999] time: 2:30:47.711536\n",
      "[Epoch 4/10] [Batch 33/350] [D loss: 0.251165, acc:  47%] [G loss: 1.174315] time: 2:30:53.984763\n",
      "[Epoch 4/10] [Batch 34/350] [D loss: 0.251366, acc:  51%] [G loss: 1.129832] time: 2:31:00.269957\n",
      "[Epoch 4/10] [Batch 35/350] [D loss: 0.251284, acc:  51%] [G loss: 1.012126] time: 2:31:06.557147\n",
      "[Epoch 4/10] [Batch 36/350] [D loss: 0.251185, acc:  51%] [G loss: 1.015993] time: 2:31:12.834362\n",
      "[Epoch 4/10] [Batch 37/350] [D loss: 0.251176, acc:  49%] [G loss: 1.271302] time: 2:31:19.101605\n",
      "[Epoch 4/10] [Batch 38/350] [D loss: 0.251428, acc:  48%] [G loss: 1.288541] time: 2:31:25.388795\n",
      "[Epoch 4/10] [Batch 39/350] [D loss: 0.251203, acc:  48%] [G loss: 1.135320] time: 2:31:31.670000\n",
      "[Epoch 4/10] [Batch 40/350] [D loss: 0.251292, acc:  47%] [G loss: 1.267506] time: 2:31:37.969157\n",
      "[Epoch 4/10] [Batch 41/350] [D loss: 0.251607, acc:  46%] [G loss: 1.249074] time: 2:31:44.301226\n",
      "[Epoch 4/10] [Batch 42/350] [D loss: 0.251351, acc:  50%] [G loss: 1.030642] time: 2:31:50.571461\n",
      "[Epoch 4/10] [Batch 43/350] [D loss: 0.251499, acc:  48%] [G loss: 1.225213] time: 2:31:56.851669\n",
      "[Epoch 4/10] [Batch 44/350] [D loss: 0.251274, acc:  45%] [G loss: 1.207861] time: 2:32:03.140854\n",
      "[Epoch 4/10] [Batch 45/350] [D loss: 0.251440, acc:  48%] [G loss: 1.161358] time: 2:32:09.423056\n",
      "[Epoch 4/10] [Batch 46/350] [D loss: 0.251065, acc:  48%] [G loss: 1.060009] time: 2:32:15.767093\n",
      "[Epoch 4/10] [Batch 47/350] [D loss: 0.251073, acc:  47%] [G loss: 1.162432] time: 2:32:22.268709\n",
      "[Epoch 4/10] [Batch 48/350] [D loss: 0.251205, acc:  46%] [G loss: 1.239268] time: 2:32:28.564875\n",
      "[Epoch 4/10] [Batch 49/350] [D loss: 0.251173, acc:  49%] [G loss: 1.025216] time: 2:32:34.882981\n",
      "[Epoch 4/10] [Batch 50/350] [D loss: 0.251156, acc:  48%] [G loss: 1.053256] time: 2:32:41.162192\n",
      "[Epoch 4/10] [Batch 51/350] [D loss: 0.251448, acc:  46%] [G loss: 1.039702] time: 2:32:47.451376\n",
      "[Epoch 4/10] [Batch 52/350] [D loss: 0.251449, acc:  49%] [G loss: 1.040056] time: 2:32:53.732582\n",
      "[Epoch 4/10] [Batch 53/350] [D loss: 0.251553, acc:  51%] [G loss: 1.024993] time: 2:33:00.039717\n",
      "[Epoch 4/10] [Batch 54/350] [D loss: 0.251318, acc:  51%] [G loss: 1.194628] time: 2:33:06.331893\n",
      "[Epoch 4/10] [Batch 55/350] [D loss: 0.251305, acc:  50%] [G loss: 1.133520] time: 2:33:12.620080\n",
      "[Epoch 4/10] [Batch 56/350] [D loss: 0.251053, acc:  49%] [G loss: 1.337023] time: 2:33:18.914251\n",
      "[Epoch 4/10] [Batch 57/350] [D loss: 0.251291, acc:  56%] [G loss: 1.227768] time: 2:33:25.177504\n",
      "[Epoch 4/10] [Batch 58/350] [D loss: 0.251388, acc:  51%] [G loss: 1.275007] time: 2:33:31.489627\n",
      "[Epoch 4/10] [Batch 59/350] [D loss: 0.251354, acc:  52%] [G loss: 1.208932] time: 2:33:37.774822\n",
      "[Epoch 4/10] [Batch 60/350] [D loss: 0.251556, acc:  52%] [G loss: 1.244060] time: 2:33:44.094923\n",
      "[Epoch 4/10] [Batch 61/350] [D loss: 0.251528, acc:  47%] [G loss: 1.390820] time: 2:33:50.376128\n",
      "[Epoch 4/10] [Batch 62/350] [D loss: 0.251317, acc:  42%] [G loss: 1.182151] time: 2:33:56.656336\n",
      "[Epoch 4/10] [Batch 63/350] [D loss: 0.251307, acc:  49%] [G loss: 1.270885] time: 2:34:02.935546\n",
      "[Epoch 4/10] [Batch 64/350] [D loss: 0.251258, acc:  47%] [G loss: 1.383549] time: 2:34:09.211766\n",
      "[Epoch 4/10] [Batch 65/350] [D loss: 0.251562, acc:  45%] [G loss: 1.217198] time: 2:34:15.511951\n",
      "[Epoch 4/10] [Batch 66/350] [D loss: 0.251324, acc:  49%] [G loss: 1.201644] time: 2:34:21.804096\n",
      "[Epoch 4/10] [Batch 67/350] [D loss: 0.251382, acc:  49%] [G loss: 1.322179] time: 2:34:28.091285\n",
      "[Epoch 4/10] [Batch 68/350] [D loss: 0.251735, acc:  47%] [G loss: 1.165357] time: 2:34:34.401445\n",
      "[Epoch 4/10] [Batch 69/350] [D loss: 0.251871, acc:  46%] [G loss: 1.316236] time: 2:34:40.680624\n",
      "[Epoch 4/10] [Batch 70/350] [D loss: 0.251982, acc:  47%] [G loss: 1.243128] time: 2:34:46.952853\n",
      "[Epoch 4/10] [Batch 71/350] [D loss: 0.251621, acc:  48%] [G loss: 1.242666] time: 2:34:53.233061\n",
      "[Epoch 4/10] [Batch 72/350] [D loss: 0.251785, acc:  51%] [G loss: 1.220762] time: 2:34:59.505291\n",
      "[Epoch 4/10] [Batch 73/350] [D loss: 0.251725, acc:  50%] [G loss: 1.168992] time: 2:35:05.783505\n",
      "[Epoch 4/10] [Batch 74/350] [D loss: 0.251870, acc:  48%] [G loss: 1.387287] time: 2:35:12.064709\n",
      "[Epoch 4/10] [Batch 75/350] [D loss: 0.252473, acc:  48%] [G loss: 1.322465] time: 2:35:18.332949\n",
      "[Epoch 4/10] [Batch 76/350] [D loss: 0.252328, acc:  48%] [G loss: 1.552310] time: 2:35:24.619142\n",
      "[Epoch 4/10] [Batch 77/350] [D loss: 0.251546, acc:  52%] [G loss: 1.189573] time: 2:35:30.923285\n",
      "[Epoch 4/10] [Batch 78/350] [D loss: 0.251875, acc:  53%] [G loss: 1.207348] time: 2:35:37.205488\n",
      "[Epoch 4/10] [Batch 79/350] [D loss: 0.251648, acc:  47%] [G loss: 1.373016] time: 2:35:43.544539\n",
      "[Epoch 4/10] [Batch 80/350] [D loss: 0.251684, acc:  50%] [G loss: 1.279445] time: 2:35:49.836714\n",
      "[Epoch 4/10] [Batch 81/350] [D loss: 0.252447, acc:  53%] [G loss: 1.368535] time: 2:35:56.113931\n",
      "[Epoch 4/10] [Batch 82/350] [D loss: 0.252467, acc:  50%] [G loss: 1.083948] time: 2:36:02.404112\n",
      "[Epoch 4/10] [Batch 83/350] [D loss: 0.252068, acc:  50%] [G loss: 1.279654] time: 2:36:08.687312\n",
      "[Epoch 4/10] [Batch 84/350] [D loss: 0.252274, acc:  46%] [G loss: 1.440313] time: 2:36:14.961536\n",
      "[Epoch 4/10] [Batch 85/350] [D loss: 0.251904, acc:  46%] [G loss: 1.254876] time: 2:36:21.230773\n",
      "[Epoch 4/10] [Batch 86/350] [D loss: 0.251670, acc:  49%] [G loss: 1.142882] time: 2:36:27.507990\n",
      "[Epoch 4/10] [Batch 87/350] [D loss: 0.252211, acc:  52%] [G loss: 1.416250] time: 2:36:33.799168\n",
      "[Epoch 4/10] [Batch 88/350] [D loss: 0.252024, acc:  50%] [G loss: 1.090627] time: 2:36:40.089349\n",
      "[Epoch 4/10] [Batch 89/350] [D loss: 0.251306, acc:  52%] [G loss: 1.204755] time: 2:36:46.372549\n",
      "[Epoch 4/10] [Batch 90/350] [D loss: 0.251271, acc:  50%] [G loss: 1.148942] time: 2:36:52.654752\n",
      "[Epoch 4/10] [Batch 91/350] [D loss: 0.251190, acc:  48%] [G loss: 1.065486] time: 2:36:58.927978\n",
      "[Epoch 4/10] [Batch 92/350] [D loss: 0.251372, acc:  47%] [G loss: 1.104001] time: 2:37:05.220155\n",
      "[Epoch 4/10] [Batch 93/350] [D loss: 0.251151, acc:  49%] [G loss: 1.168886] time: 2:37:11.499365\n",
      "[Epoch 4/10] [Batch 94/350] [D loss: 0.251175, acc:  48%] [G loss: 1.233682] time: 2:37:17.841408\n",
      "[Epoch 4/10] [Batch 95/350] [D loss: 0.251146, acc:  47%] [G loss: 1.208085] time: 2:37:24.145552\n",
      "[Epoch 4/10] [Batch 96/350] [D loss: 0.251172, acc:  51%] [G loss: 1.073684] time: 2:37:30.416816\n",
      "[Epoch 4/10] [Batch 97/350] [D loss: 0.251240, acc:  49%] [G loss: 1.348908] time: 2:37:36.715941\n",
      "[Epoch 4/10] [Batch 98/350] [D loss: 0.251260, acc:  48%] [G loss: 1.101338] time: 2:37:43.039067\n",
      "[Epoch 4/10] [Batch 99/350] [D loss: 0.251124, acc:  45%] [G loss: 1.169749] time: 2:37:49.332208\n",
      "[Epoch 4/10] [Batch 100/350] [D loss: 0.251186, acc:  52%] [G loss: 1.280242] time: 2:37:55.598454\n",
      "[Epoch 4/10] [Batch 101/350] [D loss: 0.251431, acc:  50%] [G loss: 1.093022] time: 2:38:01.895616\n",
      "[Epoch 4/10] [Batch 102/350] [D loss: 0.252275, acc:  56%] [G loss: 1.380535] time: 2:38:08.172832\n",
      "[Epoch 4/10] [Batch 103/350] [D loss: 0.252661, acc:  49%] [G loss: 1.301754] time: 2:38:14.459024\n",
      "[Epoch 4/10] [Batch 104/350] [D loss: 0.251924, acc:  53%] [G loss: 1.286399] time: 2:38:20.759179\n",
      "[Epoch 4/10] [Batch 105/350] [D loss: 0.251700, acc:  42%] [G loss: 1.200164] time: 2:38:27.061362\n",
      "[Epoch 4/10] [Batch 106/350] [D loss: 0.251837, acc:  51%] [G loss: 1.446380] time: 2:38:33.355499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/10] [Batch 107/350] [D loss: 0.251447, acc:  52%] [G loss: 1.033507] time: 2:38:39.666624\n",
      "[Epoch 4/10] [Batch 108/350] [D loss: 0.251646, acc:  46%] [G loss: 1.205717] time: 2:38:45.952816\n",
      "[Epoch 4/10] [Batch 109/350] [D loss: 0.252671, acc:  52%] [G loss: 1.186122] time: 2:38:52.229064\n",
      "[Epoch 4/10] [Batch 110/350] [D loss: 0.252289, acc:  49%] [G loss: 1.340247] time: 2:38:58.508246\n",
      "[Epoch 4/10] [Batch 111/350] [D loss: 0.251789, acc:  46%] [G loss: 1.174940] time: 2:39:04.785462\n",
      "[Epoch 4/10] [Batch 112/350] [D loss: 0.252655, acc:  50%] [G loss: 1.416239] time: 2:39:11.072651\n",
      "[Epoch 4/10] [Batch 113/350] [D loss: 0.252614, acc:  50%] [G loss: 1.182043] time: 2:39:17.349866\n",
      "[Epoch 4/10] [Batch 114/350] [D loss: 0.251675, acc:  46%] [G loss: 1.195695] time: 2:39:23.646032\n",
      "[Epoch 4/10] [Batch 115/350] [D loss: 0.252180, acc:  47%] [G loss: 1.365260] time: 2:39:29.949178\n",
      "[Epoch 4/10] [Batch 116/350] [D loss: 0.252332, acc:  55%] [G loss: 1.260524] time: 2:39:36.267286\n",
      "[Epoch 4/10] [Batch 117/350] [D loss: 0.251816, acc:  52%] [G loss: 1.166376] time: 2:39:42.574421\n",
      "[Epoch 4/10] [Batch 118/350] [D loss: 0.252660, acc:  49%] [G loss: 1.280110] time: 2:39:48.852667\n",
      "[Epoch 4/10] [Batch 119/350] [D loss: 0.251717, acc:  43%] [G loss: 1.207069] time: 2:39:55.136832\n",
      "[Epoch 4/10] [Batch 120/350] [D loss: 0.251428, acc:  54%] [G loss: 1.236808] time: 2:40:01.433995\n",
      "[Epoch 4/10] [Batch 121/350] [D loss: 0.251542, acc:  51%] [G loss: 1.146873] time: 2:40:07.699243\n",
      "[Epoch 4/10] [Batch 122/350] [D loss: 0.251381, acc:  45%] [G loss: 1.175413] time: 2:40:13.973467\n",
      "[Epoch 4/10] [Batch 123/350] [D loss: 0.251669, acc:  50%] [G loss: 1.133152] time: 2:40:20.255670\n",
      "[Epoch 4/10] [Batch 124/350] [D loss: 0.252159, acc:  50%] [G loss: 1.163860] time: 2:40:26.536904\n",
      "[Epoch 4/10] [Batch 125/350] [D loss: 0.251866, acc:  48%] [G loss: 1.097494] time: 2:40:32.819077\n",
      "[Epoch 4/10] [Batch 126/350] [D loss: 0.251504, acc:  47%] [G loss: 1.263487] time: 2:40:39.107264\n",
      "[Epoch 4/10] [Batch 127/350] [D loss: 0.251903, acc:  52%] [G loss: 1.246614] time: 2:40:45.369529\n",
      "[Epoch 4/10] [Batch 128/350] [D loss: 0.252154, acc:  49%] [G loss: 1.091523] time: 2:40:51.669675\n",
      "[Epoch 4/10] [Batch 129/350] [D loss: 0.251549, acc:  48%] [G loss: 1.248078] time: 2:40:57.955866\n",
      "[Epoch 4/10] [Batch 130/350] [D loss: 0.251957, acc:  48%] [G loss: 1.268307] time: 2:41:04.256021\n",
      "[Epoch 4/10] [Batch 131/350] [D loss: 0.251803, acc:  50%] [G loss: 1.126873] time: 2:41:10.544208\n",
      "[Epoch 4/10] [Batch 132/350] [D loss: 0.251462, acc:  48%] [G loss: 1.104125] time: 2:41:16.813445\n",
      "[Epoch 4/10] [Batch 133/350] [D loss: 0.252252, acc:  48%] [G loss: 1.265058] time: 2:41:23.105621\n",
      "[Epoch 4/10] [Batch 134/350] [D loss: 0.251999, acc:  47%] [G loss: 1.197855] time: 2:41:29.379845\n",
      "[Epoch 4/10] [Batch 135/350] [D loss: 0.251251, acc:  44%] [G loss: 1.318594] time: 2:41:35.670027\n",
      "[Epoch 4/10] [Batch 136/350] [D loss: 0.251082, acc:  47%] [G loss: 1.125349] time: 2:41:42.002096\n",
      "[Epoch 4/10] [Batch 137/350] [D loss: 0.251044, acc:  47%] [G loss: 1.292101] time: 2:41:48.293275\n",
      "[Epoch 4/10] [Batch 138/350] [D loss: 0.251273, acc:  54%] [G loss: 1.398431] time: 2:41:54.562512\n",
      "[Epoch 4/10] [Batch 139/350] [D loss: 0.251676, acc:  53%] [G loss: 1.123054] time: 2:42:00.851697\n",
      "[Epoch 4/10] [Batch 140/350] [D loss: 0.251689, acc:  49%] [G loss: 1.259063] time: 2:42:07.165813\n",
      "[Epoch 4/10] [Batch 141/350] [D loss: 0.251486, acc:  44%] [G loss: 1.141888] time: 2:42:13.443030\n",
      "[Epoch 4/10] [Batch 142/350] [D loss: 0.251505, acc:  49%] [G loss: 1.121303] time: 2:42:19.734208\n",
      "[Epoch 4/10] [Batch 143/350] [D loss: 0.251318, acc:  48%] [G loss: 1.258084] time: 2:42:26.006437\n",
      "[Epoch 4/10] [Batch 144/350] [D loss: 0.251268, acc:  48%] [G loss: 1.258616] time: 2:42:32.283653\n",
      "[Epoch 4/10] [Batch 145/350] [D loss: 0.251468, acc:  48%] [G loss: 1.424462] time: 2:42:38.565856\n",
      "[Epoch 4/10] [Batch 146/350] [D loss: 0.251283, acc:  47%] [G loss: 1.304497] time: 2:42:44.857035\n",
      "[Epoch 4/10] [Batch 147/350] [D loss: 0.251278, acc:  47%] [G loss: 1.276890] time: 2:42:51.142229\n",
      "[Epoch 4/10] [Batch 148/350] [D loss: 0.251881, acc:  41%] [G loss: 1.279592] time: 2:42:57.441387\n",
      "[Epoch 4/10] [Batch 149/350] [D loss: 0.251794, acc:  48%] [G loss: 1.057394] time: 2:43:03.744533\n",
      "[Epoch 4/10] [Batch 150/350] [D loss: 0.251451, acc:  51%] [G loss: 1.234719] time: 2:43:10.041696\n",
      "[Epoch 4/10] [Batch 151/350] [D loss: 0.251102, acc:  46%] [G loss: 1.134826] time: 2:43:16.316949\n",
      "[Epoch 4/10] [Batch 152/350] [D loss: 0.251111, acc:  47%] [G loss: 1.275497] time: 2:43:22.610091\n",
      "[Epoch 4/10] [Batch 153/350] [D loss: 0.251002, acc:  48%] [G loss: 1.109491] time: 2:43:28.890299\n",
      "[Epoch 4/10] [Batch 154/350] [D loss: 0.251421, acc:  49%] [G loss: 1.219914] time: 2:43:35.203419\n",
      "[Epoch 4/10] [Batch 155/350] [D loss: 0.251517, acc:  46%] [G loss: 1.143581] time: 2:43:41.544464\n",
      "[Epoch 4/10] [Batch 156/350] [D loss: 0.251516, acc:  46%] [G loss: 1.123890] time: 2:43:47.820683\n",
      "[Epoch 4/10] [Batch 157/350] [D loss: 0.251476, acc:  49%] [G loss: 1.155058] time: 2:43:54.090918\n",
      "[Epoch 4/10] [Batch 158/350] [D loss: 0.251366, acc:  50%] [G loss: 1.143078] time: 2:44:00.372123\n",
      "[Epoch 4/10] [Batch 159/350] [D loss: 0.251228, acc:  44%] [G loss: 1.311397] time: 2:44:06.668288\n",
      "[Epoch 4/10] [Batch 160/350] [D loss: 0.251262, acc:  51%] [G loss: 1.154732] time: 2:44:12.949493\n",
      "[Epoch 4/10] [Batch 161/350] [D loss: 0.251434, acc:  48%] [G loss: 1.223225] time: 2:44:19.213744\n",
      "[Epoch 4/10] [Batch 162/350] [D loss: 0.251263, acc:  47%] [G loss: 1.140294] time: 2:44:25.509910\n",
      "[Epoch 4/10] [Batch 163/350] [D loss: 0.251664, acc:  44%] [G loss: 1.178710] time: 2:44:31.804080\n",
      "[Epoch 4/10] [Batch 164/350] [D loss: 0.251692, acc:  48%] [G loss: 1.113320] time: 2:44:38.087280\n",
      "[Epoch 4/10] [Batch 165/350] [D loss: 0.251339, acc:  41%] [G loss: 1.137471] time: 2:44:44.353526\n",
      "[Epoch 4/10] [Batch 166/350] [D loss: 0.251273, acc:  48%] [G loss: 1.205448] time: 2:44:50.637722\n",
      "[Epoch 4/10] [Batch 167/350] [D loss: 0.251274, acc:  49%] [G loss: 0.994567] time: 2:44:56.923915\n",
      "[Epoch 4/10] [Batch 168/350] [D loss: 0.251389, acc:  51%] [G loss: 1.171718] time: 2:45:03.222107\n",
      "[Epoch 4/10] [Batch 169/350] [D loss: 0.252011, acc:  56%] [G loss: 0.977630] time: 2:45:09.473394\n",
      "[Epoch 4/10] [Batch 170/350] [D loss: 0.252333, acc:  49%] [G loss: 1.244652] time: 2:45:15.746586\n",
      "[Epoch 4/10] [Batch 171/350] [D loss: 0.251795, acc:  49%] [G loss: 1.201425] time: 2:45:22.032811\n",
      "[Epoch 4/10] [Batch 172/350] [D loss: 0.252280, acc:  54%] [G loss: 1.155628] time: 2:45:28.308000\n",
      "[Epoch 4/10] [Batch 173/350] [D loss: 0.253257, acc:  49%] [G loss: 1.394465] time: 2:45:34.591200\n",
      "[Epoch 4/10] [Batch 174/350] [D loss: 0.252177, acc:  50%] [G loss: 1.195482] time: 2:45:40.909306\n",
      "[Epoch 4/10] [Batch 175/350] [D loss: 0.252282, acc:  48%] [G loss: 1.303170] time: 2:45:47.223424\n",
      "[Epoch 4/10] [Batch 176/350] [D loss: 0.253240, acc:  49%] [G loss: 1.175313] time: 2:45:59.055786\n",
      "[Epoch 4/10] [Batch 177/350] [D loss: 0.252287, acc:  49%] [G loss: 1.264923] time: 2:46:05.334000\n",
      "[Epoch 4/10] [Batch 178/350] [D loss: 0.251165, acc:  49%] [G loss: 1.233480] time: 2:46:11.649115\n",
      "[Epoch 4/10] [Batch 179/350] [D loss: 0.251276, acc:  48%] [G loss: 1.186387] time: 2:46:17.935307\n",
      "[Epoch 4/10] [Batch 180/350] [D loss: 0.251342, acc:  47%] [G loss: 1.127911] time: 2:46:24.235461\n",
      "[Epoch 4/10] [Batch 181/350] [D loss: 0.251358, acc:  49%] [G loss: 1.206644] time: 2:46:30.529632\n",
      "[Epoch 4/10] [Batch 182/350] [D loss: 0.251352, acc:  47%] [G loss: 1.109767] time: 2:46:36.811834\n",
      "[Epoch 4/10] [Batch 183/350] [D loss: 0.251053, acc:  50%] [G loss: 1.291312] time: 2:46:43.090048\n",
      "[Epoch 4/10] [Batch 184/350] [D loss: 0.251182, acc:  50%] [G loss: 1.249562] time: 2:46:49.381226\n",
      "[Epoch 4/10] [Batch 185/350] [D loss: 0.251360, acc:  49%] [G loss: 0.992316] time: 2:46:55.668447\n",
      "[Epoch 4/10] [Batch 186/350] [D loss: 0.251234, acc:  46%] [G loss: 1.266038] time: 2:47:01.933664\n",
      "[Epoch 4/10] [Batch 187/350] [D loss: 0.251171, acc:  46%] [G loss: 1.239595] time: 2:47:08.218859\n",
      "[Epoch 4/10] [Batch 188/350] [D loss: 0.251355, acc:  48%] [G loss: 1.004160] time: 2:47:14.536966\n",
      "[Epoch 4/10] [Batch 189/350] [D loss: 0.251401, acc:  55%] [G loss: 1.145688] time: 2:47:20.827147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/10] [Batch 190/350] [D loss: 0.251323, acc:  51%] [G loss: 1.388996] time: 2:47:27.105360\n",
      "[Epoch 4/10] [Batch 191/350] [D loss: 0.251589, acc:  45%] [G loss: 1.242891] time: 2:47:33.407541\n",
      "[Epoch 4/10] [Batch 192/350] [D loss: 0.251422, acc:  44%] [G loss: 1.089180] time: 2:47:39.691707\n",
      "[Epoch 4/10] [Batch 193/350] [D loss: 0.251693, acc:  50%] [G loss: 1.200993] time: 2:47:45.987872\n",
      "[Epoch 4/10] [Batch 194/350] [D loss: 0.251668, acc:  49%] [G loss: 1.397504] time: 2:47:52.270074\n",
      "[Epoch 4/10] [Batch 195/350] [D loss: 0.251987, acc:  45%] [G loss: 1.176385] time: 2:47:58.554272\n",
      "[Epoch 4/10] [Batch 196/350] [D loss: 0.252469, acc:  54%] [G loss: 1.214840] time: 2:48:04.819520\n",
      "[Epoch 4/10] [Batch 197/350] [D loss: 0.252100, acc:  52%] [G loss: 1.016217] time: 2:48:11.099728\n",
      "[Epoch 4/10] [Batch 198/350] [D loss: 0.251830, acc:  48%] [G loss: 1.108167] time: 2:48:17.367999\n",
      "[Epoch 4/10] [Batch 199/350] [D loss: 0.252275, acc:  45%] [G loss: 1.117345] time: 2:48:23.653163\n",
      "[Epoch 4/10] [Batch 200/350] [D loss: 0.251746, acc:  45%] [G loss: 1.193986] time: 2:48:29.934368\n",
      "[Epoch 4/10] [Batch 201/350] [D loss: 0.251119, acc:  48%] [G loss: 1.034812] time: 2:48:36.225547\n",
      "[Epoch 4/10] [Batch 202/350] [D loss: 0.251321, acc:  48%] [G loss: 1.192751] time: 2:48:42.482847\n",
      "[Epoch 4/10] [Batch 203/350] [D loss: 0.251219, acc:  45%] [G loss: 1.103936] time: 2:48:48.768011\n",
      "[Epoch 4/10] [Batch 204/350] [D loss: 0.251371, acc:  46%] [G loss: 1.121830] time: 2:48:55.043232\n",
      "[Epoch 4/10] [Batch 205/350] [D loss: 0.251387, acc:  51%] [G loss: 1.086814] time: 2:49:01.314464\n",
      "[Epoch 4/10] [Batch 206/350] [D loss: 0.251304, acc:  50%] [G loss: 1.174294] time: 2:49:07.581707\n",
      "[Epoch 4/10] [Batch 207/350] [D loss: 0.251227, acc:  51%] [G loss: 1.291728] time: 2:49:13.866901\n",
      "[Epoch 4/10] [Batch 208/350] [D loss: 0.251407, acc:  49%] [G loss: 1.116114] time: 2:49:20.151098\n",
      "[Epoch 4/10] [Batch 209/350] [D loss: 0.251914, acc:  48%] [G loss: 1.302128] time: 2:49:26.448261\n",
      "[Epoch 4/10] [Batch 210/350] [D loss: 0.251676, acc:  50%] [G loss: 1.189446] time: 2:49:32.725478\n",
      "[Epoch 4/10] [Batch 211/350] [D loss: 0.251411, acc:  46%] [G loss: 1.041480] time: 2:49:39.003690\n",
      "[Epoch 4/10] [Batch 212/350] [D loss: 0.251371, acc:  46%] [G loss: 0.970366] time: 2:49:45.345734\n",
      "[Epoch 4/10] [Batch 213/350] [D loss: 0.251523, acc:  48%] [G loss: 1.125403] time: 2:49:51.643893\n",
      "[Epoch 4/10] [Batch 214/350] [D loss: 0.251141, acc:  48%] [G loss: 1.090324] time: 2:49:57.928091\n",
      "[Epoch 4/10] [Batch 215/350] [D loss: 0.251080, acc:  49%] [G loss: 1.238123] time: 2:50:04.215280\n",
      "[Epoch 4/10] [Batch 216/350] [D loss: 0.251009, acc:  48%] [G loss: 1.053662] time: 2:50:10.490501\n",
      "[Epoch 4/10] [Batch 217/350] [D loss: 0.251181, acc:  49%] [G loss: 1.000919] time: 2:50:16.753754\n",
      "[Epoch 4/10] [Batch 218/350] [D loss: 0.251187, acc:  48%] [G loss: 1.141463] time: 2:50:23.062886\n",
      "[Epoch 4/10] [Batch 219/350] [D loss: 0.252060, acc:  39%] [G loss: 1.130940] time: 2:50:29.376005\n",
      "[Epoch 4/10] [Batch 220/350] [D loss: 0.252359, acc:  47%] [G loss: 1.446418] time: 2:50:35.676160\n",
      "[Epoch 4/10] [Batch 221/350] [D loss: 0.251921, acc:  46%] [G loss: 1.029163] time: 2:50:41.948389\n",
      "[Epoch 4/10] [Batch 222/350] [D loss: 0.251362, acc:  49%] [G loss: 1.097053] time: 2:50:48.236576\n",
      "[Epoch 4/10] [Batch 223/350] [D loss: 0.251615, acc:  51%] [G loss: 1.293626] time: 2:50:54.516784\n",
      "[Epoch 4/10] [Batch 224/350] [D loss: 0.251727, acc:  49%] [G loss: 1.277883] time: 2:51:00.792005\n",
      "[Epoch 4/10] [Batch 225/350] [D loss: 0.251105, acc:  50%] [G loss: 1.158441] time: 2:51:07.076202\n",
      "[Epoch 4/10] [Batch 226/350] [D loss: 0.251109, acc:  46%] [G loss: 1.216462] time: 2:51:13.362396\n",
      "[Epoch 4/10] [Batch 227/350] [D loss: 0.251472, acc:  47%] [G loss: 1.260374] time: 2:51:19.665541\n",
      "[Epoch 4/10] [Batch 228/350] [D loss: 0.251527, acc:  48%] [G loss: 1.147912] time: 2:51:25.934778\n",
      "[Epoch 4/10] [Batch 229/350] [D loss: 0.251248, acc:  48%] [G loss: 1.180273] time: 2:51:32.237926\n",
      "[Epoch 4/10] [Batch 230/350] [D loss: 0.251427, acc:  52%] [G loss: 1.210127] time: 2:51:38.518134\n",
      "[Epoch 4/10] [Batch 231/350] [D loss: 0.251561, acc:  45%] [G loss: 1.344725] time: 2:51:44.813301\n",
      "[Epoch 4/10] [Batch 232/350] [D loss: 0.251475, acc:  51%] [G loss: 1.130899] time: 2:51:51.091514\n",
      "[Epoch 4/10] [Batch 233/350] [D loss: 0.251495, acc:  47%] [G loss: 1.081385] time: 2:51:57.353771\n",
      "[Epoch 4/10] [Batch 234/350] [D loss: 0.251453, acc:  49%] [G loss: 1.228661] time: 2:52:03.640992\n",
      "[Epoch 4/10] [Batch 235/350] [D loss: 0.251244, acc:  48%] [G loss: 1.197716] time: 2:52:09.926155\n",
      "[Epoch 4/10] [Batch 236/350] [D loss: 0.251329, acc:  44%] [G loss: 1.105903] time: 2:52:16.286149\n",
      "[Epoch 4/10] [Batch 237/350] [D loss: 0.251340, acc:  48%] [G loss: 1.174020] time: 2:52:23.062033\n",
      "[Epoch 4/10] [Batch 238/350] [D loss: 0.251160, acc:  49%] [G loss: 1.143368] time: 2:52:29.597557\n",
      "[Epoch 4/10] [Batch 239/350] [D loss: 0.251016, acc:  46%] [G loss: 1.119376] time: 2:52:36.477169\n",
      "[Epoch 4/10] [Batch 240/350] [D loss: 0.251246, acc:  47%] [G loss: 1.211246] time: 2:52:43.285957\n",
      "[Epoch 4/10] [Batch 241/350] [D loss: 0.251281, acc:  48%] [G loss: 1.199501] time: 2:52:49.575142\n",
      "[Epoch 4/10] [Batch 242/350] [D loss: 0.251223, acc:  44%] [G loss: 1.130415] time: 2:52:55.837397\n",
      "[Epoch 4/10] [Batch 243/350] [D loss: 0.251751, acc:  41%] [G loss: 1.441042] time: 2:53:02.148522\n",
      "[Epoch 4/10] [Batch 244/350] [D loss: 0.251582, acc:  48%] [G loss: 1.100335] time: 2:53:08.479602\n",
      "[Epoch 4/10] [Batch 245/350] [D loss: 0.251227, acc:  50%] [G loss: 1.267457] time: 2:53:14.775760\n",
      "[Epoch 4/10] [Batch 246/350] [D loss: 0.251240, acc:  54%] [G loss: 1.222737] time: 2:53:21.062949\n",
      "[Epoch 4/10] [Batch 247/350] [D loss: 0.251421, acc:  48%] [G loss: 1.105391] time: 2:53:27.356123\n",
      "[Epoch 4/10] [Batch 248/350] [D loss: 0.251216, acc:  45%] [G loss: 1.333683] time: 2:53:33.629350\n",
      "[Epoch 4/10] [Batch 249/350] [D loss: 0.251202, acc:  51%] [G loss: 1.438631] time: 2:53:39.933494\n",
      "[Epoch 4/10] [Batch 250/350] [D loss: 0.251326, acc:  46%] [G loss: 1.324362] time: 2:53:46.230656\n",
      "[Epoch 4/10] [Batch 251/350] [D loss: 0.251165, acc:  51%] [G loss: 1.145759] time: 2:53:52.529814\n",
      "[Epoch 4/10] [Batch 252/350] [D loss: 0.251382, acc:  49%] [G loss: 1.049950] time: 2:53:58.838944\n",
      "[Epoch 4/10] [Batch 253/350] [D loss: 0.251277, acc:  50%] [G loss: 1.283745] time: 2:54:05.138101\n",
      "[Epoch 4/10] [Batch 254/350] [D loss: 0.251339, acc:  47%] [G loss: 1.155734] time: 2:54:11.423296\n",
      "[Epoch 4/10] [Batch 255/350] [D loss: 0.251242, acc:  48%] [G loss: 1.175806] time: 2:54:17.702539\n",
      "[Epoch 4/10] [Batch 256/350] [D loss: 0.251409, acc:  43%] [G loss: 1.075521] time: 2:54:24.002662\n",
      "[Epoch 4/10] [Batch 257/350] [D loss: 0.251259, acc:  46%] [G loss: 1.297690] time: 2:54:30.297829\n",
      "[Epoch 4/10] [Batch 258/350] [D loss: 0.251096, acc:  46%] [G loss: 1.225494] time: 2:54:36.576043\n",
      "[Epoch 4/10] [Batch 259/350] [D loss: 0.250950, acc:  46%] [G loss: 0.999714] time: 2:54:42.861237\n",
      "[Epoch 4/10] [Batch 260/350] [D loss: 0.251011, acc:  49%] [G loss: 1.132601] time: 2:54:49.167376\n",
      "[Epoch 4/10] [Batch 261/350] [D loss: 0.251177, acc:  48%] [G loss: 1.073822] time: 2:54:55.444592\n",
      "[Epoch 4/10] [Batch 262/350] [D loss: 0.251134, acc:  46%] [G loss: 1.434744] time: 2:55:01.728790\n",
      "[Epoch 4/10] [Batch 263/350] [D loss: 0.251192, acc:  47%] [G loss: 1.183594] time: 2:55:08.015979\n",
      "[Epoch 4/10] [Batch 264/350] [D loss: 0.251158, acc:  48%] [G loss: 1.178597] time: 2:55:14.292197\n",
      "[Epoch 4/10] [Batch 265/350] [D loss: 0.251476, acc:  47%] [G loss: 1.040210] time: 2:55:20.582378\n",
      "[Epoch 4/10] [Batch 266/350] [D loss: 0.251520, acc:  49%] [G loss: 1.081883] time: 2:55:26.879541\n",
      "[Epoch 4/10] [Batch 267/350] [D loss: 0.251388, acc:  49%] [G loss: 1.049266] time: 2:55:33.176704\n",
      "[Epoch 4/10] [Batch 268/350] [D loss: 0.251574, acc:  52%] [G loss: 1.190841] time: 2:55:39.445942\n",
      "[Epoch 4/10] [Batch 269/350] [D loss: 0.251698, acc:  47%] [G loss: 1.186737] time: 2:55:45.758064\n",
      "[Epoch 4/10] [Batch 270/350] [D loss: 0.251415, acc:  37%] [G loss: 1.285119] time: 2:55:52.037275\n",
      "[Epoch 4/10] [Batch 271/350] [D loss: 0.251406, acc:  50%] [G loss: 1.033185] time: 2:55:58.340422\n",
      "[Epoch 4/10] [Batch 272/350] [D loss: 0.251363, acc:  49%] [G loss: 1.225208] time: 2:56:04.650549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/10] [Batch 273/350] [D loss: 0.251183, acc:  50%] [G loss: 1.300423] time: 2:56:10.931755\n",
      "[Epoch 4/10] [Batch 274/350] [D loss: 0.250944, acc:  50%] [G loss: 1.348529] time: 2:56:17.207973\n",
      "[Epoch 4/10] [Batch 275/350] [D loss: 0.251423, acc:  48%] [G loss: 1.235576] time: 2:56:23.507130\n",
      "[Epoch 4/10] [Batch 276/350] [D loss: 0.251313, acc:  55%] [G loss: 1.109935] time: 2:56:29.788337\n",
      "[Epoch 4/10] [Batch 277/350] [D loss: 0.251460, acc:  48%] [G loss: 1.076187] time: 2:56:36.073530\n",
      "[Epoch 4/10] [Batch 278/350] [D loss: 0.251182, acc:  47%] [G loss: 1.150691] time: 2:56:42.360720\n",
      "[Epoch 4/10] [Batch 279/350] [D loss: 0.251231, acc:  47%] [G loss: 1.165313] time: 2:56:48.665861\n",
      "[Epoch 4/10] [Batch 280/350] [D loss: 0.251130, acc:  49%] [G loss: 1.138479] time: 2:56:54.948064\n",
      "[Epoch 4/10] [Batch 281/350] [D loss: 0.251161, acc:  48%] [G loss: 1.130401] time: 2:57:01.243232\n",
      "[Epoch 4/10] [Batch 282/350] [D loss: 0.251430, acc:  50%] [G loss: 1.200858] time: 2:57:07.511472\n",
      "[Epoch 4/10] [Batch 283/350] [D loss: 0.251564, acc:  46%] [G loss: 1.053934] time: 2:57:13.813621\n",
      "[Epoch 4/10] [Batch 284/350] [D loss: 0.251623, acc:  49%] [G loss: 1.135108] time: 2:57:20.102805\n",
      "[Epoch 4/10] [Batch 285/350] [D loss: 0.251243, acc:  46%] [G loss: 1.091893] time: 2:57:26.404955\n",
      "[Epoch 4/10] [Batch 286/350] [D loss: 0.251158, acc:  47%] [G loss: 1.089875] time: 2:57:32.686160\n",
      "[Epoch 4/10] [Batch 287/350] [D loss: 0.250982, acc:  46%] [G loss: 1.136744] time: 2:57:38.988309\n",
      "[Epoch 4/10] [Batch 288/350] [D loss: 0.251210, acc:  47%] [G loss: 1.198320] time: 2:57:45.338363\n",
      "[Epoch 4/10] [Batch 289/350] [D loss: 0.251281, acc:  54%] [G loss: 1.330854] time: 2:57:51.610560\n",
      "[Epoch 4/10] [Batch 290/350] [D loss: 0.251310, acc:  49%] [G loss: 1.044455] time: 2:57:57.912709\n",
      "[Epoch 4/10] [Batch 291/350] [D loss: 0.251464, acc:  45%] [G loss: 1.268404] time: 2:58:04.227856\n",
      "[Epoch 4/10] [Batch 292/350] [D loss: 0.251214, acc:  49%] [G loss: 1.075758] time: 2:58:10.512021\n",
      "[Epoch 4/10] [Batch 293/350] [D loss: 0.251173, acc:  48%] [G loss: 1.451350] time: 2:58:16.812176\n",
      "[Epoch 4/10] [Batch 294/350] [D loss: 0.251267, acc:  54%] [G loss: 1.178275] time: 2:58:23.089392\n",
      "[Epoch 4/10] [Batch 295/350] [D loss: 0.251427, acc:  49%] [G loss: 1.137028] time: 2:58:29.350651\n",
      "[Epoch 4/10] [Batch 296/350] [D loss: 0.251179, acc:  45%] [G loss: 1.223424] time: 2:58:35.647813\n",
      "[Epoch 4/10] [Batch 297/350] [D loss: 0.251071, acc:  49%] [G loss: 1.201868] time: 2:58:41.922037\n",
      "[Epoch 4/10] [Batch 298/350] [D loss: 0.251104, acc:  49%] [G loss: 1.210168] time: 2:58:48.206235\n",
      "[Epoch 4/10] [Batch 299/350] [D loss: 0.251164, acc:  49%] [G loss: 1.400206] time: 2:58:54.504395\n",
      "[Epoch 4/10] [Batch 300/350] [D loss: 0.251510, acc:  49%] [G loss: 1.383973] time: 2:59:00.781611\n",
      "[Epoch 4/10] [Batch 301/350] [D loss: 0.251626, acc:  49%] [G loss: 1.333307] time: 2:59:07.069798\n",
      "[Epoch 4/10] [Batch 302/350] [D loss: 0.251535, acc:  49%] [G loss: 1.070547] time: 2:59:13.350006\n",
      "[Epoch 4/10] [Batch 303/350] [D loss: 0.251331, acc:  52%] [G loss: 1.143702] time: 2:59:19.655146\n",
      "[Epoch 4/10] [Batch 304/350] [D loss: 0.251665, acc:  47%] [G loss: 0.991834] time: 2:59:25.964278\n",
      "[Epoch 4/10] [Batch 305/350] [D loss: 0.251650, acc:  50%] [G loss: 1.114729] time: 2:59:32.249472\n",
      "[Epoch 4/10] [Batch 306/350] [D loss: 0.251139, acc:  49%] [G loss: 1.121204] time: 2:59:38.530678\n",
      "[Epoch 4/10] [Batch 307/350] [D loss: 0.251161, acc:  46%] [G loss: 1.241395] time: 2:59:44.897685\n",
      "[Epoch 4/10] [Batch 308/350] [D loss: 0.251105, acc:  49%] [G loss: 1.152706] time: 2:59:51.181851\n",
      "[Epoch 4/10] [Batch 309/350] [D loss: 0.251136, acc:  48%] [G loss: 1.149843] time: 2:59:57.477019\n",
      "[Epoch 4/10] [Batch 310/350] [D loss: 0.251190, acc:  47%] [G loss: 1.183363] time: 3:00:03.768197\n",
      "[Epoch 4/10] [Batch 311/350] [D loss: 0.251035, acc:  46%] [G loss: 1.230475] time: 3:00:10.060373\n",
      "[Epoch 4/10] [Batch 312/350] [D loss: 0.251871, acc:  49%] [G loss: 1.125979] time: 3:00:16.321632\n",
      "[Epoch 4/10] [Batch 313/350] [D loss: 0.251870, acc:  50%] [G loss: 0.978331] time: 3:00:22.616800\n",
      "[Epoch 4/10] [Batch 314/350] [D loss: 0.252231, acc:  48%] [G loss: 1.250295] time: 3:00:29.001760\n",
      "[Epoch 4/10] [Batch 315/350] [D loss: 0.251732, acc:  48%] [G loss: 1.184561] time: 3:00:35.297893\n",
      "[Epoch 4/10] [Batch 316/350] [D loss: 0.251757, acc:  51%] [G loss: 1.259310] time: 3:00:41.582091\n",
      "[Epoch 4/10] [Batch 317/350] [D loss: 0.252559, acc:  51%] [G loss: 1.214613] time: 3:00:47.870277\n",
      "[Epoch 4/10] [Batch 318/350] [D loss: 0.252192, acc:  47%] [G loss: 1.205770] time: 3:00:54.147493\n",
      "[Epoch 4/10] [Batch 319/350] [D loss: 0.251252, acc:  50%] [G loss: 1.098290] time: 3:01:00.409749\n",
      "[Epoch 4/10] [Batch 320/350] [D loss: 0.251503, acc:  48%] [G loss: 1.122486] time: 3:01:06.691952\n",
      "[Epoch 4/10] [Batch 321/350] [D loss: 0.251815, acc:  48%] [G loss: 1.148964] time: 3:01:12.978144\n",
      "[Epoch 4/10] [Batch 322/350] [D loss: 0.251423, acc:  48%] [G loss: 1.287648] time: 3:01:19.262341\n",
      "[Epoch 4/10] [Batch 323/350] [D loss: 0.251326, acc:  50%] [G loss: 1.168130] time: 3:01:25.565488\n",
      "[Epoch 4/10] [Batch 324/350] [D loss: 0.251280, acc:  48%] [G loss: 1.109419] time: 3:01:31.868635\n",
      "[Epoch 4/10] [Batch 325/350] [D loss: 0.251120, acc:  45%] [G loss: 1.236650] time: 3:01:38.142859\n",
      "[Epoch 4/10] [Batch 326/350] [D loss: 0.251497, acc:  51%] [G loss: 1.162315] time: 3:01:44.453984\n",
      "[Epoch 4/10] [Batch 327/350] [D loss: 0.251408, acc:  44%] [G loss: 1.123346] time: 3:01:50.742171\n",
      "[Epoch 4/10] [Batch 328/350] [D loss: 0.251376, acc:  47%] [G loss: 1.108084] time: 3:01:57.040331\n",
      "[Epoch 4/10] [Batch 329/350] [D loss: 0.251159, acc:  48%] [G loss: 1.175900] time: 3:02:03.333504\n",
      "[Epoch 4/10] [Batch 330/350] [D loss: 0.251171, acc:  49%] [G loss: 1.220396] time: 3:02:09.603739\n",
      "[Epoch 4/10] [Batch 331/350] [D loss: 0.251240, acc:  48%] [G loss: 1.332868] time: 3:02:15.979690\n",
      "[Epoch 4/10] [Batch 332/350] [D loss: 0.251389, acc:  45%] [G loss: 1.275808] time: 3:02:22.244939\n",
      "[Epoch 4/10] [Batch 333/350] [D loss: 0.251419, acc:  46%] [G loss: 1.096177] time: 3:02:28.537115\n",
      "[Epoch 4/10] [Batch 334/350] [D loss: 0.251268, acc:  46%] [G loss: 1.137655] time: 3:02:34.840261\n",
      "[Epoch 4/10] [Batch 335/350] [D loss: 0.251438, acc:  43%] [G loss: 1.270557] time: 3:02:41.125490\n",
      "[Epoch 4/10] [Batch 336/350] [D loss: 0.251468, acc:  49%] [G loss: 1.249026] time: 3:02:47.433590\n",
      "[Epoch 4/10] [Batch 337/350] [D loss: 0.251189, acc:  51%] [G loss: 1.144227] time: 3:02:53.716789\n",
      "[Epoch 4/10] [Batch 338/350] [D loss: 0.251134, acc:  49%] [G loss: 1.317202] time: 3:03:00.022928\n",
      "[Epoch 4/10] [Batch 339/350] [D loss: 0.250938, acc:  46%] [G loss: 1.058132] time: 3:03:06.310117\n",
      "[Epoch 4/10] [Batch 340/350] [D loss: 0.251386, acc:  40%] [G loss: 1.027199] time: 3:03:12.614261\n",
      "[Epoch 4/10] [Batch 341/350] [D loss: 0.251497, acc:  48%] [G loss: 1.053072] time: 3:03:18.882501\n",
      "[Epoch 4/10] [Batch 342/350] [D loss: 0.251443, acc:  44%] [G loss: 1.393140] time: 3:03:25.167696\n",
      "[Epoch 4/10] [Batch 343/350] [D loss: 0.251462, acc:  48%] [G loss: 1.165091] time: 3:03:31.457877\n",
      "[Epoch 4/10] [Batch 344/350] [D loss: 0.251847, acc:  46%] [G loss: 1.303809] time: 3:03:37.739083\n",
      "[Epoch 4/10] [Batch 345/350] [D loss: 0.251706, acc:  51%] [G loss: 1.135903] time: 3:03:44.070155\n",
      "[Epoch 4/10] [Batch 346/350] [D loss: 0.251496, acc:  47%] [G loss: 1.131367] time: 3:03:50.358341\n",
      "[Epoch 4/10] [Batch 347/350] [D loss: 0.251687, acc:  54%] [G loss: 1.128416] time: 3:03:56.623589\n",
      "[Epoch 4/10] [Batch 348/350] [D loss: 0.251689, acc:  49%] [G loss: 1.053393] time: 3:04:02.913771\n",
      "weights saved...\n",
      "[Epoch 5/10] [Batch 0/350] [D loss: 0.251198, acc:  49%] [G loss: 1.089183] time: 3:04:09.522101\n",
      "[Epoch 5/10] [Batch 1/350] [D loss: 0.251041, acc:  49%] [G loss: 1.064487] time: 3:04:21.703579\n",
      "[Epoch 5/10] [Batch 2/350] [D loss: 0.251254, acc:  47%] [G loss: 1.205823] time: 3:04:28.157323\n",
      "[Epoch 5/10] [Batch 3/350] [D loss: 0.251522, acc:  51%] [G loss: 1.343013] time: 3:04:34.591152\n",
      "[Epoch 5/10] [Batch 4/350] [D loss: 0.251485, acc:  50%] [G loss: 1.292028] time: 3:04:40.887316\n",
      "[Epoch 5/10] [Batch 5/350] [D loss: 0.251205, acc:  51%] [G loss: 1.264993] time: 3:04:47.220384\n",
      "[Epoch 5/10] [Batch 6/350] [D loss: 0.251468, acc:  41%] [G loss: 1.244302] time: 3:04:53.525499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/10] [Batch 7/350] [D loss: 0.251316, acc:  45%] [G loss: 1.192974] time: 3:04:59.797723\n",
      "[Epoch 5/10] [Batch 8/350] [D loss: 0.251455, acc:  44%] [G loss: 1.042827] time: 3:05:06.114832\n",
      "[Epoch 5/10] [Batch 9/350] [D loss: 0.251621, acc:  50%] [G loss: 1.146694] time: 3:05:12.392048\n",
      "[Epoch 5/10] [Batch 10/350] [D loss: 0.251445, acc:  43%] [G loss: 1.252433] time: 3:05:18.672256\n",
      "[Epoch 5/10] [Batch 11/350] [D loss: 0.251748, acc:  49%] [G loss: 1.378177] time: 3:05:24.964466\n",
      "[Epoch 5/10] [Batch 12/350] [D loss: 0.252099, acc:  51%] [G loss: 1.146727] time: 3:05:31.267579\n",
      "[Epoch 5/10] [Batch 13/350] [D loss: 0.251926, acc:  47%] [G loss: 1.050629] time: 3:05:37.550779\n",
      "[Epoch 5/10] [Batch 14/350] [D loss: 0.251133, acc:  48%] [G loss: 1.069283] time: 3:05:43.878859\n",
      "[Epoch 5/10] [Batch 15/350] [D loss: 0.251159, acc:  49%] [G loss: 1.063339] time: 3:05:50.171035\n",
      "[Epoch 5/10] [Batch 16/350] [D loss: 0.251160, acc:  45%] [G loss: 1.043328] time: 3:05:56.450246\n",
      "[Epoch 5/10] [Batch 17/350] [D loss: 0.251222, acc:  50%] [G loss: 1.452467] time: 3:06:02.722506\n",
      "[Epoch 5/10] [Batch 18/350] [D loss: 0.251226, acc:  48%] [G loss: 1.238187] time: 3:06:09.000688\n",
      "[Epoch 5/10] [Batch 19/350] [D loss: 0.251219, acc:  45%] [G loss: 1.183169] time: 3:06:15.273949\n",
      "[Epoch 5/10] [Batch 20/350] [D loss: 0.251224, acc:  43%] [G loss: 1.354067] time: 3:06:21.583046\n",
      "[Epoch 5/10] [Batch 21/350] [D loss: 0.251349, acc:  49%] [G loss: 1.218359] time: 3:06:27.879243\n",
      "[Epoch 5/10] [Batch 22/350] [D loss: 0.251233, acc:  48%] [G loss: 1.046579] time: 3:06:34.173381\n",
      "[Epoch 5/10] [Batch 23/350] [D loss: 0.250930, acc:  47%] [G loss: 1.276201] time: 3:06:40.459573\n",
      "[Epoch 5/10] [Batch 24/350] [D loss: 0.251196, acc:  48%] [G loss: 1.087597] time: 3:06:46.728811\n",
      "[Epoch 5/10] [Batch 25/350] [D loss: 0.251118, acc:  44%] [G loss: 1.100969] time: 3:06:53.030960\n",
      "[Epoch 5/10] [Batch 26/350] [D loss: 0.251093, acc:  48%] [G loss: 1.160304] time: 3:06:59.322139\n",
      "[Epoch 5/10] [Batch 27/350] [D loss: 0.251165, acc:  46%] [G loss: 1.193061] time: 3:07:05.631269\n",
      "[Epoch 5/10] [Batch 28/350] [D loss: 0.251297, acc:  42%] [G loss: 1.081862] time: 3:07:11.927435\n",
      "[Epoch 5/10] [Batch 29/350] [D loss: 0.251198, acc:  46%] [G loss: 1.142532] time: 3:07:18.261499\n",
      "[Epoch 5/10] [Batch 30/350] [D loss: 0.251071, acc:  49%] [G loss: 1.094961] time: 3:07:24.557664\n",
      "[Epoch 5/10] [Batch 31/350] [D loss: 0.251038, acc:  47%] [G loss: 1.147793] time: 3:07:30.848843\n",
      "[Epoch 5/10] [Batch 32/350] [D loss: 0.251078, acc:  46%] [G loss: 1.111149] time: 3:07:37.169941\n",
      "[Epoch 5/10] [Batch 33/350] [D loss: 0.251115, acc:  47%] [G loss: 1.153524] time: 3:07:43.503008\n",
      "[Epoch 5/10] [Batch 34/350] [D loss: 0.251315, acc:  51%] [G loss: 1.105566] time: 3:07:49.792192\n",
      "[Epoch 5/10] [Batch 35/350] [D loss: 0.251231, acc:  52%] [G loss: 0.995696] time: 3:07:56.085366\n",
      "[Epoch 5/10] [Batch 36/350] [D loss: 0.251142, acc:  51%] [G loss: 0.999596] time: 3:08:02.378539\n",
      "[Epoch 5/10] [Batch 37/350] [D loss: 0.251124, acc:  49%] [G loss: 1.248482] time: 3:08:08.660742\n",
      "[Epoch 5/10] [Batch 38/350] [D loss: 0.251375, acc:  48%] [G loss: 1.258852] time: 3:08:14.990847\n",
      "[Epoch 5/10] [Batch 39/350] [D loss: 0.251145, acc:  48%] [G loss: 1.115011] time: 3:08:21.274016\n",
      "[Epoch 5/10] [Batch 40/350] [D loss: 0.251244, acc:  47%] [G loss: 1.239245] time: 3:08:27.584144\n",
      "[Epoch 5/10] [Batch 41/350] [D loss: 0.251522, acc:  46%] [G loss: 1.237054] time: 3:08:33.891283\n",
      "[Epoch 5/10] [Batch 42/350] [D loss: 0.251288, acc:  49%] [G loss: 1.026471] time: 3:08:40.171488\n",
      "[Epoch 5/10] [Batch 43/350] [D loss: 0.251423, acc:  48%] [G loss: 1.210641] time: 3:08:46.456683\n",
      "[Epoch 5/10] [Batch 44/350] [D loss: 0.251229, acc:  45%] [G loss: 1.192382] time: 3:08:52.742875\n",
      "[Epoch 5/10] [Batch 45/350] [D loss: 0.251372, acc:  48%] [G loss: 1.135201] time: 3:08:59.034053\n",
      "[Epoch 5/10] [Batch 46/350] [D loss: 0.251020, acc:  49%] [G loss: 1.049595] time: 3:09:05.341223\n",
      "[Epoch 5/10] [Batch 47/350] [D loss: 0.251026, acc:  47%] [G loss: 1.151835] time: 3:09:11.616411\n",
      "[Epoch 5/10] [Batch 48/350] [D loss: 0.251166, acc:  46%] [G loss: 1.217000] time: 3:09:17.927536\n",
      "[Epoch 5/10] [Batch 49/350] [D loss: 0.251128, acc:  49%] [G loss: 1.005221] time: 3:09:24.240656\n",
      "[Epoch 5/10] [Batch 50/350] [D loss: 0.251106, acc:  48%] [G loss: 1.032138] time: 3:09:30.526848\n",
      "[Epoch 5/10] [Batch 51/350] [D loss: 0.251405, acc:  46%] [G loss: 1.021553] time: 3:09:36.822016\n",
      "[Epoch 5/10] [Batch 52/350] [D loss: 0.251400, acc:  49%] [G loss: 1.020725] time: 3:09:43.153121\n",
      "[Epoch 5/10] [Batch 53/350] [D loss: 0.251494, acc:  51%] [G loss: 1.010993] time: 3:09:49.473189\n",
      "[Epoch 5/10] [Batch 54/350] [D loss: 0.251281, acc:  51%] [G loss: 1.165918] time: 3:09:55.762373\n",
      "[Epoch 5/10] [Batch 55/350] [D loss: 0.251263, acc:  50%] [G loss: 1.113753] time: 3:10:02.060533\n",
      "[Epoch 5/10] [Batch 56/350] [D loss: 0.251008, acc:  48%] [G loss: 1.295732] time: 3:10:08.360720\n",
      "[Epoch 5/10] [Batch 57/350] [D loss: 0.251250, acc:  56%] [G loss: 1.191463] time: 3:10:14.618955\n",
      "[Epoch 5/10] [Batch 58/350] [D loss: 0.251350, acc:  51%] [G loss: 1.257889] time: 3:10:20.912128\n",
      "[Epoch 5/10] [Batch 59/350] [D loss: 0.251315, acc:  52%] [G loss: 1.183733] time: 3:10:27.204304\n",
      "[Epoch 5/10] [Batch 60/350] [D loss: 0.251515, acc:  52%] [G loss: 1.225824] time: 3:10:33.494486\n",
      "[Epoch 5/10] [Batch 61/350] [D loss: 0.251470, acc:  47%] [G loss: 1.367815] time: 3:10:39.796635\n",
      "[Epoch 5/10] [Batch 62/350] [D loss: 0.251243, acc:  41%] [G loss: 1.150862] time: 3:10:46.081829\n",
      "[Epoch 5/10] [Batch 63/350] [D loss: 0.251250, acc:  49%] [G loss: 1.257957] time: 3:10:52.364033\n",
      "[Epoch 5/10] [Batch 64/350] [D loss: 0.251190, acc:  47%] [G loss: 1.393896] time: 3:10:58.638256\n",
      "[Epoch 5/10] [Batch 65/350] [D loss: 0.251500, acc:  45%] [G loss: 1.229146] time: 3:11:04.975312\n",
      "[Epoch 5/10] [Batch 66/350] [D loss: 0.251278, acc:  49%] [G loss: 1.272363] time: 3:11:11.266490\n",
      "[Epoch 5/10] [Batch 67/350] [D loss: 0.251334, acc:  49%] [G loss: 1.277958] time: 3:11:17.553680\n",
      "[Epoch 5/10] [Batch 68/350] [D loss: 0.251719, acc:  47%] [G loss: 1.129326] time: 3:11:23.869823\n",
      "[Epoch 5/10] [Batch 69/350] [D loss: 0.251821, acc:  46%] [G loss: 1.262764] time: 3:11:30.167952\n",
      "[Epoch 5/10] [Batch 70/350] [D loss: 0.251912, acc:  47%] [G loss: 1.208729] time: 3:11:36.454144\n",
      "[Epoch 5/10] [Batch 71/350] [D loss: 0.251566, acc:  48%] [G loss: 1.209982] time: 3:11:42.782224\n",
      "[Epoch 5/10] [Batch 72/350] [D loss: 0.251739, acc:  51%] [G loss: 1.206768] time: 3:11:49.061435\n",
      "[Epoch 5/10] [Batch 73/350] [D loss: 0.251686, acc:  51%] [G loss: 1.139202] time: 3:11:55.344635\n",
      "[Epoch 5/10] [Batch 74/350] [D loss: 0.251832, acc:  48%] [G loss: 1.353613] time: 3:12:01.637808\n",
      "[Epoch 5/10] [Batch 75/350] [D loss: 0.252410, acc:  48%] [G loss: 1.280044] time: 3:12:07.925995\n",
      "[Epoch 5/10] [Batch 76/350] [D loss: 0.252257, acc:  48%] [G loss: 1.509497] time: 3:12:14.253109\n",
      "[Epoch 5/10] [Batch 77/350] [D loss: 0.251487, acc:  52%] [G loss: 1.203153] time: 3:12:20.687873\n",
      "[Epoch 5/10] [Batch 78/350] [D loss: 0.251855, acc:  53%] [G loss: 1.207369] time: 3:12:26.998000\n",
      "[Epoch 5/10] [Batch 79/350] [D loss: 0.251604, acc:  47%] [G loss: 1.361789] time: 3:12:33.325114\n",
      "[Epoch 5/10] [Batch 80/350] [D loss: 0.251643, acc:  50%] [G loss: 1.289436] time: 3:12:39.701069\n",
      "[Epoch 5/10] [Batch 81/350] [D loss: 0.252403, acc:  53%] [G loss: 1.336706] time: 3:12:46.001189\n",
      "[Epoch 5/10] [Batch 82/350] [D loss: 0.252409, acc:  51%] [G loss: 1.076838] time: 3:12:52.308325\n",
      "[Epoch 5/10] [Batch 83/350] [D loss: 0.252029, acc:  50%] [G loss: 1.275789] time: 3:12:58.600502\n",
      "[Epoch 5/10] [Batch 84/350] [D loss: 0.252239, acc:  46%] [G loss: 1.426773] time: 3:13:04.892677\n",
      "[Epoch 5/10] [Batch 85/350] [D loss: 0.251876, acc:  47%] [G loss: 1.244915] time: 3:13:11.186880\n",
      "[Epoch 5/10] [Batch 86/350] [D loss: 0.251625, acc:  50%] [G loss: 1.117444] time: 3:13:17.462069\n",
      "[Epoch 5/10] [Batch 87/350] [D loss: 0.252149, acc:  52%] [G loss: 1.373073] time: 3:13:23.743275\n",
      "[Epoch 5/10] [Batch 88/350] [D loss: 0.251977, acc:  50%] [G loss: 1.086286] time: 3:13:30.049414\n",
      "[Epoch 5/10] [Batch 89/350] [D loss: 0.251253, acc:  52%] [G loss: 1.191171] time: 3:13:36.347574\n",
      "[Epoch 5/10] [Batch 90/350] [D loss: 0.251218, acc:  50%] [G loss: 1.137325] time: 3:13:42.667675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/10] [Batch 91/350] [D loss: 0.251133, acc:  48%] [G loss: 1.046991] time: 3:13:49.079531\n",
      "[Epoch 5/10] [Batch 92/350] [D loss: 0.251323, acc:  47%] [G loss: 1.085872] time: 3:13:55.391654\n",
      "[Epoch 5/10] [Batch 93/350] [D loss: 0.251105, acc:  49%] [G loss: 1.149870] time: 3:14:01.702778\n",
      "[Epoch 5/10] [Batch 94/350] [D loss: 0.251122, acc:  48%] [G loss: 1.215595] time: 3:14:07.989968\n",
      "[Epoch 5/10] [Batch 95/350] [D loss: 0.251100, acc:  47%] [G loss: 1.197903] time: 3:14:14.275163\n",
      "[Epoch 5/10] [Batch 96/350] [D loss: 0.251120, acc:  50%] [G loss: 1.054618] time: 3:14:20.549387\n",
      "[Epoch 5/10] [Batch 97/350] [D loss: 0.251207, acc:  49%] [G loss: 1.319488] time: 3:14:26.847547\n",
      "[Epoch 5/10] [Batch 98/350] [D loss: 0.251213, acc:  48%] [G loss: 1.076140] time: 3:14:33.127755\n",
      "[Epoch 5/10] [Batch 99/350] [D loss: 0.251090, acc:  45%] [G loss: 1.154383] time: 3:14:39.417936\n",
      "[Epoch 5/10] [Batch 100/350] [D loss: 0.251132, acc:  52%] [G loss: 1.251581] time: 3:14:45.683217\n",
      "[Epoch 5/10] [Batch 101/350] [D loss: 0.251386, acc:  50%] [G loss: 1.074457] time: 3:14:51.988357\n",
      "[Epoch 5/10] [Batch 102/350] [D loss: 0.252260, acc:  56%] [G loss: 1.359562] time: 3:14:58.261586\n",
      "[Epoch 5/10] [Batch 103/350] [D loss: 0.252654, acc:  49%] [G loss: 1.272435] time: 3:15:04.569685\n",
      "[Epoch 5/10] [Batch 104/350] [D loss: 0.251887, acc:  53%] [G loss: 1.268071] time: 3:15:10.873829\n",
      "[Epoch 5/10] [Batch 105/350] [D loss: 0.251674, acc:  41%] [G loss: 1.177840] time: 3:15:17.174016\n",
      "[Epoch 5/10] [Batch 106/350] [D loss: 0.251835, acc:  51%] [G loss: 1.416391] time: 3:15:23.474139\n",
      "[Epoch 5/10] [Batch 107/350] [D loss: 0.251413, acc:  53%] [G loss: 1.012430] time: 3:15:29.786261\n",
      "[Epoch 5/10] [Batch 108/350] [D loss: 0.251624, acc:  46%] [G loss: 1.188355] time: 3:15:36.089408\n",
      "[Epoch 5/10] [Batch 109/350] [D loss: 0.252646, acc:  52%] [G loss: 1.164499] time: 3:15:42.417488\n",
      "[Epoch 5/10] [Batch 110/350] [D loss: 0.252236, acc:  49%] [G loss: 1.323090] time: 3:15:48.700688\n",
      "[Epoch 5/10] [Batch 111/350] [D loss: 0.251738, acc:  46%] [G loss: 1.151114] time: 3:15:54.978902\n",
      "[Epoch 5/10] [Batch 112/350] [D loss: 0.252612, acc:  50%] [G loss: 1.384376] time: 3:16:01.268086\n",
      "[Epoch 5/10] [Batch 113/350] [D loss: 0.252539, acc:  50%] [G loss: 1.160353] time: 3:16:07.578213\n",
      "[Epoch 5/10] [Batch 114/350] [D loss: 0.251628, acc:  46%] [G loss: 1.181608] time: 3:16:13.874379\n",
      "[Epoch 5/10] [Batch 115/350] [D loss: 0.252144, acc:  47%] [G loss: 1.370671] time: 3:16:20.166555\n",
      "[Epoch 5/10] [Batch 116/350] [D loss: 0.252297, acc:  55%] [G loss: 1.301112] time: 3:16:26.484693\n",
      "[Epoch 5/10] [Batch 117/350] [D loss: 0.251798, acc:  52%] [G loss: 1.144199] time: 3:16:32.759883\n",
      "[Epoch 5/10] [Batch 118/350] [D loss: 0.252621, acc:  49%] [G loss: 1.265418] time: 3:16:39.045077\n",
      "[Epoch 5/10] [Batch 119/350] [D loss: 0.251659, acc:  43%] [G loss: 1.186681] time: 3:16:45.336288\n",
      "[Epoch 5/10] [Batch 120/350] [D loss: 0.251410, acc:  55%] [G loss: 1.217174] time: 3:16:51.633419\n",
      "[Epoch 5/10] [Batch 121/350] [D loss: 0.251520, acc:  50%] [G loss: 1.135003] time: 3:16:57.908641\n",
      "[Epoch 5/10] [Batch 122/350] [D loss: 0.251335, acc:  44%] [G loss: 1.150186] time: 3:17:04.212784\n",
      "[Epoch 5/10] [Batch 123/350] [D loss: 0.251632, acc:  50%] [G loss: 1.114872] time: 3:17:10.495984\n",
      "[Epoch 5/10] [Batch 124/350] [D loss: 0.252129, acc:  50%] [G loss: 1.146795] time: 3:17:16.831045\n",
      "[Epoch 5/10] [Batch 125/350] [D loss: 0.251809, acc:  48%] [G loss: 1.080376] time: 3:17:23.125216\n",
      "[Epoch 5/10] [Batch 126/350] [D loss: 0.251460, acc:  46%] [G loss: 1.250098] time: 3:17:29.428363\n",
      "[Epoch 5/10] [Batch 127/350] [D loss: 0.251867, acc:  52%] [G loss: 1.232038] time: 3:17:35.718544\n",
      "[Epoch 5/10] [Batch 128/350] [D loss: 0.252093, acc:  50%] [G loss: 1.085370] time: 3:17:42.045659\n",
      "[Epoch 5/10] [Batch 129/350] [D loss: 0.251510, acc:  48%] [G loss: 1.236798] time: 3:17:48.345781\n",
      "[Epoch 5/10] [Batch 130/350] [D loss: 0.251932, acc:  49%] [G loss: 1.260314] time: 3:17:54.645936\n",
      "[Epoch 5/10] [Batch 131/350] [D loss: 0.251749, acc:  50%] [G loss: 1.109554] time: 3:18:00.948122\n",
      "[Epoch 5/10] [Batch 132/350] [D loss: 0.251429, acc:  48%] [G loss: 1.087313] time: 3:18:07.248240\n",
      "[Epoch 5/10] [Batch 133/350] [D loss: 0.252233, acc:  48%] [G loss: 1.247716] time: 3:18:13.546400\n",
      "[Epoch 5/10] [Batch 134/350] [D loss: 0.251939, acc:  47%] [G loss: 1.183000] time: 3:18:19.818630\n",
      "[Epoch 5/10] [Batch 135/350] [D loss: 0.251200, acc:  44%] [G loss: 1.298516] time: 3:18:26.111803\n",
      "[Epoch 5/10] [Batch 136/350] [D loss: 0.251054, acc:  47%] [G loss: 1.106439] time: 3:18:32.422960\n",
      "[Epoch 5/10] [Batch 137/350] [D loss: 0.250998, acc:  47%] [G loss: 1.265152] time: 3:18:38.735051\n",
      "[Epoch 5/10] [Batch 138/350] [D loss: 0.251223, acc:  54%] [G loss: 1.376426] time: 3:18:45.006314\n",
      "[Epoch 5/10] [Batch 139/350] [D loss: 0.251593, acc:  53%] [G loss: 1.105898] time: 3:18:51.293472\n",
      "[Epoch 5/10] [Batch 140/350] [D loss: 0.251615, acc:  49%] [G loss: 1.231630] time: 3:18:57.582656\n",
      "[Epoch 5/10] [Batch 141/350] [D loss: 0.251428, acc:  44%] [G loss: 1.110328] time: 3:19:03.857907\n",
      "[Epoch 5/10] [Batch 142/350] [D loss: 0.251436, acc:  49%] [G loss: 1.108216] time: 3:19:10.164016\n",
      "[Epoch 5/10] [Batch 143/350] [D loss: 0.251256, acc:  48%] [G loss: 1.244728] time: 3:19:16.441264\n",
      "[Epoch 5/10] [Batch 144/350] [D loss: 0.251224, acc:  48%] [G loss: 1.243346] time: 3:19:22.728421\n",
      "[Epoch 5/10] [Batch 145/350] [D loss: 0.251415, acc:  48%] [G loss: 1.402657] time: 3:19:29.015611\n",
      "[Epoch 5/10] [Batch 146/350] [D loss: 0.251230, acc:  47%] [G loss: 1.272514] time: 3:19:35.316795\n",
      "[Epoch 5/10] [Batch 147/350] [D loss: 0.251233, acc:  47%] [G loss: 1.248343] time: 3:19:41.643845\n",
      "[Epoch 5/10] [Batch 148/350] [D loss: 0.251836, acc:  41%] [G loss: 1.244975] time: 3:19:47.949984\n",
      "[Epoch 5/10] [Batch 149/350] [D loss: 0.251759, acc:  48%] [G loss: 1.065857] time: 3:19:54.260112\n",
      "[Epoch 5/10] [Batch 150/350] [D loss: 0.251407, acc:  51%] [G loss: 1.215200] time: 3:20:00.563291\n",
      "[Epoch 5/10] [Batch 151/350] [D loss: 0.251059, acc:  46%] [G loss: 1.115859] time: 3:20:06.859424\n",
      "[Epoch 5/10] [Batch 152/350] [D loss: 0.251069, acc:  47%] [G loss: 1.245957] time: 3:20:13.157618\n",
      "[Epoch 5/10] [Batch 153/350] [D loss: 0.250962, acc:  48%] [G loss: 1.092369] time: 3:20:19.448795\n",
      "[Epoch 5/10] [Batch 154/350] [D loss: 0.251378, acc:  49%] [G loss: 1.208742] time: 3:20:25.756897\n",
      "[Epoch 5/10] [Batch 155/350] [D loss: 0.251466, acc:  46%] [G loss: 1.123534] time: 3:20:32.076997\n",
      "[Epoch 5/10] [Batch 156/350] [D loss: 0.251468, acc:  46%] [G loss: 1.112238] time: 3:20:38.364187\n",
      "[Epoch 5/10] [Batch 157/350] [D loss: 0.251434, acc:  49%] [G loss: 1.131498] time: 3:20:44.651376\n",
      "[Epoch 5/10] [Batch 158/350] [D loss: 0.251321, acc:  51%] [G loss: 1.131262] time: 3:20:50.947541\n",
      "[Epoch 5/10] [Batch 159/350] [D loss: 0.251182, acc:  44%] [G loss: 1.284965] time: 3:20:57.240715\n",
      "[Epoch 5/10] [Batch 160/350] [D loss: 0.251193, acc:  50%] [G loss: 1.136379] time: 3:21:03.530896\n",
      "[Epoch 5/10] [Batch 161/350] [D loss: 0.251376, acc:  48%] [G loss: 1.193297] time: 3:21:09.807115\n",
      "[Epoch 5/10] [Batch 162/350] [D loss: 0.251204, acc:  47%] [G loss: 1.118120] time: 3:21:16.108267\n",
      "[Epoch 5/10] [Batch 163/350] [D loss: 0.251572, acc:  44%] [G loss: 1.169579] time: 3:21:22.393493\n",
      "[Epoch 5/10] [Batch 164/350] [D loss: 0.251618, acc:  49%] [G loss: 1.093709] time: 3:21:28.671675\n",
      "[Epoch 5/10] [Batch 165/350] [D loss: 0.251286, acc:  41%] [G loss: 1.117297] time: 3:21:34.953877\n",
      "[Epoch 5/10] [Batch 166/350] [D loss: 0.251213, acc:  48%] [G loss: 1.181454] time: 3:21:41.263008\n",
      "[Epoch 5/10] [Batch 167/350] [D loss: 0.251208, acc:  49%] [G loss: 0.983983] time: 3:21:47.565157\n",
      "[Epoch 5/10] [Batch 168/350] [D loss: 0.251329, acc:  51%] [G loss: 1.146658] time: 3:21:53.871296\n",
      "[Epoch 5/10] [Batch 169/350] [D loss: 0.251929, acc:  57%] [G loss: 0.954147] time: 3:22:00.130560\n",
      "[Epoch 5/10] [Batch 170/350] [D loss: 0.252241, acc:  49%] [G loss: 1.230672] time: 3:22:06.413791\n",
      "[Epoch 5/10] [Batch 171/350] [D loss: 0.251727, acc:  49%] [G loss: 1.180957] time: 3:22:12.720896\n",
      "[Epoch 5/10] [Batch 172/350] [D loss: 0.252189, acc:  54%] [G loss: 1.149735] time: 3:22:19.009114\n",
      "[Epoch 5/10] [Batch 173/350] [D loss: 0.253121, acc:  49%] [G loss: 1.368259] time: 3:22:25.319211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/10] [Batch 174/350] [D loss: 0.252083, acc:  50%] [G loss: 1.176536] time: 3:22:31.616374\n",
      "[Epoch 5/10] [Batch 175/350] [D loss: 0.252189, acc:  48%] [G loss: 1.257112] time: 3:22:37.905557\n",
      "[Epoch 5/10] [Batch 176/350] [D loss: 0.253085, acc:  49%] [G loss: 1.163702] time: 3:22:49.809728\n",
      "[Epoch 5/10] [Batch 177/350] [D loss: 0.252170, acc:  49%] [G loss: 1.222924] time: 3:22:56.087942\n",
      "[Epoch 5/10] [Batch 178/350] [D loss: 0.251122, acc:  50%] [G loss: 1.170189] time: 3:23:02.396075\n",
      "[Epoch 5/10] [Batch 179/350] [D loss: 0.251209, acc:  48%] [G loss: 1.108205] time: 3:23:08.694268\n",
      "[Epoch 5/10] [Batch 180/350] [D loss: 0.251284, acc:  47%] [G loss: 1.090739] time: 3:23:14.988437\n",
      "[Epoch 5/10] [Batch 181/350] [D loss: 0.251321, acc:  50%] [G loss: 1.170728] time: 3:23:21.290555\n",
      "[Epoch 5/10] [Batch 182/350] [D loss: 0.251308, acc:  47%] [G loss: 1.074683] time: 3:23:27.582731\n",
      "[Epoch 5/10] [Batch 183/350] [D loss: 0.251011, acc:  50%] [G loss: 1.250989] time: 3:23:33.877899\n",
      "[Epoch 5/10] [Batch 184/350] [D loss: 0.251130, acc:  50%] [G loss: 1.237626] time: 3:23:40.181045\n",
      "[Epoch 5/10] [Batch 185/350] [D loss: 0.251325, acc:  49%] [G loss: 0.985440] time: 3:23:46.494166\n",
      "[Epoch 5/10] [Batch 186/350] [D loss: 0.251189, acc:  46%] [G loss: 1.249114] time: 3:23:52.771382\n",
      "[Epoch 5/10] [Batch 187/350] [D loss: 0.251129, acc:  46%] [G loss: 1.211695] time: 3:23:59.091483\n",
      "[Epoch 5/10] [Batch 188/350] [D loss: 0.251317, acc:  48%] [G loss: 0.995017] time: 3:24:05.374683\n",
      "[Epoch 5/10] [Batch 189/350] [D loss: 0.251351, acc:  56%] [G loss: 1.121977] time: 3:24:11.702795\n",
      "[Epoch 5/10] [Batch 190/350] [D loss: 0.251283, acc:  51%] [G loss: 1.371954] time: 3:24:17.995968\n",
      "[Epoch 5/10] [Batch 191/350] [D loss: 0.251557, acc:  45%] [G loss: 1.218087] time: 3:24:24.306064\n",
      "[Epoch 5/10] [Batch 192/350] [D loss: 0.251387, acc:  44%] [G loss: 1.066905] time: 3:24:30.601264\n",
      "[Epoch 5/10] [Batch 193/350] [D loss: 0.251655, acc:  50%] [G loss: 1.188870] time: 3:24:36.884432\n",
      "[Epoch 5/10] [Batch 194/350] [D loss: 0.251639, acc:  50%] [G loss: 1.399474] time: 3:24:43.166635\n",
      "[Epoch 5/10] [Batch 195/350] [D loss: 0.251946, acc:  45%] [G loss: 1.171655] time: 3:24:49.463798\n",
      "[Epoch 5/10] [Batch 196/350] [D loss: 0.252391, acc:  54%] [G loss: 1.215642] time: 3:24:55.731040\n",
      "[Epoch 5/10] [Batch 197/350] [D loss: 0.252036, acc:  52%] [G loss: 1.013478] time: 3:25:02.021221\n",
      "[Epoch 5/10] [Batch 198/350] [D loss: 0.251767, acc:  48%] [G loss: 1.121958] time: 3:25:08.306416\n",
      "[Epoch 5/10] [Batch 199/350] [D loss: 0.252186, acc:  45%] [G loss: 1.096411] time: 3:25:14.601584\n",
      "[Epoch 5/10] [Batch 200/350] [D loss: 0.251691, acc:  45%] [G loss: 1.186282] time: 3:25:20.887776\n",
      "[Epoch 5/10] [Batch 201/350] [D loss: 0.251066, acc:  49%] [G loss: 1.019918] time: 3:25:27.173002\n",
      "[Epoch 5/10] [Batch 202/350] [D loss: 0.251263, acc:  47%] [G loss: 1.166679] time: 3:25:33.447195\n",
      "[Epoch 5/10] [Batch 203/350] [D loss: 0.251180, acc:  44%] [G loss: 1.089226] time: 3:25:39.751339\n",
      "[Epoch 5/10] [Batch 204/350] [D loss: 0.251317, acc:  46%] [G loss: 1.100937] time: 3:25:46.050528\n",
      "[Epoch 5/10] [Batch 205/350] [D loss: 0.251340, acc:  52%] [G loss: 1.066086] time: 3:25:52.330704\n",
      "[Epoch 5/10] [Batch 206/350] [D loss: 0.251251, acc:  51%] [G loss: 1.147540] time: 3:25:58.620915\n",
      "[Epoch 5/10] [Batch 207/350] [D loss: 0.251200, acc:  51%] [G loss: 1.270825] time: 3:26:04.964954\n",
      "[Epoch 5/10] [Batch 208/350] [D loss: 0.251349, acc:  49%] [G loss: 1.085121] time: 3:26:11.259127\n",
      "[Epoch 5/10] [Batch 209/350] [D loss: 0.251878, acc:  48%] [G loss: 1.281712] time: 3:26:17.553265\n",
      "[Epoch 5/10] [Batch 210/350] [D loss: 0.251628, acc:  50%] [G loss: 1.169610] time: 3:26:23.850428\n",
      "[Epoch 5/10] [Batch 211/350] [D loss: 0.251382, acc:  47%] [G loss: 1.033742] time: 3:26:30.135621\n",
      "[Epoch 5/10] [Batch 212/350] [D loss: 0.251307, acc:  46%] [G loss: 0.953521] time: 3:26:36.528528\n",
      "[Epoch 5/10] [Batch 213/350] [D loss: 0.251489, acc:  48%] [G loss: 1.118489] time: 3:26:42.877552\n",
      "[Epoch 5/10] [Batch 214/350] [D loss: 0.251097, acc:  48%] [G loss: 1.074630] time: 3:26:49.172720\n",
      "[Epoch 5/10] [Batch 215/350] [D loss: 0.251047, acc:  49%] [G loss: 1.215492] time: 3:26:55.459941\n",
      "[Epoch 5/10] [Batch 216/350] [D loss: 0.250976, acc:  48%] [G loss: 1.036439] time: 3:27:01.744107\n",
      "[Epoch 5/10] [Batch 217/350] [D loss: 0.251123, acc:  49%] [G loss: 0.992625] time: 3:27:08.041269\n",
      "[Epoch 5/10] [Batch 218/350] [D loss: 0.251151, acc:  48%] [G loss: 1.128550] time: 3:27:14.398272\n",
      "[Epoch 5/10] [Batch 219/350] [D loss: 0.252015, acc:  39%] [G loss: 1.103676] time: 3:27:20.723361\n",
      "[Epoch 5/10] [Batch 220/350] [D loss: 0.252327, acc:  47%] [G loss: 1.407785] time: 3:27:27.023515\n",
      "[Epoch 5/10] [Batch 221/350] [D loss: 0.251877, acc:  46%] [G loss: 1.020426] time: 3:27:33.310704\n",
      "[Epoch 5/10] [Batch 222/350] [D loss: 0.251328, acc:  49%] [G loss: 1.074964] time: 3:27:39.598891\n",
      "[Epoch 5/10] [Batch 223/350] [D loss: 0.251564, acc:  51%] [G loss: 1.274231] time: 3:27:45.907024\n",
      "[Epoch 5/10] [Batch 224/350] [D loss: 0.251681, acc:  49%] [G loss: 1.239947] time: 3:27:52.198203\n",
      "[Epoch 5/10] [Batch 225/350] [D loss: 0.251064, acc:  51%] [G loss: 1.111454] time: 3:27:58.484395\n",
      "[Epoch 5/10] [Batch 226/350] [D loss: 0.251072, acc:  46%] [G loss: 1.190689] time: 3:28:04.786544\n",
      "[Epoch 5/10] [Batch 227/350] [D loss: 0.251417, acc:  47%] [G loss: 1.228788] time: 3:28:11.098667\n",
      "[Epoch 5/10] [Batch 228/350] [D loss: 0.251469, acc:  48%] [G loss: 1.184642] time: 3:28:17.362917\n",
      "[Epoch 5/10] [Batch 229/350] [D loss: 0.251198, acc:  48%] [G loss: 1.175060] time: 3:28:23.680027\n",
      "[Epoch 5/10] [Batch 230/350] [D loss: 0.251367, acc:  52%] [G loss: 1.202552] time: 3:28:29.964224\n",
      "[Epoch 5/10] [Batch 231/350] [D loss: 0.251492, acc:  45%] [G loss: 1.322928] time: 3:28:36.227509\n",
      "[Epoch 5/10] [Batch 232/350] [D loss: 0.251420, acc:  51%] [G loss: 1.134290] time: 3:28:42.500736\n",
      "[Epoch 5/10] [Batch 233/350] [D loss: 0.251418, acc:  47%] [G loss: 1.062571] time: 3:28:48.789889\n",
      "[Epoch 5/10] [Batch 234/350] [D loss: 0.251391, acc:  49%] [G loss: 1.226065] time: 3:28:55.090043\n",
      "[Epoch 5/10] [Batch 235/350] [D loss: 0.251190, acc:  48%] [G loss: 1.198202] time: 3:29:01.391226\n",
      "[Epoch 5/10] [Batch 236/350] [D loss: 0.251289, acc:  43%] [G loss: 1.102945] time: 3:29:07.683371\n",
      "[Epoch 5/10] [Batch 237/350] [D loss: 0.251285, acc:  48%] [G loss: 1.144498] time: 3:29:13.987514\n",
      "[Epoch 5/10] [Batch 238/350] [D loss: 0.251113, acc:  49%] [G loss: 1.113442] time: 3:29:20.272709\n",
      "[Epoch 5/10] [Batch 239/350] [D loss: 0.250971, acc:  46%] [G loss: 1.089332] time: 3:29:26.571867\n",
      "[Epoch 5/10] [Batch 240/350] [D loss: 0.251209, acc:  46%] [G loss: 1.173225] time: 3:29:32.870027\n",
      "[Epoch 5/10] [Batch 241/350] [D loss: 0.251245, acc:  48%] [G loss: 1.158153] time: 3:29:39.153227\n",
      "[Epoch 5/10] [Batch 242/350] [D loss: 0.251184, acc:  44%] [G loss: 1.103523] time: 3:29:45.462357\n",
      "[Epoch 5/10] [Batch 243/350] [D loss: 0.251696, acc:  41%] [G loss: 1.407933] time: 3:29:51.781462\n",
      "[Epoch 5/10] [Batch 244/350] [D loss: 0.251556, acc:  48%] [G loss: 1.066854] time: 3:29:58.070646\n",
      "[Epoch 5/10] [Batch 245/350] [D loss: 0.251182, acc:  50%] [G loss: 1.228163] time: 3:30:04.365814\n",
      "[Epoch 5/10] [Batch 246/350] [D loss: 0.251209, acc:  54%] [G loss: 1.202460] time: 3:30:10.678933\n",
      "[Epoch 5/10] [Batch 247/350] [D loss: 0.251389, acc:  48%] [G loss: 1.084546] time: 3:30:16.987098\n",
      "[Epoch 5/10] [Batch 248/350] [D loss: 0.251170, acc:  44%] [G loss: 1.303423] time: 3:30:23.264283\n",
      "[Epoch 5/10] [Batch 249/350] [D loss: 0.251164, acc:  51%] [G loss: 1.388240] time: 3:30:29.560448\n",
      "[Epoch 5/10] [Batch 250/350] [D loss: 0.251293, acc:  46%] [G loss: 1.308227] time: 3:30:35.865590\n",
      "[Epoch 5/10] [Batch 251/350] [D loss: 0.251122, acc:  51%] [G loss: 1.157465] time: 3:30:42.146795\n",
      "[Epoch 5/10] [Batch 252/350] [D loss: 0.251337, acc:  49%] [G loss: 1.047222] time: 3:30:48.436976\n",
      "[Epoch 5/10] [Batch 253/350] [D loss: 0.251239, acc:  50%] [G loss: 1.259045] time: 3:30:54.742118\n",
      "[Epoch 5/10] [Batch 254/350] [D loss: 0.251299, acc:  47%] [G loss: 1.147620] time: 3:31:01.033296\n",
      "[Epoch 5/10] [Batch 255/350] [D loss: 0.251203, acc:  48%] [G loss: 1.149682] time: 3:31:07.328464\n",
      "[Epoch 5/10] [Batch 256/350] [D loss: 0.251370, acc:  43%] [G loss: 1.047885] time: 3:31:13.632608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/10] [Batch 257/350] [D loss: 0.251206, acc:  46%] [G loss: 1.269703] time: 3:31:19.934757\n",
      "[Epoch 5/10] [Batch 258/350] [D loss: 0.251052, acc:  46%] [G loss: 1.207968] time: 3:31:26.223973\n",
      "[Epoch 5/10] [Batch 259/350] [D loss: 0.250932, acc:  46%] [G loss: 0.977127] time: 3:31:32.518112\n",
      "[Epoch 5/10] [Batch 260/350] [D loss: 0.250973, acc:  49%] [G loss: 1.115195] time: 3:31:38.823254\n",
      "[Epoch 5/10] [Batch 261/350] [D loss: 0.251137, acc:  48%] [G loss: 1.082656] time: 3:31:45.160309\n",
      "[Epoch 5/10] [Batch 262/350] [D loss: 0.251097, acc:  46%] [G loss: 1.405322] time: 3:31:51.454480\n",
      "[Epoch 5/10] [Batch 263/350] [D loss: 0.251164, acc:  47%] [G loss: 1.175286] time: 3:31:57.744661\n",
      "[Epoch 5/10] [Batch 264/350] [D loss: 0.251111, acc:  48%] [G loss: 1.163254] time: 3:32:04.027861\n",
      "[Epoch 5/10] [Batch 265/350] [D loss: 0.251440, acc:  48%] [G loss: 1.026200] time: 3:32:10.322032\n",
      "[Epoch 5/10] [Batch 266/350] [D loss: 0.251464, acc:  49%] [G loss: 1.059124] time: 3:32:16.702005\n",
      "[Epoch 5/10] [Batch 267/350] [D loss: 0.251358, acc:  49%] [G loss: 1.023292] time: 3:32:23.016091\n",
      "[Epoch 5/10] [Batch 268/350] [D loss: 0.251526, acc:  53%] [G loss: 1.155626] time: 3:32:29.297296\n",
      "[Epoch 5/10] [Batch 269/350] [D loss: 0.251675, acc:  47%] [G loss: 1.143842] time: 3:32:35.595488\n",
      "[Epoch 5/10] [Batch 270/350] [D loss: 0.251376, acc:  38%] [G loss: 1.259089] time: 3:32:41.863696\n",
      "[Epoch 5/10] [Batch 271/350] [D loss: 0.251373, acc:  50%] [G loss: 1.012871] time: 3:32:48.173824\n",
      "[Epoch 5/10] [Batch 272/350] [D loss: 0.251325, acc:  49%] [G loss: 1.199817] time: 3:32:54.477968\n",
      "[Epoch 5/10] [Batch 273/350] [D loss: 0.251158, acc:  51%] [G loss: 1.266269] time: 3:33:00.763163\n",
      "[Epoch 5/10] [Batch 274/350] [D loss: 0.250903, acc:  50%] [G loss: 1.304344] time: 3:33:07.073291\n",
      "[Epoch 5/10] [Batch 275/350] [D loss: 0.251378, acc:  48%] [G loss: 1.206149] time: 3:33:13.371451\n",
      "[Epoch 5/10] [Batch 276/350] [D loss: 0.251270, acc:  55%] [G loss: 1.092442] time: 3:33:19.660668\n",
      "[Epoch 5/10] [Batch 277/350] [D loss: 0.251404, acc:  49%] [G loss: 1.063119] time: 3:33:25.979772\n",
      "[Epoch 5/10] [Batch 278/350] [D loss: 0.251134, acc:  47%] [G loss: 1.129387] time: 3:33:32.284911\n",
      "[Epoch 5/10] [Batch 279/350] [D loss: 0.251184, acc:  47%] [G loss: 1.135899] time: 3:33:38.591019\n",
      "[Epoch 5/10] [Batch 280/350] [D loss: 0.251098, acc:  49%] [G loss: 1.114834] time: 3:33:44.929104\n",
      "[Epoch 5/10] [Batch 281/350] [D loss: 0.251119, acc:  48%] [G loss: 1.110470] time: 3:33:51.221248\n",
      "[Epoch 5/10] [Batch 282/350] [D loss: 0.251396, acc:  50%] [G loss: 1.165567] time: 3:33:57.504448\n",
      "[Epoch 5/10] [Batch 283/350] [D loss: 0.251535, acc:  46%] [G loss: 1.033354] time: 3:34:03.785654\n",
      "[Epoch 5/10] [Batch 284/350] [D loss: 0.251601, acc:  49%] [G loss: 1.098848] time: 3:34:10.083813\n",
      "[Epoch 5/10] [Batch 285/350] [D loss: 0.251190, acc:  46%] [G loss: 1.074696] time: 3:34:16.372000\n",
      "[Epoch 5/10] [Batch 286/350] [D loss: 0.251122, acc:  47%] [G loss: 1.078757] time: 3:34:22.654203\n",
      "[Epoch 5/10] [Batch 287/350] [D loss: 0.250955, acc:  46%] [G loss: 1.112713] time: 3:34:28.965328\n",
      "[Epoch 5/10] [Batch 288/350] [D loss: 0.251160, acc:  47%] [G loss: 1.177096] time: 3:34:35.280443\n",
      "[Epoch 5/10] [Batch 289/350] [D loss: 0.251234, acc:  54%] [G loss: 1.286537] time: 3:34:41.531728\n",
      "[Epoch 5/10] [Batch 290/350] [D loss: 0.251268, acc:  49%] [G loss: 1.027572] time: 3:34:47.831883\n",
      "[Epoch 5/10] [Batch 291/350] [D loss: 0.251410, acc:  45%] [G loss: 1.237427] time: 3:34:54.130043\n",
      "[Epoch 5/10] [Batch 292/350] [D loss: 0.251153, acc:  49%] [G loss: 1.057212] time: 3:35:00.429232\n",
      "[Epoch 5/10] [Batch 293/350] [D loss: 0.251122, acc:  48%] [G loss: 1.408488] time: 3:35:06.726394\n",
      "[Epoch 5/10] [Batch 294/350] [D loss: 0.251215, acc:  54%] [G loss: 1.148889] time: 3:35:13.006571\n",
      "[Epoch 5/10] [Batch 295/350] [D loss: 0.251368, acc:  49%] [G loss: 1.107282] time: 3:35:19.260848\n",
      "[Epoch 5/10] [Batch 296/350] [D loss: 0.251133, acc:  44%] [G loss: 1.210184] time: 3:35:25.569979\n",
      "[Epoch 5/10] [Batch 297/350] [D loss: 0.251031, acc:  49%] [G loss: 1.187120] time: 3:35:31.855173\n",
      "[Epoch 5/10] [Batch 298/350] [D loss: 0.251048, acc:  49%] [G loss: 1.193403] time: 3:35:38.144389\n",
      "[Epoch 5/10] [Batch 299/350] [D loss: 0.251113, acc:  48%] [G loss: 1.388465] time: 3:35:44.484405\n",
      "[Epoch 5/10] [Batch 300/350] [D loss: 0.251442, acc:  48%] [G loss: 1.371523] time: 3:35:50.776582\n",
      "[Epoch 5/10] [Batch 301/350] [D loss: 0.251525, acc:  49%] [G loss: 1.327124] time: 3:35:57.059782\n",
      "[Epoch 5/10] [Batch 302/350] [D loss: 0.251456, acc:  49%] [G loss: 1.054431] time: 3:36:03.343979\n",
      "[Epoch 5/10] [Batch 303/350] [D loss: 0.251268, acc:  52%] [G loss: 1.132653] time: 3:36:09.649120\n",
      "[Epoch 5/10] [Batch 304/350] [D loss: 0.251579, acc:  47%] [G loss: 0.990425] time: 3:36:15.944288\n",
      "[Epoch 5/10] [Batch 305/350] [D loss: 0.251565, acc:  50%] [G loss: 1.100042] time: 3:36:22.224528\n",
      "[Epoch 5/10] [Batch 306/350] [D loss: 0.251089, acc:  49%] [G loss: 1.107210] time: 3:36:28.539611\n",
      "[Epoch 5/10] [Batch 307/350] [D loss: 0.251118, acc:  46%] [G loss: 1.215151] time: 3:36:34.841760\n",
      "[Epoch 5/10] [Batch 308/350] [D loss: 0.251072, acc:  50%] [G loss: 1.125988] time: 3:36:41.125957\n",
      "[Epoch 5/10] [Batch 309/350] [D loss: 0.251098, acc:  49%] [G loss: 1.118329] time: 3:36:47.416139\n",
      "[Epoch 5/10] [Batch 310/350] [D loss: 0.251153, acc:  48%] [G loss: 1.171770] time: 3:36:53.721281\n",
      "[Epoch 5/10] [Batch 311/350] [D loss: 0.250999, acc:  45%] [G loss: 1.234617] time: 3:37:00.027450\n",
      "[Epoch 5/10] [Batch 312/350] [D loss: 0.251796, acc:  48%] [G loss: 1.129846] time: 3:37:06.290672\n",
      "[Epoch 5/10] [Batch 313/350] [D loss: 0.251813, acc:  50%] [G loss: 0.958336] time: 3:37:12.589830\n",
      "[Epoch 5/10] [Batch 314/350] [D loss: 0.252194, acc:  49%] [G loss: 1.235271] time: 3:37:18.898960\n",
      "[Epoch 5/10] [Batch 315/350] [D loss: 0.251691, acc:  48%] [G loss: 1.174794] time: 3:37:25.213077\n",
      "[Epoch 5/10] [Batch 316/350] [D loss: 0.251724, acc:  51%] [G loss: 1.235100] time: 3:37:31.512235\n",
      "[Epoch 5/10] [Batch 317/350] [D loss: 0.252532, acc:  51%] [G loss: 1.193759] time: 3:37:37.811392\n",
      "[Epoch 5/10] [Batch 318/350] [D loss: 0.252142, acc:  47%] [G loss: 1.170679] time: 3:37:44.130496\n",
      "[Epoch 5/10] [Batch 319/350] [D loss: 0.251214, acc:  51%] [G loss: 1.073647] time: 3:37:50.391755\n",
      "[Epoch 5/10] [Batch 320/350] [D loss: 0.251461, acc:  48%] [G loss: 1.098323] time: 3:37:56.681936\n",
      "[Epoch 5/10] [Batch 321/350] [D loss: 0.251767, acc:  48%] [G loss: 1.130713] time: 3:38:02.988109\n",
      "[Epoch 5/10] [Batch 322/350] [D loss: 0.251393, acc:  49%] [G loss: 1.256899] time: 3:38:09.282277\n",
      "[Epoch 5/10] [Batch 323/350] [D loss: 0.251293, acc:  50%] [G loss: 1.159752] time: 3:38:15.577413\n",
      "[Epoch 5/10] [Batch 324/350] [D loss: 0.251245, acc:  48%] [G loss: 1.102196] time: 3:38:21.879563\n",
      "[Epoch 5/10] [Batch 325/350] [D loss: 0.251076, acc:  45%] [G loss: 1.212234] time: 3:38:28.166752\n",
      "[Epoch 5/10] [Batch 326/350] [D loss: 0.251432, acc:  51%] [G loss: 1.152622] time: 3:38:34.435989\n",
      "[Epoch 5/10] [Batch 327/350] [D loss: 0.251345, acc:  44%] [G loss: 1.106519] time: 3:38:40.725173\n",
      "[Epoch 5/10] [Batch 328/350] [D loss: 0.251328, acc:  47%] [G loss: 1.093476] time: 3:38:47.023333\n",
      "[Epoch 5/10] [Batch 329/350] [D loss: 0.251113, acc:  48%] [G loss: 1.159731] time: 3:38:53.319531\n",
      "[Epoch 5/10] [Batch 330/350] [D loss: 0.251123, acc:  49%] [G loss: 1.212363] time: 3:38:59.592757\n",
      "[Epoch 5/10] [Batch 331/350] [D loss: 0.251187, acc:  48%] [G loss: 1.295445] time: 3:39:05.892880\n",
      "[Epoch 5/10] [Batch 332/350] [D loss: 0.251334, acc:  46%] [G loss: 1.248908] time: 3:39:12.156134\n",
      "[Epoch 5/10] [Batch 333/350] [D loss: 0.251361, acc:  46%] [G loss: 1.077144] time: 3:39:18.454294\n",
      "[Epoch 5/10] [Batch 334/350] [D loss: 0.251240, acc:  46%] [G loss: 1.121243] time: 3:39:24.762427\n",
      "[Epoch 5/10] [Batch 335/350] [D loss: 0.251404, acc:  43%] [G loss: 1.290569] time: 3:39:31.059590\n",
      "[Epoch 5/10] [Batch 336/350] [D loss: 0.251425, acc:  49%] [G loss: 1.251438] time: 3:39:37.375702\n",
      "[Epoch 5/10] [Batch 337/350] [D loss: 0.251145, acc:  51%] [G loss: 1.136389] time: 3:39:43.706773\n",
      "[Epoch 5/10] [Batch 338/350] [D loss: 0.251088, acc:  49%] [G loss: 1.317137] time: 3:39:50.003936\n",
      "[Epoch 5/10] [Batch 339/350] [D loss: 0.250911, acc:  46%] [G loss: 1.061115] time: 3:39:56.287168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/10] [Batch 340/350] [D loss: 0.251344, acc:  39%] [G loss: 1.018480] time: 3:40:02.586293\n",
      "[Epoch 5/10] [Batch 341/350] [D loss: 0.251459, acc:  48%] [G loss: 1.060573] time: 3:40:08.863541\n",
      "[Epoch 5/10] [Batch 342/350] [D loss: 0.251408, acc:  44%] [G loss: 1.369897] time: 3:40:15.137734\n",
      "[Epoch 5/10] [Batch 343/350] [D loss: 0.251413, acc:  48%] [G loss: 1.151997] time: 3:40:21.430906\n",
      "[Epoch 5/10] [Batch 344/350] [D loss: 0.251796, acc:  46%] [G loss: 1.304636] time: 3:40:27.724080\n",
      "[Epoch 5/10] [Batch 345/350] [D loss: 0.251671, acc:  51%] [G loss: 1.133165] time: 3:40:34.060139\n",
      "[Epoch 5/10] [Batch 346/350] [D loss: 0.251453, acc:  47%] [G loss: 1.131142] time: 3:40:40.354310\n",
      "[Epoch 5/10] [Batch 347/350] [D loss: 0.251630, acc:  55%] [G loss: 1.154408] time: 3:40:46.624544\n",
      "[Epoch 5/10] [Batch 348/350] [D loss: 0.251650, acc:  49%] [G loss: 1.077991] time: 3:40:52.904784\n",
      "weights saved...\n",
      "[Epoch 6/10] [Batch 0/350] [D loss: 0.251167, acc:  49%] [G loss: 1.096740] time: 3:40:59.525051\n",
      "[Epoch 6/10] [Batch 1/350] [D loss: 0.251009, acc:  49%] [G loss: 1.070692] time: 3:41:11.412267\n",
      "[Epoch 6/10] [Batch 2/350] [D loss: 0.251199, acc:  47%] [G loss: 1.200616] time: 3:41:17.694470\n",
      "[Epoch 6/10] [Batch 3/350] [D loss: 0.251457, acc:  51%] [G loss: 1.370555] time: 3:41:23.977669\n",
      "[Epoch 6/10] [Batch 4/350] [D loss: 0.251466, acc:  50%] [G loss: 1.328992] time: 3:41:30.270843\n",
      "[Epoch 6/10] [Batch 5/350] [D loss: 0.251170, acc:  51%] [G loss: 1.300210] time: 3:41:36.576981\n",
      "[Epoch 6/10] [Batch 6/350] [D loss: 0.251399, acc:  40%] [G loss: 1.279770] time: 3:41:42.924011\n",
      "[Epoch 6/10] [Batch 7/350] [D loss: 0.251248, acc:  45%] [G loss: 1.209065] time: 3:41:49.196240\n",
      "[Epoch 6/10] [Batch 8/350] [D loss: 0.251414, acc:  44%] [G loss: 1.062249] time: 3:41:55.509360\n",
      "[Epoch 6/10] [Batch 9/350] [D loss: 0.251576, acc:  50%] [G loss: 1.153857] time: 3:42:01.789568\n",
      "[Epoch 6/10] [Batch 10/350] [D loss: 0.251396, acc:  43%] [G loss: 1.238150] time: 3:42:08.073765\n",
      "[Epoch 6/10] [Batch 11/350] [D loss: 0.251713, acc:  49%] [G loss: 1.369322] time: 3:42:14.399851\n",
      "[Epoch 6/10] [Batch 12/350] [D loss: 0.252070, acc:  51%] [G loss: 1.147296] time: 3:42:20.702000\n",
      "[Epoch 6/10] [Batch 13/350] [D loss: 0.251872, acc:  47%] [G loss: 1.051863] time: 3:42:26.985200\n",
      "[Epoch 6/10] [Batch 14/350] [D loss: 0.251088, acc:  48%] [G loss: 1.062920] time: 3:42:33.294331\n",
      "[Epoch 6/10] [Batch 15/350] [D loss: 0.251113, acc:  49%] [G loss: 1.051959] time: 3:42:39.590496\n",
      "[Epoch 6/10] [Batch 16/350] [D loss: 0.251117, acc:  45%] [G loss: 1.038087] time: 3:42:45.869707\n",
      "[Epoch 6/10] [Batch 17/350] [D loss: 0.251165, acc:  50%] [G loss: 1.434193] time: 3:42:52.133958\n",
      "[Epoch 6/10] [Batch 18/350] [D loss: 0.251176, acc:  48%] [G loss: 1.207720] time: 3:42:58.406187\n",
      "[Epoch 6/10] [Batch 19/350] [D loss: 0.251175, acc:  45%] [G loss: 1.155487] time: 3:43:04.700389\n",
      "[Epoch 6/10] [Batch 20/350] [D loss: 0.251180, acc:  43%] [G loss: 1.335025] time: 3:43:10.997520\n",
      "[Epoch 6/10] [Batch 21/350] [D loss: 0.251305, acc:  49%] [G loss: 1.193445] time: 3:43:17.274736\n",
      "[Epoch 6/10] [Batch 22/350] [D loss: 0.251205, acc:  48%] [G loss: 1.049910] time: 3:43:23.564918\n",
      "[Epoch 6/10] [Batch 23/350] [D loss: 0.250886, acc:  47%] [G loss: 1.253567] time: 3:43:29.868064\n",
      "[Epoch 6/10] [Batch 24/350] [D loss: 0.251152, acc:  48%] [G loss: 1.078754] time: 3:43:36.158245\n",
      "[Epoch 6/10] [Batch 25/350] [D loss: 0.251075, acc:  45%] [G loss: 1.084899] time: 3:43:42.502283\n",
      "[Epoch 6/10] [Batch 26/350] [D loss: 0.251049, acc:  48%] [G loss: 1.140931] time: 3:43:48.783517\n",
      "[Epoch 6/10] [Batch 27/350] [D loss: 0.251127, acc:  46%] [G loss: 1.173525] time: 3:43:55.081648\n",
      "[Epoch 6/10] [Batch 28/350] [D loss: 0.251253, acc:  42%] [G loss: 1.069098] time: 3:44:01.378842\n",
      "[Epoch 6/10] [Batch 29/350] [D loss: 0.251150, acc:  46%] [G loss: 1.121820] time: 3:44:07.684950\n",
      "[Epoch 6/10] [Batch 30/350] [D loss: 0.251019, acc:  49%] [G loss: 1.075681] time: 3:44:13.971141\n",
      "[Epoch 6/10] [Batch 31/350] [D loss: 0.250996, acc:  47%] [G loss: 1.128134] time: 3:44:20.257365\n",
      "[Epoch 6/10] [Batch 32/350] [D loss: 0.251035, acc:  46%] [G loss: 1.083640] time: 3:44:26.571451\n",
      "[Epoch 6/10] [Batch 33/350] [D loss: 0.251075, acc:  47%] [G loss: 1.133579] time: 3:44:32.849698\n",
      "[Epoch 6/10] [Batch 34/350] [D loss: 0.251267, acc:  51%] [G loss: 1.090537] time: 3:44:39.141840\n",
      "[Epoch 6/10] [Batch 35/350] [D loss: 0.251192, acc:  52%] [G loss: 0.987808] time: 3:44:45.435045\n",
      "[Epoch 6/10] [Batch 36/350] [D loss: 0.251109, acc:  51%] [G loss: 0.992846] time: 3:44:51.725195\n",
      "[Epoch 6/10] [Batch 37/350] [D loss: 0.251078, acc:  48%] [G loss: 1.224990] time: 3:44:58.005434\n",
      "[Epoch 6/10] [Batch 38/350] [D loss: 0.251323, acc:  48%] [G loss: 1.227455] time: 3:45:04.300571\n",
      "[Epoch 6/10] [Batch 39/350] [D loss: 0.251097, acc:  48%] [G loss: 1.090293] time: 3:45:10.592748\n",
      "[Epoch 6/10] [Batch 40/350] [D loss: 0.251205, acc:  47%] [G loss: 1.214615] time: 3:45:16.885952\n",
      "[Epoch 6/10] [Batch 41/350] [D loss: 0.251442, acc:  46%] [G loss: 1.231120] time: 3:45:23.205024\n",
      "[Epoch 6/10] [Batch 42/350] [D loss: 0.251230, acc:  49%] [G loss: 1.034482] time: 3:45:29.482272\n",
      "[Epoch 6/10] [Batch 43/350] [D loss: 0.251356, acc:  48%] [G loss: 1.200082] time: 3:45:35.777408\n",
      "[Epoch 6/10] [Batch 44/350] [D loss: 0.251192, acc:  45%] [G loss: 1.174746] time: 3:45:42.108480\n",
      "[Epoch 6/10] [Batch 45/350] [D loss: 0.251316, acc:  48%] [G loss: 1.111931] time: 3:45:48.387691\n",
      "[Epoch 6/10] [Batch 46/350] [D loss: 0.250985, acc:  49%] [G loss: 1.039698] time: 3:45:54.671888\n",
      "[Epoch 6/10] [Batch 47/350] [D loss: 0.250985, acc:  47%] [G loss: 1.135164] time: 3:46:00.958080\n",
      "[Epoch 6/10] [Batch 48/350] [D loss: 0.251135, acc:  46%] [G loss: 1.185424] time: 3:46:07.258235\n",
      "[Epoch 6/10] [Batch 49/350] [D loss: 0.251090, acc:  49%] [G loss: 0.987443] time: 3:46:13.562379\n",
      "[Epoch 6/10] [Batch 50/350] [D loss: 0.251061, acc:  48%] [G loss: 1.010383] time: 3:46:19.841590\n",
      "[Epoch 6/10] [Batch 51/350] [D loss: 0.251366, acc:  46%] [G loss: 0.992054] time: 3:46:26.143739\n",
      "[Epoch 6/10] [Batch 52/350] [D loss: 0.251356, acc:  49%] [G loss: 1.011588] time: 3:46:32.441927\n",
      "[Epoch 6/10] [Batch 53/350] [D loss: 0.251443, acc:  50%] [G loss: 0.997871] time: 3:46:38.764992\n",
      "[Epoch 6/10] [Batch 54/350] [D loss: 0.251250, acc:  51%] [G loss: 1.143187] time: 3:46:45.060160\n",
      "[Epoch 6/10] [Batch 55/350] [D loss: 0.251222, acc:  50%] [G loss: 1.091468] time: 3:46:51.355328\n",
      "[Epoch 6/10] [Batch 56/350] [D loss: 0.250976, acc:  48%] [G loss: 1.266310] time: 3:46:57.645510\n",
      "[Epoch 6/10] [Batch 57/350] [D loss: 0.251217, acc:  56%] [G loss: 1.155636] time: 3:47:03.904774\n",
      "[Epoch 6/10] [Batch 58/350] [D loss: 0.251322, acc:  51%] [G loss: 1.204237] time: 3:47:10.204928\n",
      "[Epoch 6/10] [Batch 59/350] [D loss: 0.251273, acc:  52%] [G loss: 1.146128] time: 3:47:16.589856\n",
      "[Epoch 6/10] [Batch 60/350] [D loss: 0.251481, acc:  52%] [G loss: 1.216140] time: 3:47:22.882032\n",
      "[Epoch 6/10] [Batch 61/350] [D loss: 0.251421, acc:  47%] [G loss: 1.360918] time: 3:47:29.193157\n",
      "[Epoch 6/10] [Batch 62/350] [D loss: 0.251177, acc:  41%] [G loss: 1.136648] time: 3:47:35.491317\n",
      "[Epoch 6/10] [Batch 63/350] [D loss: 0.251205, acc:  49%] [G loss: 1.237002] time: 3:47:41.805435\n",
      "[Epoch 6/10] [Batch 64/350] [D loss: 0.251148, acc:  47%] [G loss: 1.330868] time: 3:47:48.086641\n",
      "[Epoch 6/10] [Batch 65/350] [D loss: 0.251449, acc:  45%] [G loss: 1.184996] time: 3:47:54.401786\n",
      "[Epoch 6/10] [Batch 66/350] [D loss: 0.251228, acc:  49%] [G loss: 1.225392] time: 3:48:00.707894\n",
      "[Epoch 6/10] [Batch 67/350] [D loss: 0.251290, acc:  49%] [G loss: 1.233356] time: 3:48:06.991125\n",
      "[Epoch 6/10] [Batch 68/350] [D loss: 0.251678, acc:  48%] [G loss: 1.123454] time: 3:48:13.300256\n",
      "[Epoch 6/10] [Batch 69/350] [D loss: 0.251789, acc:  46%] [G loss: 1.242409] time: 3:48:19.601376\n",
      "[Epoch 6/10] [Batch 70/350] [D loss: 0.251873, acc:  47%] [G loss: 1.186594] time: 3:48:25.883579\n",
      "[Epoch 6/10] [Batch 71/350] [D loss: 0.251529, acc:  48%] [G loss: 1.186777] time: 3:48:32.174789\n",
      "[Epoch 6/10] [Batch 72/350] [D loss: 0.251699, acc:  51%] [G loss: 1.192274] time: 3:48:38.460982\n",
      "[Epoch 6/10] [Batch 73/350] [D loss: 0.251646, acc:  51%] [G loss: 1.135509] time: 3:48:44.748139\n",
      "[Epoch 6/10] [Batch 74/350] [D loss: 0.251792, acc:  49%] [G loss: 1.321743] time: 3:48:51.030342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/10] [Batch 75/350] [D loss: 0.252354, acc:  48%] [G loss: 1.258148] time: 3:48:57.304566\n",
      "[Epoch 6/10] [Batch 76/350] [D loss: 0.252202, acc:  48%] [G loss: 1.459424] time: 3:49:03.590757\n",
      "[Epoch 6/10] [Batch 77/350] [D loss: 0.251443, acc:  52%] [G loss: 1.167191] time: 3:49:09.883931\n",
      "[Epoch 6/10] [Batch 78/350] [D loss: 0.251827, acc:  52%] [G loss: 1.172612] time: 3:49:16.169125\n",
      "[Epoch 6/10] [Batch 79/350] [D loss: 0.251571, acc:  47%] [G loss: 1.337934] time: 3:49:22.481248\n",
      "[Epoch 6/10] [Batch 80/350] [D loss: 0.251618, acc:  50%] [G loss: 1.234502] time: 3:49:28.780436\n",
      "[Epoch 6/10] [Batch 81/350] [D loss: 0.252354, acc:  53%] [G loss: 1.311661] time: 3:49:35.071584\n",
      "[Epoch 6/10] [Batch 82/350] [D loss: 0.252362, acc:  51%] [G loss: 1.052827] time: 3:49:41.404678\n",
      "[Epoch 6/10] [Batch 83/350] [D loss: 0.251998, acc:  50%] [G loss: 1.258134] time: 3:49:47.716773\n",
      "[Epoch 6/10] [Batch 84/350] [D loss: 0.252212, acc:  46%] [G loss: 1.386678] time: 3:49:54.000971\n",
      "[Epoch 6/10] [Batch 85/350] [D loss: 0.251836, acc:  47%] [G loss: 1.248888] time: 3:50:00.285168\n",
      "[Epoch 6/10] [Batch 86/350] [D loss: 0.251590, acc:  50%] [G loss: 1.117093] time: 3:50:06.563413\n",
      "[Epoch 6/10] [Batch 87/350] [D loss: 0.252093, acc:  52%] [G loss: 1.352385] time: 3:50:12.844587\n",
      "[Epoch 6/10] [Batch 88/350] [D loss: 0.251926, acc:  50%] [G loss: 1.060549] time: 3:50:19.149728\n",
      "[Epoch 6/10] [Batch 89/350] [D loss: 0.251210, acc:  52%] [G loss: 1.170903] time: 3:50:25.452875\n",
      "[Epoch 6/10] [Batch 90/350] [D loss: 0.251177, acc:  50%] [G loss: 1.118668] time: 3:50:31.731088\n",
      "[Epoch 6/10] [Batch 91/350] [D loss: 0.251088, acc:  48%] [G loss: 1.031994] time: 3:50:38.007338\n",
      "[Epoch 6/10] [Batch 92/350] [D loss: 0.251283, acc:  47%] [G loss: 1.065088] time: 3:50:44.301510\n",
      "[Epoch 6/10] [Batch 93/350] [D loss: 0.251064, acc:  49%] [G loss: 1.126583] time: 3:50:50.611606\n",
      "[Epoch 6/10] [Batch 94/350] [D loss: 0.251077, acc:  48%] [G loss: 1.196037] time: 3:50:56.899792\n",
      "[Epoch 6/10] [Batch 95/350] [D loss: 0.251069, acc:  47%] [G loss: 1.188884] time: 3:51:03.206928\n",
      "[Epoch 6/10] [Batch 96/350] [D loss: 0.251079, acc:  50%] [G loss: 1.024675] time: 3:51:09.488167\n",
      "[Epoch 6/10] [Batch 97/350] [D loss: 0.251179, acc:  49%] [G loss: 1.285447] time: 3:51:15.770336\n",
      "[Epoch 6/10] [Batch 98/350] [D loss: 0.251173, acc:  49%] [G loss: 1.065451] time: 3:51:22.035584\n",
      "[Epoch 6/10] [Batch 99/350] [D loss: 0.251060, acc:  45%] [G loss: 1.137992] time: 3:51:28.332747\n",
      "[Epoch 6/10] [Batch 100/350] [D loss: 0.251086, acc:  52%] [G loss: 1.223631] time: 3:51:34.608966\n",
      "[Epoch 6/10] [Batch 101/350] [D loss: 0.251349, acc:  50%] [G loss: 1.056173] time: 3:51:40.935051\n",
      "[Epoch 6/10] [Batch 102/350] [D loss: 0.252256, acc:  56%] [G loss: 1.331163] time: 3:51:47.224234\n",
      "[Epoch 6/10] [Batch 103/350] [D loss: 0.252657, acc:  49%] [G loss: 1.246923] time: 3:51:53.518405\n",
      "[Epoch 6/10] [Batch 104/350] [D loss: 0.251850, acc:  54%] [G loss: 1.238872] time: 3:51:59.825541\n",
      "[Epoch 6/10] [Batch 105/350] [D loss: 0.251659, acc:  41%] [G loss: 1.150524] time: 3:52:06.128722\n",
      "[Epoch 6/10] [Batch 106/350] [D loss: 0.251838, acc:  51%] [G loss: 1.369354] time: 3:52:12.413883\n",
      "[Epoch 6/10] [Batch 107/350] [D loss: 0.251385, acc:  53%] [G loss: 0.993322] time: 3:52:18.740965\n",
      "[Epoch 6/10] [Batch 108/350] [D loss: 0.251599, acc:  46%] [G loss: 1.157946] time: 3:52:25.045110\n",
      "[Epoch 6/10] [Batch 109/350] [D loss: 0.252627, acc:  52%] [G loss: 1.169572] time: 3:52:31.329307\n",
      "[Epoch 6/10] [Batch 110/350] [D loss: 0.252204, acc:  49%] [G loss: 1.335061] time: 3:52:37.608517\n",
      "[Epoch 6/10] [Batch 111/350] [D loss: 0.251706, acc:  46%] [G loss: 1.157045] time: 3:52:43.904683\n",
      "[Epoch 6/10] [Batch 112/350] [D loss: 0.252567, acc:  50%] [G loss: 1.369966] time: 3:52:50.204868\n",
      "[Epoch 6/10] [Batch 113/350] [D loss: 0.252487, acc:  50%] [G loss: 1.140628] time: 3:52:56.506987\n",
      "[Epoch 6/10] [Batch 114/350] [D loss: 0.251580, acc:  47%] [G loss: 1.149507] time: 3:53:02.802186\n",
      "[Epoch 6/10] [Batch 115/350] [D loss: 0.252123, acc:  47%] [G loss: 1.309289] time: 3:53:09.102309\n",
      "[Epoch 6/10] [Batch 116/350] [D loss: 0.252246, acc:  56%] [G loss: 1.205234] time: 3:53:15.398506\n",
      "[Epoch 6/10] [Batch 117/350] [D loss: 0.251785, acc:  53%] [G loss: 1.113032] time: 3:53:21.675691\n",
      "[Epoch 6/10] [Batch 118/350] [D loss: 0.252608, acc:  49%] [G loss: 1.228857] time: 3:53:27.964875\n",
      "[Epoch 6/10] [Batch 119/350] [D loss: 0.251614, acc:  43%] [G loss: 1.137832] time: 3:53:34.277995\n",
      "[Epoch 6/10] [Batch 120/350] [D loss: 0.251382, acc:  55%] [G loss: 1.183916] time: 3:53:40.593110\n",
      "[Epoch 6/10] [Batch 121/350] [D loss: 0.251503, acc:  50%] [G loss: 1.090428] time: 3:53:46.893264\n",
      "[Epoch 6/10] [Batch 122/350] [D loss: 0.251291, acc:  44%] [G loss: 1.127247] time: 3:53:53.196446\n",
      "[Epoch 6/10] [Batch 123/350] [D loss: 0.251593, acc:  49%] [G loss: 1.101979] time: 3:53:59.489584\n",
      "[Epoch 6/10] [Batch 124/350] [D loss: 0.252099, acc:  50%] [G loss: 1.128389] time: 3:54:05.776774\n",
      "[Epoch 6/10] [Batch 125/350] [D loss: 0.251757, acc:  48%] [G loss: 1.068272] time: 3:54:12.067952\n",
      "[Epoch 6/10] [Batch 126/350] [D loss: 0.251415, acc:  46%] [G loss: 1.238054] time: 3:54:18.350155\n",
      "[Epoch 6/10] [Batch 127/350] [D loss: 0.251832, acc:  52%] [G loss: 1.200218] time: 3:54:24.645323\n",
      "[Epoch 6/10] [Batch 128/350] [D loss: 0.252038, acc:  50%] [G loss: 1.082133] time: 3:54:30.946475\n",
      "[Epoch 6/10] [Batch 129/350] [D loss: 0.251478, acc:  48%] [G loss: 1.217615] time: 3:54:37.252613\n",
      "[Epoch 6/10] [Batch 130/350] [D loss: 0.251906, acc:  49%] [G loss: 1.254829] time: 3:54:43.547782\n",
      "[Epoch 6/10] [Batch 131/350] [D loss: 0.251693, acc:  50%] [G loss: 1.091352] time: 3:54:49.852955\n",
      "[Epoch 6/10] [Batch 132/350] [D loss: 0.251397, acc:  48%] [G loss: 1.078663] time: 3:54:56.153077\n",
      "[Epoch 6/10] [Batch 133/350] [D loss: 0.252209, acc:  48%] [G loss: 1.216414] time: 3:55:02.445254\n",
      "[Epoch 6/10] [Batch 134/350] [D loss: 0.251884, acc:  47%] [G loss: 1.162770] time: 3:55:08.713494\n",
      "[Epoch 6/10] [Batch 135/350] [D loss: 0.251155, acc:  45%] [G loss: 1.277489] time: 3:55:15.000683\n",
      "[Epoch 6/10] [Batch 136/350] [D loss: 0.251028, acc:  47%] [G loss: 1.081975] time: 3:55:21.304827\n",
      "[Epoch 6/10] [Batch 137/350] [D loss: 0.250962, acc:  47%] [G loss: 1.226752] time: 3:55:27.610994\n",
      "[Epoch 6/10] [Batch 138/350] [D loss: 0.251173, acc:  54%] [G loss: 1.328558] time: 3:55:33.908128\n",
      "[Epoch 6/10] [Batch 139/350] [D loss: 0.251522, acc:  53%] [G loss: 1.093517] time: 3:55:40.233217\n",
      "[Epoch 6/10] [Batch 140/350] [D loss: 0.251550, acc:  49%] [G loss: 1.204274] time: 3:55:46.546336\n",
      "[Epoch 6/10] [Batch 141/350] [D loss: 0.251375, acc:  44%] [G loss: 1.083432] time: 3:55:52.822587\n",
      "[Epoch 6/10] [Batch 142/350] [D loss: 0.251379, acc:  49%] [G loss: 1.081800] time: 3:55:59.120715\n",
      "[Epoch 6/10] [Batch 143/350] [D loss: 0.251202, acc:  48%] [G loss: 1.216481] time: 3:56:05.400954\n",
      "[Epoch 6/10] [Batch 144/350] [D loss: 0.251187, acc:  48%] [G loss: 1.219444] time: 3:56:11.682128\n",
      "[Epoch 6/10] [Batch 145/350] [D loss: 0.251365, acc:  47%] [G loss: 1.387514] time: 3:56:17.976299\n",
      "[Epoch 6/10] [Batch 146/350] [D loss: 0.251181, acc:  47%] [G loss: 1.239792] time: 3:56:24.269472\n",
      "[Epoch 6/10] [Batch 147/350] [D loss: 0.251195, acc:  47%] [G loss: 1.215044] time: 3:56:30.577637\n",
      "[Epoch 6/10] [Batch 148/350] [D loss: 0.251789, acc:  41%] [G loss: 1.216995] time: 3:56:36.901696\n",
      "[Epoch 6/10] [Batch 149/350] [D loss: 0.251724, acc:  48%] [G loss: 1.033652] time: 3:56:43.209829\n",
      "[Epoch 6/10] [Batch 150/350] [D loss: 0.251375, acc:  51%] [G loss: 1.202860] time: 3:56:49.515968\n",
      "[Epoch 6/10] [Batch 151/350] [D loss: 0.251015, acc:  46%] [G loss: 1.112314] time: 3:56:55.808176\n",
      "[Epoch 6/10] [Batch 152/350] [D loss: 0.251035, acc:  47%] [G loss: 1.206083] time: 3:57:02.100333\n",
      "[Epoch 6/10] [Batch 153/350] [D loss: 0.250930, acc:  48%] [G loss: 1.074573] time: 3:57:08.403467\n",
      "[Epoch 6/10] [Batch 154/350] [D loss: 0.251340, acc:  49%] [G loss: 1.206234] time: 3:57:14.772438\n",
      "[Epoch 6/10] [Batch 155/350] [D loss: 0.251420, acc:  46%] [G loss: 1.095269] time: 3:57:21.069600\n",
      "[Epoch 6/10] [Batch 156/350] [D loss: 0.251427, acc:  46%] [G loss: 1.093581] time: 3:57:27.362802\n",
      "[Epoch 6/10] [Batch 157/350] [D loss: 0.251394, acc:  48%] [G loss: 1.121282] time: 3:57:33.657942\n",
      "[Epoch 6/10] [Batch 158/350] [D loss: 0.251279, acc:  51%] [G loss: 1.130658] time: 3:57:39.967104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/10] [Batch 159/350] [D loss: 0.251145, acc:  44%] [G loss: 1.259380] time: 3:57:46.281189\n",
      "[Epoch 6/10] [Batch 160/350] [D loss: 0.251137, acc:  50%] [G loss: 1.103555] time: 3:57:52.563392\n",
      "[Epoch 6/10] [Batch 161/350] [D loss: 0.251317, acc:  48%] [G loss: 1.161734] time: 3:57:58.845595\n",
      "[Epoch 6/10] [Batch 162/350] [D loss: 0.251157, acc:  47%] [G loss: 1.092582] time: 3:58:05.146779\n",
      "[Epoch 6/10] [Batch 163/350] [D loss: 0.251503, acc:  43%] [G loss: 1.139724] time: 3:58:11.455877\n",
      "[Epoch 6/10] [Batch 164/350] [D loss: 0.251548, acc:  49%] [G loss: 1.074153] time: 3:58:17.734091\n",
      "[Epoch 6/10] [Batch 165/350] [D loss: 0.251239, acc:  41%] [G loss: 1.092388] time: 3:58:24.021280\n",
      "[Epoch 6/10] [Batch 166/350] [D loss: 0.251164, acc:  48%] [G loss: 1.146033] time: 3:58:30.311461\n",
      "[Epoch 6/10] [Batch 167/350] [D loss: 0.251154, acc:  49%] [G loss: 0.968635] time: 3:58:36.607658\n",
      "[Epoch 6/10] [Batch 168/350] [D loss: 0.251279, acc:  51%] [G loss: 1.119625] time: 3:58:42.928725\n",
      "[Epoch 6/10] [Batch 169/350] [D loss: 0.251860, acc:  57%] [G loss: 0.935744] time: 3:58:49.195999\n",
      "[Epoch 6/10] [Batch 170/350] [D loss: 0.252155, acc:  49%] [G loss: 1.212809] time: 3:58:55.472187\n",
      "[Epoch 6/10] [Batch 171/350] [D loss: 0.251668, acc:  49%] [G loss: 1.161944] time: 3:59:01.781318\n",
      "[Epoch 6/10] [Batch 172/350] [D loss: 0.252113, acc:  54%] [G loss: 1.131197] time: 3:59:08.053547\n",
      "[Epoch 6/10] [Batch 173/350] [D loss: 0.252998, acc:  49%] [G loss: 1.333767] time: 3:59:14.342731\n",
      "[Epoch 6/10] [Batch 174/350] [D loss: 0.251998, acc:  50%] [G loss: 1.161856] time: 3:59:20.635936\n",
      "[Epoch 6/10] [Batch 175/350] [D loss: 0.252101, acc:  48%] [G loss: 1.231510] time: 3:59:26.938085\n",
      "[Epoch 6/10] [Batch 176/350] [D loss: 0.252950, acc:  49%] [G loss: 1.127228] time: 3:59:39.106233\n",
      "[Epoch 6/10] [Batch 177/350] [D loss: 0.252067, acc:  49%] [G loss: 1.206290] time: 3:59:45.433347\n",
      "[Epoch 6/10] [Batch 178/350] [D loss: 0.251086, acc:  50%] [G loss: 1.151012] time: 3:59:51.753417\n",
      "[Epoch 6/10] [Batch 179/350] [D loss: 0.251163, acc:  48%] [G loss: 1.094799] time: 3:59:58.062548\n",
      "[Epoch 6/10] [Batch 180/350] [D loss: 0.251232, acc:  47%] [G loss: 1.096018] time: 4:00:04.367689\n",
      "[Epoch 6/10] [Batch 181/350] [D loss: 0.251280, acc:  50%] [G loss: 1.152496] time: 4:00:10.672862\n",
      "[Epoch 6/10] [Batch 182/350] [D loss: 0.251275, acc:  47%] [G loss: 1.057646] time: 4:00:16.970026\n",
      "[Epoch 6/10] [Batch 183/350] [D loss: 0.250975, acc:  49%] [G loss: 1.248824] time: 4:00:23.253193\n",
      "[Epoch 6/10] [Batch 184/350] [D loss: 0.251084, acc:  50%] [G loss: 1.220768] time: 4:00:29.537391\n",
      "[Epoch 6/10] [Batch 185/350] [D loss: 0.251293, acc:  49%] [G loss: 0.974925] time: 4:00:35.837546\n",
      "[Epoch 6/10] [Batch 186/350] [D loss: 0.251156, acc:  46%] [G loss: 1.224172] time: 4:00:42.108809\n",
      "[Epoch 6/10] [Batch 187/350] [D loss: 0.251082, acc:  46%] [G loss: 1.191615] time: 4:00:48.412921\n",
      "[Epoch 6/10] [Batch 188/350] [D loss: 0.251279, acc:  48%] [G loss: 0.988979] time: 4:00:54.698116\n",
      "[Epoch 6/10] [Batch 189/350] [D loss: 0.251309, acc:  56%] [G loss: 1.114694] time: 4:01:01.002291\n",
      "[Epoch 6/10] [Batch 190/350] [D loss: 0.251247, acc:  51%] [G loss: 1.350856] time: 4:01:07.275487\n",
      "[Epoch 6/10] [Batch 191/350] [D loss: 0.251527, acc:  45%] [G loss: 1.211055] time: 4:01:13.574644\n",
      "[Epoch 6/10] [Batch 192/350] [D loss: 0.251359, acc:  44%] [G loss: 1.044460] time: 4:01:19.839926\n",
      "[Epoch 6/10] [Batch 193/350] [D loss: 0.251617, acc:  50%] [G loss: 1.175528] time: 4:01:26.129076\n",
      "[Epoch 6/10] [Batch 194/350] [D loss: 0.251608, acc:  50%] [G loss: 1.350541] time: 4:01:32.405295\n",
      "[Epoch 6/10] [Batch 195/350] [D loss: 0.251902, acc:  45%] [G loss: 1.139639] time: 4:01:38.697471\n",
      "[Epoch 6/10] [Batch 196/350] [D loss: 0.252334, acc:  54%] [G loss: 1.183814] time: 4:01:45.021561\n",
      "[Epoch 6/10] [Batch 197/350] [D loss: 0.251987, acc:  52%] [G loss: 1.003599] time: 4:01:51.309748\n",
      "[Epoch 6/10] [Batch 198/350] [D loss: 0.251701, acc:  48%] [G loss: 1.093916] time: 4:01:57.601924\n",
      "[Epoch 6/10] [Batch 199/350] [D loss: 0.252110, acc:  45%] [G loss: 1.103176] time: 4:02:03.907065\n",
      "[Epoch 6/10] [Batch 200/350] [D loss: 0.251643, acc:  45%] [G loss: 1.156304] time: 4:02:10.207220\n",
      "[Epoch 6/10] [Batch 201/350] [D loss: 0.251032, acc:  49%] [G loss: 1.018775] time: 4:02:16.554249\n",
      "[Epoch 6/10] [Batch 202/350] [D loss: 0.251204, acc:  47%] [G loss: 1.154928] time: 4:02:22.849417\n",
      "[Epoch 6/10] [Batch 203/350] [D loss: 0.251148, acc:  44%] [G loss: 1.064366] time: 4:02:29.151566\n",
      "[Epoch 6/10] [Batch 204/350] [D loss: 0.251272, acc:  45%] [G loss: 1.089105] time: 4:02:35.438756\n",
      "[Epoch 6/10] [Batch 205/350] [D loss: 0.251292, acc:  52%] [G loss: 1.040516] time: 4:02:41.719961\n",
      "[Epoch 6/10] [Batch 206/350] [D loss: 0.251203, acc:  51%] [G loss: 1.115700] time: 4:02:48.005156\n",
      "[Epoch 6/10] [Batch 207/350] [D loss: 0.251175, acc:  51%] [G loss: 1.227517] time: 4:02:54.304313\n",
      "[Epoch 6/10] [Batch 208/350] [D loss: 0.251304, acc:  49%] [G loss: 1.073146] time: 4:03:00.596521\n",
      "[Epoch 6/10] [Batch 209/350] [D loss: 0.251846, acc:  48%] [G loss: 1.264512] time: 4:03:06.896644\n",
      "[Epoch 6/10] [Batch 210/350] [D loss: 0.251586, acc:  50%] [G loss: 1.149790] time: 4:03:13.180841\n",
      "[Epoch 6/10] [Batch 211/350] [D loss: 0.251348, acc:  47%] [G loss: 1.011198] time: 4:03:19.462079\n",
      "[Epoch 6/10] [Batch 212/350] [D loss: 0.251254, acc:  46%] [G loss: 0.933236] time: 4:03:25.779156\n",
      "[Epoch 6/10] [Batch 213/350] [D loss: 0.251459, acc:  48%] [G loss: 1.099750] time: 4:03:32.077316\n",
      "[Epoch 6/10] [Batch 214/350] [D loss: 0.251062, acc:  48%] [G loss: 1.055570] time: 4:03:38.369492\n",
      "[Epoch 6/10] [Batch 215/350] [D loss: 0.251021, acc:  49%] [G loss: 1.185852] time: 4:03:44.701593\n",
      "[Epoch 6/10] [Batch 216/350] [D loss: 0.250950, acc:  48%] [G loss: 1.015630] time: 4:03:50.985758\n",
      "[Epoch 6/10] [Batch 217/350] [D loss: 0.251069, acc:  49%] [G loss: 0.979866] time: 4:03:57.273945\n",
      "[Epoch 6/10] [Batch 218/350] [D loss: 0.251118, acc:  48%] [G loss: 1.107005] time: 4:04:03.587065\n",
      "[Epoch 6/10] [Batch 219/350] [D loss: 0.251972, acc:  39%] [G loss: 1.079849] time: 4:04:09.909190\n",
      "[Epoch 6/10] [Batch 220/350] [D loss: 0.252300, acc:  47%] [G loss: 1.364915] time: 4:04:16.202334\n",
      "[Epoch 6/10] [Batch 221/350] [D loss: 0.251840, acc:  46%] [G loss: 1.001820] time: 4:04:22.484537\n",
      "[Epoch 6/10] [Batch 222/350] [D loss: 0.251301, acc:  49%] [G loss: 1.047320] time: 4:04:28.910356\n",
      "[Epoch 6/10] [Batch 223/350] [D loss: 0.251523, acc:  51%] [G loss: 1.254635] time: 4:04:35.247443\n",
      "[Epoch 6/10] [Batch 224/350] [D loss: 0.251639, acc:  49%] [G loss: 1.204456] time: 4:04:41.528649\n",
      "[Epoch 6/10] [Batch 225/350] [D loss: 0.251028, acc:  51%] [G loss: 1.064057] time: 4:04:47.821790\n",
      "[Epoch 6/10] [Batch 226/350] [D loss: 0.251047, acc:  47%] [G loss: 1.168202] time: 4:04:54.107983\n",
      "[Epoch 6/10] [Batch 227/350] [D loss: 0.251366, acc:  47%] [G loss: 1.207684] time: 4:05:00.422100\n",
      "[Epoch 6/10] [Batch 228/350] [D loss: 0.251394, acc:  48%] [G loss: 1.167421] time: 4:05:06.686350\n",
      "[Epoch 6/10] [Batch 229/350] [D loss: 0.251164, acc:  48%] [G loss: 1.170192] time: 4:05:12.999471\n",
      "[Epoch 6/10] [Batch 230/350] [D loss: 0.251347, acc:  51%] [G loss: 1.174701] time: 4:05:19.285662\n",
      "[Epoch 6/10] [Batch 231/350] [D loss: 0.251421, acc:  45%] [G loss: 1.295690] time: 4:05:25.552905\n",
      "[Epoch 6/10] [Batch 232/350] [D loss: 0.251359, acc:  51%] [G loss: 1.132748] time: 4:05:31.824137\n",
      "[Epoch 6/10] [Batch 233/350] [D loss: 0.251358, acc:  47%] [G loss: 1.108409] time: 4:05:38.114318\n",
      "[Epoch 6/10] [Batch 234/350] [D loss: 0.251338, acc:  48%] [G loss: 1.231093] time: 4:05:44.463343\n",
      "[Epoch 6/10] [Batch 235/350] [D loss: 0.251119, acc:  48%] [G loss: 1.197620] time: 4:05:50.745546\n",
      "[Epoch 6/10] [Batch 236/350] [D loss: 0.251249, acc:  43%] [G loss: 1.108481] time: 4:05:57.037753\n",
      "[Epoch 6/10] [Batch 237/350] [D loss: 0.251256, acc:  48%] [G loss: 1.137612] time: 4:06:03.348847\n",
      "[Epoch 6/10] [Batch 238/350] [D loss: 0.251070, acc:  49%] [G loss: 1.119572] time: 4:06:09.629055\n",
      "[Epoch 6/10] [Batch 239/350] [D loss: 0.250929, acc:  46%] [G loss: 1.074969] time: 4:06:15.930207\n",
      "[Epoch 6/10] [Batch 240/350] [D loss: 0.251187, acc:  46%] [G loss: 1.202373] time: 4:06:22.215401\n",
      "[Epoch 6/10] [Batch 241/350] [D loss: 0.251207, acc:  48%] [G loss: 1.150285] time: 4:06:28.508586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/10] [Batch 242/350] [D loss: 0.251135, acc:  44%] [G loss: 1.082090] time: 4:06:34.792772\n",
      "[Epoch 6/10] [Batch 243/350] [D loss: 0.251659, acc:  41%] [G loss: 1.377585] time: 4:06:41.112873\n",
      "[Epoch 6/10] [Batch 244/350] [D loss: 0.251539, acc:  48%] [G loss: 1.065523] time: 4:06:47.399065\n",
      "[Epoch 6/10] [Batch 245/350] [D loss: 0.251142, acc:  50%] [G loss: 1.191850] time: 4:06:53.690244\n",
      "[Epoch 6/10] [Batch 246/350] [D loss: 0.251181, acc:  54%] [G loss: 1.153416] time: 4:06:59.992425\n",
      "[Epoch 6/10] [Batch 247/350] [D loss: 0.251369, acc:  48%] [G loss: 1.077019] time: 4:07:06.299529\n",
      "[Epoch 6/10] [Batch 248/350] [D loss: 0.251129, acc:  44%] [G loss: 1.291188] time: 4:07:12.565775\n",
      "[Epoch 6/10] [Batch 249/350] [D loss: 0.251113, acc:  51%] [G loss: 1.362242] time: 4:07:18.917791\n",
      "[Epoch 6/10] [Batch 250/350] [D loss: 0.251266, acc:  46%] [G loss: 1.237434] time: 4:07:25.223930\n",
      "[Epoch 6/10] [Batch 251/350] [D loss: 0.251092, acc:  51%] [G loss: 1.127173] time: 4:07:31.519098\n",
      "[Epoch 6/10] [Batch 252/350] [D loss: 0.251299, acc:  49%] [G loss: 1.028765] time: 4:07:37.814266\n",
      "[Epoch 6/10] [Batch 253/350] [D loss: 0.251210, acc:  50%] [G loss: 1.232055] time: 4:07:44.151354\n",
      "[Epoch 6/10] [Batch 254/350] [D loss: 0.251262, acc:  47%] [G loss: 1.149664] time: 4:07:50.445492\n",
      "[Epoch 6/10] [Batch 255/350] [D loss: 0.251181, acc:  48%] [G loss: 1.141778] time: 4:07:56.726697\n",
      "[Epoch 6/10] [Batch 256/350] [D loss: 0.251330, acc:  44%] [G loss: 1.025004] time: 4:08:03.030842\n",
      "[Epoch 6/10] [Batch 257/350] [D loss: 0.251144, acc:  46%] [G loss: 1.208062] time: 4:08:09.326009\n",
      "[Epoch 6/10] [Batch 258/350] [D loss: 0.251018, acc:  46%] [G loss: 1.169701] time: 4:08:15.620180\n",
      "[Epoch 6/10] [Batch 259/350] [D loss: 0.250898, acc:  46%] [G loss: 0.966235] time: 4:08:21.917343\n",
      "[Epoch 6/10] [Batch 260/350] [D loss: 0.250935, acc:  49%] [G loss: 1.111835] time: 4:08:28.214506\n",
      "[Epoch 6/10] [Batch 261/350] [D loss: 0.251107, acc:  48%] [G loss: 1.060813] time: 4:08:34.516655\n",
      "[Epoch 6/10] [Batch 262/350] [D loss: 0.251056, acc:  45%] [G loss: 1.373437] time: 4:08:40.807864\n",
      "[Epoch 6/10] [Batch 263/350] [D loss: 0.251132, acc:  48%] [G loss: 1.159144] time: 4:08:47.088043\n",
      "[Epoch 6/10] [Batch 264/350] [D loss: 0.251074, acc:  48%] [G loss: 1.157604] time: 4:08:53.367252\n",
      "[Epoch 6/10] [Batch 265/350] [D loss: 0.251416, acc:  48%] [G loss: 1.009953] time: 4:08:59.661423\n",
      "[Epoch 6/10] [Batch 266/350] [D loss: 0.251405, acc:  48%] [G loss: 1.033495] time: 4:09:05.976572\n",
      "[Epoch 6/10] [Batch 267/350] [D loss: 0.251334, acc:  49%] [G loss: 1.001859] time: 4:09:12.283673\n",
      "[Epoch 6/10] [Batch 268/350] [D loss: 0.251482, acc:  53%] [G loss: 1.120390] time: 4:09:18.553940\n",
      "[Epoch 6/10] [Batch 269/350] [D loss: 0.251654, acc:  47%] [G loss: 1.103895] time: 4:09:24.851099\n",
      "[Epoch 6/10] [Batch 270/350] [D loss: 0.251338, acc:  39%] [G loss: 1.215567] time: 4:09:31.172170\n",
      "[Epoch 6/10] [Batch 271/350] [D loss: 0.251348, acc:  50%] [G loss: 0.979754] time: 4:09:37.659858\n",
      "[Epoch 6/10] [Batch 272/350] [D loss: 0.251288, acc:  49%] [G loss: 1.161525] time: 4:09:44.005855\n",
      "[Epoch 6/10] [Batch 273/350] [D loss: 0.251132, acc:  51%] [G loss: 1.219172] time: 4:09:50.297033\n",
      "[Epoch 6/10] [Batch 274/350] [D loss: 0.250869, acc:  50%] [G loss: 1.258695] time: 4:09:56.590207\n",
      "[Epoch 6/10] [Batch 275/350] [D loss: 0.251338, acc:  48%] [G loss: 1.177527] time: 4:10:02.890361\n",
      "[Epoch 6/10] [Batch 276/350] [D loss: 0.251233, acc:  55%] [G loss: 1.104441] time: 4:10:09.162590\n",
      "[Epoch 6/10] [Batch 277/350] [D loss: 0.251346, acc:  49%] [G loss: 1.042224] time: 4:10:15.456762\n",
      "[Epoch 6/10] [Batch 278/350] [D loss: 0.251089, acc:  47%] [G loss: 1.117234] time: 4:10:21.752959\n",
      "[Epoch 6/10] [Batch 279/350] [D loss: 0.251142, acc:  47%] [G loss: 1.121995] time: 4:10:28.058068\n",
      "[Epoch 6/10] [Batch 280/350] [D loss: 0.251069, acc:  49%] [G loss: 1.081634] time: 4:10:34.344291\n",
      "[Epoch 6/10] [Batch 281/350] [D loss: 0.251082, acc:  49%] [G loss: 1.082559] time: 4:10:40.632478\n",
      "[Epoch 6/10] [Batch 282/350] [D loss: 0.251363, acc:  50%] [G loss: 1.116986] time: 4:10:46.917642\n",
      "[Epoch 6/10] [Batch 283/350] [D loss: 0.251501, acc:  46%] [G loss: 1.009763] time: 4:10:53.205860\n",
      "[Epoch 6/10] [Batch 284/350] [D loss: 0.251581, acc:  49%] [G loss: 1.070745] time: 4:10:59.505017\n",
      "[Epoch 6/10] [Batch 285/350] [D loss: 0.251141, acc:  45%] [G loss: 1.055992] time: 4:11:05.806137\n",
      "[Epoch 6/10] [Batch 286/350] [D loss: 0.251088, acc:  47%] [G loss: 1.058567] time: 4:11:12.071420\n",
      "[Epoch 6/10] [Batch 287/350] [D loss: 0.250935, acc:  46%] [G loss: 1.089140] time: 4:11:18.375530\n",
      "[Epoch 6/10] [Batch 288/350] [D loss: 0.251118, acc:  47%] [G loss: 1.147461] time: 4:11:24.694665\n",
      "[Epoch 6/10] [Batch 289/350] [D loss: 0.251191, acc:  55%] [G loss: 1.242168] time: 4:11:30.964868\n",
      "[Epoch 6/10] [Batch 290/350] [D loss: 0.251233, acc:  50%] [G loss: 1.001831] time: 4:11:37.273999\n",
      "[Epoch 6/10] [Batch 291/350] [D loss: 0.251376, acc:  45%] [G loss: 1.220849] time: 4:11:43.628009\n",
      "[Epoch 6/10] [Batch 292/350] [D loss: 0.251101, acc:  48%] [G loss: 1.060492] time: 4:11:49.995982\n",
      "[Epoch 6/10] [Batch 293/350] [D loss: 0.251071, acc:  48%] [G loss: 1.391185] time: 4:11:56.300126\n",
      "[Epoch 6/10] [Batch 294/350] [D loss: 0.251177, acc:  54%] [G loss: 1.131300] time: 4:12:02.593300\n",
      "[Epoch 6/10] [Batch 295/350] [D loss: 0.251312, acc:  49%] [G loss: 1.092277] time: 4:12:08.862569\n",
      "[Epoch 6/10] [Batch 296/350] [D loss: 0.251096, acc:  44%] [G loss: 1.140725] time: 4:12:15.194607\n",
      "[Epoch 6/10] [Batch 297/350] [D loss: 0.250985, acc:  48%] [G loss: 1.094442] time: 4:12:21.481796\n",
      "[Epoch 6/10] [Batch 298/350] [D loss: 0.251006, acc:  49%] [G loss: 1.174166] time: 4:12:27.783976\n",
      "[Epoch 6/10] [Batch 299/350] [D loss: 0.251075, acc:  48%] [G loss: 1.322424] time: 4:12:34.079113\n",
      "[Epoch 6/10] [Batch 300/350] [D loss: 0.251389, acc:  48%] [G loss: 1.339675] time: 4:12:40.363311\n",
      "[Epoch 6/10] [Batch 301/350] [D loss: 0.251443, acc:  48%] [G loss: 1.256229] time: 4:12:46.680420\n",
      "[Epoch 6/10] [Batch 302/350] [D loss: 0.251386, acc:  49%] [G loss: 1.043088] time: 4:12:52.962623\n",
      "[Epoch 6/10] [Batch 303/350] [D loss: 0.251207, acc:  52%] [G loss: 1.149772] time: 4:12:59.269759\n",
      "[Epoch 6/10] [Batch 304/350] [D loss: 0.251491, acc:  47%] [G loss: 1.008289] time: 4:13:05.565924\n",
      "[Epoch 6/10] [Batch 305/350] [D loss: 0.251484, acc:  50%] [G loss: 1.099604] time: 4:13:11.851119\n",
      "[Epoch 6/10] [Batch 306/350] [D loss: 0.251043, acc:  49%] [G loss: 1.103018] time: 4:13:18.137311\n",
      "[Epoch 6/10] [Batch 307/350] [D loss: 0.251079, acc:  46%] [G loss: 1.201770] time: 4:13:24.448436\n",
      "[Epoch 6/10] [Batch 308/350] [D loss: 0.251042, acc:  50%] [G loss: 1.109678] time: 4:13:30.744601\n",
      "[Epoch 6/10] [Batch 309/350] [D loss: 0.251071, acc:  49%] [G loss: 1.076346] time: 4:13:37.048746\n",
      "[Epoch 6/10] [Batch 310/350] [D loss: 0.251108, acc:  48%] [G loss: 1.123787] time: 4:13:43.394777\n",
      "[Epoch 6/10] [Batch 311/350] [D loss: 0.250984, acc:  45%] [G loss: 1.202872] time: 4:13:49.694932\n",
      "[Epoch 6/10] [Batch 312/350] [D loss: 0.251733, acc:  48%] [G loss: 1.071205] time: 4:13:55.951204\n",
      "[Epoch 6/10] [Batch 313/350] [D loss: 0.251775, acc:  50%] [G loss: 0.961174] time: 4:14:02.268347\n",
      "[Epoch 6/10] [Batch 314/350] [D loss: 0.252172, acc:  49%] [G loss: 1.194274] time: 4:14:08.575449\n",
      "[Epoch 6/10] [Batch 315/350] [D loss: 0.251655, acc:  48%] [G loss: 1.135953] time: 4:14:14.858649\n",
      "[Epoch 6/10] [Batch 316/350] [D loss: 0.251685, acc:  51%] [G loss: 1.192987] time: 4:14:21.153817\n",
      "[Epoch 6/10] [Batch 317/350] [D loss: 0.252488, acc:  51%] [G loss: 1.192651] time: 4:14:27.447988\n",
      "[Epoch 6/10] [Batch 318/350] [D loss: 0.252123, acc:  47%] [G loss: 1.143851] time: 4:14:33.741193\n",
      "[Epoch 6/10] [Batch 319/350] [D loss: 0.251166, acc:  51%] [G loss: 1.068937] time: 4:14:40.002420\n",
      "[Epoch 6/10] [Batch 320/350] [D loss: 0.251443, acc:  48%] [G loss: 1.083800] time: 4:14:46.301577\n",
      "[Epoch 6/10] [Batch 321/350] [D loss: 0.251723, acc:  48%] [G loss: 1.127109] time: 4:14:52.594751\n",
      "[Epoch 6/10] [Batch 322/350] [D loss: 0.251345, acc:  49%] [G loss: 1.267162] time: 4:14:58.879977\n",
      "[Epoch 6/10] [Batch 323/350] [D loss: 0.251270, acc:  50%] [G loss: 1.102625] time: 4:15:05.171124\n",
      "[Epoch 6/10] [Batch 324/350] [D loss: 0.251208, acc:  48%] [G loss: 1.044089] time: 4:15:11.473273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/10] [Batch 325/350] [D loss: 0.251046, acc:  44%] [G loss: 1.186646] time: 4:15:17.758468\n",
      "[Epoch 6/10] [Batch 326/350] [D loss: 0.251385, acc:  51%] [G loss: 1.160387] time: 4:15:24.037679\n",
      "[Epoch 6/10] [Batch 327/350] [D loss: 0.251298, acc:  44%] [G loss: 1.089902] time: 4:15:30.334873\n",
      "[Epoch 6/10] [Batch 328/350] [D loss: 0.251288, acc:  47%] [G loss: 1.075340] time: 4:15:36.636991\n",
      "[Epoch 6/10] [Batch 329/350] [D loss: 0.251077, acc:  48%] [G loss: 1.150693] time: 4:15:42.975044\n",
      "[Epoch 6/10] [Batch 330/350] [D loss: 0.251071, acc:  49%] [G loss: 1.189965] time: 4:15:49.246276\n",
      "[Epoch 6/10] [Batch 331/350] [D loss: 0.251145, acc:  48%] [G loss: 1.274966] time: 4:15:55.529476\n",
      "[Epoch 6/10] [Batch 332/350] [D loss: 0.251271, acc:  46%] [G loss: 1.283135] time: 4:16:01.795721\n",
      "[Epoch 6/10] [Batch 333/350] [D loss: 0.251330, acc:  46%] [G loss: 1.079232] time: 4:16:08.094878\n",
      "[Epoch 6/10] [Batch 334/350] [D loss: 0.251207, acc:  46%] [G loss: 1.112987] time: 4:16:14.394036\n",
      "[Epoch 6/10] [Batch 335/350] [D loss: 0.251355, acc:  43%] [G loss: 1.264950] time: 4:16:20.690201\n",
      "[Epoch 6/10] [Batch 336/350] [D loss: 0.251384, acc:  49%] [G loss: 1.258184] time: 4:16:26.988361\n",
      "[Epoch 6/10] [Batch 337/350] [D loss: 0.251107, acc:  51%] [G loss: 1.139614] time: 4:16:33.282532\n",
      "[Epoch 6/10] [Batch 338/350] [D loss: 0.251041, acc:  49%] [G loss: 1.351316] time: 4:16:39.583684\n",
      "[Epoch 6/10] [Batch 339/350] [D loss: 0.250887, acc:  46%] [G loss: 1.076856] time: 4:16:45.870873\n",
      "[Epoch 6/10] [Batch 340/350] [D loss: 0.251293, acc:  39%] [G loss: 1.010733] time: 4:16:52.177012\n",
      "[Epoch 6/10] [Batch 341/350] [D loss: 0.251419, acc:  48%] [G loss: 1.048396] time: 4:16:58.453231\n",
      "[Epoch 6/10] [Batch 342/350] [D loss: 0.251376, acc:  45%] [G loss: 1.353675] time: 4:17:04.732441\n",
      "[Epoch 6/10] [Batch 343/350] [D loss: 0.251379, acc:  48%] [G loss: 1.134492] time: 4:17:11.035589\n",
      "[Epoch 6/10] [Batch 344/350] [D loss: 0.251753, acc:  46%] [G loss: 1.244543] time: 4:17:17.378628\n",
      "[Epoch 6/10] [Batch 345/350] [D loss: 0.251637, acc:  51%] [G loss: 1.092883] time: 4:17:23.686761\n",
      "[Epoch 6/10] [Batch 346/350] [D loss: 0.251415, acc:  47%] [G loss: 1.112781] time: 4:17:29.992901\n",
      "[Epoch 6/10] [Batch 347/350] [D loss: 0.251582, acc:  55%] [G loss: 1.093516] time: 4:17:36.271114\n",
      "[Epoch 6/10] [Batch 348/350] [D loss: 0.251623, acc:  49%] [G loss: 1.036902] time: 4:17:42.589220\n",
      "weights saved...\n",
      "[Epoch 7/10] [Batch 0/350] [D loss: 0.251144, acc:  49%] [G loss: 1.052654] time: 4:17:49.195588\n",
      "[Epoch 7/10] [Batch 1/350] [D loss: 0.250967, acc:  49%] [G loss: 1.036838] time: 4:18:01.079780\n",
      "[Epoch 7/10] [Batch 2/350] [D loss: 0.251181, acc:  47%] [G loss: 1.202742] time: 4:18:07.374948\n",
      "[Epoch 7/10] [Batch 3/350] [D loss: 0.251416, acc:  51%] [G loss: 1.296392] time: 4:18:13.651167\n",
      "[Epoch 7/10] [Batch 4/350] [D loss: 0.251402, acc:  50%] [G loss: 1.290854] time: 4:18:19.936361\n",
      "[Epoch 7/10] [Batch 5/350] [D loss: 0.251139, acc:  51%] [G loss: 1.298929] time: 4:18:26.247486\n",
      "[Epoch 7/10] [Batch 6/350] [D loss: 0.251385, acc:  40%] [G loss: 1.248282] time: 4:18:32.568585\n",
      "[Epoch 7/10] [Batch 7/350] [D loss: 0.251200, acc:  44%] [G loss: 1.201644] time: 4:18:38.846798\n",
      "[Epoch 7/10] [Batch 8/350] [D loss: 0.251382, acc:  44%] [G loss: 1.031109] time: 4:18:45.154932\n",
      "[Epoch 7/10] [Batch 9/350] [D loss: 0.251542, acc:  50%] [G loss: 1.117742] time: 4:18:51.429157\n",
      "[Epoch 7/10] [Batch 10/350] [D loss: 0.251363, acc:  44%] [G loss: 1.213778] time: 4:18:57.705375\n",
      "[Epoch 7/10] [Batch 11/350] [D loss: 0.251678, acc:  49%] [G loss: 1.307338] time: 4:19:03.997551\n",
      "[Epoch 7/10] [Batch 12/350] [D loss: 0.252028, acc:  51%] [G loss: 1.116220] time: 4:19:10.290724\n",
      "[Epoch 7/10] [Batch 13/350] [D loss: 0.251826, acc:  47%] [G loss: 1.035627] time: 4:19:16.571929\n",
      "[Epoch 7/10] [Batch 14/350] [D loss: 0.251051, acc:  48%] [G loss: 1.042569] time: 4:19:22.875076\n",
      "[Epoch 7/10] [Batch 15/350] [D loss: 0.251072, acc:  49%] [G loss: 1.038124] time: 4:19:29.173236\n",
      "[Epoch 7/10] [Batch 16/350] [D loss: 0.251082, acc:  45%] [G loss: 1.003496] time: 4:19:35.458462\n",
      "[Epoch 7/10] [Batch 17/350] [D loss: 0.251115, acc:  50%] [G loss: 1.394488] time: 4:19:41.744623\n",
      "[Epoch 7/10] [Batch 18/350] [D loss: 0.251136, acc:  48%] [G loss: 1.230731] time: 4:19:48.026825\n",
      "[Epoch 7/10] [Batch 19/350] [D loss: 0.251130, acc:  44%] [G loss: 1.162561] time: 4:19:54.302047\n",
      "[Epoch 7/10] [Batch 20/350] [D loss: 0.251140, acc:  44%] [G loss: 1.333602] time: 4:20:00.596217\n",
      "[Epoch 7/10] [Batch 21/350] [D loss: 0.251268, acc:  49%] [G loss: 1.184520] time: 4:20:06.888393\n",
      "[Epoch 7/10] [Batch 22/350] [D loss: 0.251167, acc:  48%] [G loss: 1.029110] time: 4:20:13.171593\n",
      "[Epoch 7/10] [Batch 23/350] [D loss: 0.250851, acc:  47%] [G loss: 1.225578] time: 4:20:19.462772\n",
      "[Epoch 7/10] [Batch 24/350] [D loss: 0.251103, acc:  47%] [G loss: 1.084352] time: 4:20:25.740985\n",
      "[Epoch 7/10] [Batch 25/350] [D loss: 0.251046, acc:  45%] [G loss: 1.082645] time: 4:20:32.049119\n",
      "[Epoch 7/10] [Batch 26/350] [D loss: 0.251012, acc:  48%] [G loss: 1.139209] time: 4:20:38.343290\n",
      "[Epoch 7/10] [Batch 27/350] [D loss: 0.251096, acc:  46%] [G loss: 1.165957] time: 4:20:44.631476\n",
      "[Epoch 7/10] [Batch 28/350] [D loss: 0.251220, acc:  42%] [G loss: 1.045369] time: 4:20:50.927641\n",
      "[Epoch 7/10] [Batch 29/350] [D loss: 0.251104, acc:  46%] [G loss: 1.106094] time: 4:20:57.208846\n",
      "[Epoch 7/10] [Batch 30/350] [D loss: 0.250971, acc:  49%] [G loss: 1.061040] time: 4:21:03.499028\n",
      "[Epoch 7/10] [Batch 31/350] [D loss: 0.250957, acc:  48%] [G loss: 1.088174] time: 4:21:09.789209\n",
      "[Epoch 7/10] [Batch 32/350] [D loss: 0.250996, acc:  46%] [G loss: 1.054208] time: 4:21:16.096345\n",
      "[Epoch 7/10] [Batch 33/350] [D loss: 0.251038, acc:  47%] [G loss: 1.092746] time: 4:21:22.371567\n",
      "[Epoch 7/10] [Batch 34/350] [D loss: 0.251232, acc:  51%] [G loss: 1.071345] time: 4:21:28.677705\n",
      "[Epoch 7/10] [Batch 35/350] [D loss: 0.251152, acc:  52%] [G loss: 0.930727] time: 4:21:34.968884\n",
      "[Epoch 7/10] [Batch 36/350] [D loss: 0.251076, acc:  51%] [G loss: 0.969625] time: 4:21:41.267044\n",
      "[Epoch 7/10] [Batch 37/350] [D loss: 0.251041, acc:  48%] [G loss: 1.199170] time: 4:21:47.553236\n",
      "[Epoch 7/10] [Batch 38/350] [D loss: 0.251285, acc:  48%] [G loss: 1.178472] time: 4:21:53.846409\n",
      "[Epoch 7/10] [Batch 39/350] [D loss: 0.251046, acc:  49%] [G loss: 1.074471] time: 4:22:00.134627\n",
      "[Epoch 7/10] [Batch 40/350] [D loss: 0.251172, acc:  47%] [G loss: 1.172184] time: 4:22:06.438740\n",
      "[Epoch 7/10] [Batch 41/350] [D loss: 0.251386, acc:  46%] [G loss: 1.164156] time: 4:22:12.729919\n",
      "[Epoch 7/10] [Batch 42/350] [D loss: 0.251183, acc:  49%] [G loss: 0.997832] time: 4:22:19.015113\n",
      "[Epoch 7/10] [Batch 43/350] [D loss: 0.251295, acc:  48%] [G loss: 1.174487] time: 4:22:25.303300\n",
      "[Epoch 7/10] [Batch 44/350] [D loss: 0.251151, acc:  45%] [G loss: 1.151586] time: 4:22:31.601460\n",
      "[Epoch 7/10] [Batch 45/350] [D loss: 0.251265, acc:  48%] [G loss: 1.099106] time: 4:22:37.894665\n",
      "[Epoch 7/10] [Batch 46/350] [D loss: 0.250957, acc:  49%] [G loss: 1.000340] time: 4:22:44.191796\n",
      "[Epoch 7/10] [Batch 47/350] [D loss: 0.250940, acc:  48%] [G loss: 1.107010] time: 4:22:50.487961\n",
      "[Epoch 7/10] [Batch 48/350] [D loss: 0.251108, acc:  46%] [G loss: 1.150665] time: 4:22:56.784156\n",
      "[Epoch 7/10] [Batch 49/350] [D loss: 0.251061, acc:  49%] [G loss: 0.956816] time: 4:23:03.109215\n",
      "[Epoch 7/10] [Batch 50/350] [D loss: 0.251016, acc:  48%] [G loss: 0.974394] time: 4:23:09.382441\n",
      "[Epoch 7/10] [Batch 51/350] [D loss: 0.251336, acc:  47%] [G loss: 0.948578] time: 4:23:15.673651\n",
      "[Epoch 7/10] [Batch 52/350] [D loss: 0.251317, acc:  49%] [G loss: 0.988866] time: 4:23:21.970815\n",
      "[Epoch 7/10] [Batch 53/350] [D loss: 0.251396, acc:  50%] [G loss: 0.986744] time: 4:23:28.299860\n",
      "[Epoch 7/10] [Batch 54/350] [D loss: 0.251222, acc:  51%] [G loss: 1.117514] time: 4:23:34.596025\n",
      "[Epoch 7/10] [Batch 55/350] [D loss: 0.251191, acc:  50%] [G loss: 1.062281] time: 4:23:40.909146\n",
      "[Epoch 7/10] [Batch 56/350] [D loss: 0.250938, acc:  48%] [G loss: 1.232090] time: 4:23:47.210297\n",
      "[Epoch 7/10] [Batch 57/350] [D loss: 0.251197, acc:  56%] [G loss: 1.140294] time: 4:23:53.471557\n",
      "[Epoch 7/10] [Batch 58/350] [D loss: 0.251287, acc:  51%] [G loss: 1.198611] time: 4:23:59.773736\n",
      "[Epoch 7/10] [Batch 59/350] [D loss: 0.251223, acc:  52%] [G loss: 1.189869] time: 4:24:06.063918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/10] [Batch 60/350] [D loss: 0.251443, acc:  52%] [G loss: 1.245707] time: 4:24:12.340105\n",
      "[Epoch 7/10] [Batch 61/350] [D loss: 0.251397, acc:  47%] [G loss: 1.468090] time: 4:24:18.633279\n",
      "[Epoch 7/10] [Batch 62/350] [D loss: 0.251119, acc:  41%] [G loss: 1.264385] time: 4:24:24.937454\n",
      "[Epoch 7/10] [Batch 63/350] [D loss: 0.251138, acc:  50%] [G loss: 1.222167] time: 4:24:31.246553\n",
      "[Epoch 7/10] [Batch 64/350] [D loss: 0.251113, acc:  47%] [G loss: 1.318526] time: 4:24:37.522772\n",
      "[Epoch 7/10] [Batch 65/350] [D loss: 0.251404, acc:  45%] [G loss: 1.108177] time: 4:24:43.837887\n",
      "[Epoch 7/10] [Batch 66/350] [D loss: 0.251198, acc:  49%] [G loss: 1.138054] time: 4:24:50.132057\n",
      "[Epoch 7/10] [Batch 67/350] [D loss: 0.251265, acc:  49%] [G loss: 1.225210] time: 4:24:56.416255\n",
      "[Epoch 7/10] [Batch 68/350] [D loss: 0.251620, acc:  48%] [G loss: 1.108174] time: 4:25:02.717407\n",
      "[Epoch 7/10] [Batch 69/350] [D loss: 0.251757, acc:  47%] [G loss: 1.249349] time: 4:25:09.010580\n",
      "[Epoch 7/10] [Batch 70/350] [D loss: 0.251843, acc:  47%] [G loss: 1.205090] time: 4:25:15.298766\n",
      "[Epoch 7/10] [Batch 71/350] [D loss: 0.251505, acc:  48%] [G loss: 1.176503] time: 4:25:21.597956\n",
      "[Epoch 7/10] [Batch 72/350] [D loss: 0.251668, acc:  51%] [G loss: 1.166354] time: 4:25:27.887108\n",
      "[Epoch 7/10] [Batch 73/350] [D loss: 0.251610, acc:  51%] [G loss: 1.103325] time: 4:25:34.183274\n",
      "[Epoch 7/10] [Batch 74/350] [D loss: 0.251756, acc:  49%] [G loss: 1.296824] time: 4:25:40.477444\n",
      "[Epoch 7/10] [Batch 75/350] [D loss: 0.252299, acc:  48%] [G loss: 1.233534] time: 4:25:46.793556\n",
      "[Epoch 7/10] [Batch 76/350] [D loss: 0.252152, acc:  48%] [G loss: 1.415658] time: 4:25:53.072799\n",
      "[Epoch 7/10] [Batch 77/350] [D loss: 0.251400, acc:  52%] [G loss: 1.161857] time: 4:25:59.361951\n",
      "[Epoch 7/10] [Batch 78/350] [D loss: 0.251809, acc:  52%] [G loss: 1.200126] time: 4:26:05.655124\n",
      "[Epoch 7/10] [Batch 79/350] [D loss: 0.251549, acc:  47%] [G loss: 1.333057] time: 4:26:11.950292\n",
      "[Epoch 7/10] [Batch 80/350] [D loss: 0.251591, acc:  50%] [G loss: 1.220615] time: 4:26:18.239476\n",
      "[Epoch 7/10] [Batch 81/350] [D loss: 0.252312, acc:  52%] [G loss: 1.277205] time: 4:26:24.520713\n",
      "[Epoch 7/10] [Batch 82/350] [D loss: 0.252316, acc:  51%] [G loss: 1.033387] time: 4:26:30.822831\n",
      "[Epoch 7/10] [Batch 83/350] [D loss: 0.251969, acc:  50%] [G loss: 1.245305] time: 4:26:37.120991\n",
      "[Epoch 7/10] [Batch 84/350] [D loss: 0.252187, acc:  46%] [G loss: 1.358590] time: 4:26:43.402197\n",
      "[Epoch 7/10] [Batch 85/350] [D loss: 0.251799, acc:  47%] [G loss: 1.218872] time: 4:26:49.680409\n",
      "[Epoch 7/10] [Batch 86/350] [D loss: 0.251548, acc:  50%] [G loss: 1.102695] time: 4:26:55.960617\n",
      "[Epoch 7/10] [Batch 87/350] [D loss: 0.252042, acc:  52%] [G loss: 1.329679] time: 4:27:02.237833\n",
      "[Epoch 7/10] [Batch 88/350] [D loss: 0.251890, acc:  50%] [G loss: 1.058417] time: 4:27:08.533001\n",
      "[Epoch 7/10] [Batch 89/350] [D loss: 0.251175, acc:  52%] [G loss: 1.136791] time: 4:27:14.904964\n",
      "[Epoch 7/10] [Batch 90/350] [D loss: 0.251133, acc:  50%] [G loss: 1.099055] time: 4:27:21.193151\n",
      "[Epoch 7/10] [Batch 91/350] [D loss: 0.251041, acc:  48%] [G loss: 1.011661] time: 4:27:27.488319\n",
      "[Epoch 7/10] [Batch 92/350] [D loss: 0.251243, acc:  47%] [G loss: 1.037103] time: 4:27:33.792463\n",
      "[Epoch 7/10] [Batch 93/350] [D loss: 0.251030, acc:  50%] [G loss: 1.098668] time: 4:27:40.096638\n",
      "[Epoch 7/10] [Batch 94/350] [D loss: 0.251037, acc:  49%] [G loss: 1.178838] time: 4:27:46.405738\n",
      "[Epoch 7/10] [Batch 95/350] [D loss: 0.251039, acc:  47%] [G loss: 1.171771] time: 4:27:52.704895\n",
      "[Epoch 7/10] [Batch 96/350] [D loss: 0.251043, acc:  50%] [G loss: 0.992070] time: 4:27:58.978122\n",
      "[Epoch 7/10] [Batch 97/350] [D loss: 0.251151, acc:  49%] [G loss: 1.234373] time: 4:28:05.254340\n",
      "[Epoch 7/10] [Batch 98/350] [D loss: 0.251139, acc:  49%] [G loss: 1.024852] time: 4:28:11.527567\n",
      "[Epoch 7/10] [Batch 99/350] [D loss: 0.251033, acc:  45%] [G loss: 1.095481] time: 4:28:17.824729\n",
      "[Epoch 7/10] [Batch 100/350] [D loss: 0.251045, acc:  51%] [G loss: 1.228685] time: 4:28:24.091972\n",
      "[Epoch 7/10] [Batch 101/350] [D loss: 0.251310, acc:  49%] [G loss: 1.034427] time: 4:28:30.410079\n",
      "[Epoch 7/10] [Batch 102/350] [D loss: 0.252247, acc:  56%] [G loss: 1.300542] time: 4:28:36.697268\n",
      "[Epoch 7/10] [Batch 103/350] [D loss: 0.252663, acc:  49%] [G loss: 1.203871] time: 4:28:42.992467\n",
      "[Epoch 7/10] [Batch 104/350] [D loss: 0.251826, acc:  54%] [G loss: 1.209043] time: 4:28:49.287604\n",
      "[Epoch 7/10] [Batch 105/350] [D loss: 0.251643, acc:  41%] [G loss: 1.124424] time: 4:28:55.584767\n",
      "[Epoch 7/10] [Batch 106/350] [D loss: 0.251841, acc:  51%] [G loss: 1.350639] time: 4:29:01.874948\n",
      "[Epoch 7/10] [Batch 107/350] [D loss: 0.251365, acc:  53%] [G loss: 0.965722] time: 4:29:08.177097\n",
      "[Epoch 7/10] [Batch 108/350] [D loss: 0.251580, acc:  45%] [G loss: 1.102678] time: 4:29:14.464318\n",
      "[Epoch 7/10] [Batch 109/350] [D loss: 0.252609, acc:  52%] [G loss: 1.109749] time: 4:29:20.736516\n",
      "[Epoch 7/10] [Batch 110/350] [D loss: 0.252163, acc:  49%] [G loss: 1.255760] time: 4:29:27.026697\n",
      "[Epoch 7/10] [Batch 111/350] [D loss: 0.251669, acc:  46%] [G loss: 1.099651] time: 4:29:33.321896\n",
      "[Epoch 7/10] [Batch 112/350] [D loss: 0.252542, acc:  50%] [G loss: 1.288177] time: 4:29:39.624015\n",
      "[Epoch 7/10] [Batch 113/350] [D loss: 0.252426, acc:  50%] [G loss: 1.108058] time: 4:29:45.941124\n",
      "[Epoch 7/10] [Batch 114/350] [D loss: 0.251555, acc:  47%] [G loss: 1.118017] time: 4:29:52.227316\n",
      "[Epoch 7/10] [Batch 115/350] [D loss: 0.252092, acc:  47%] [G loss: 1.300907] time: 4:29:58.525510\n",
      "[Epoch 7/10] [Batch 116/350] [D loss: 0.252206, acc:  56%] [G loss: 1.192913] time: 4:30:04.828623\n",
      "[Epoch 7/10] [Batch 117/350] [D loss: 0.251772, acc:  53%] [G loss: 1.098361] time: 4:30:11.104841\n",
      "[Epoch 7/10] [Batch 118/350] [D loss: 0.252584, acc:  49%] [G loss: 1.195656] time: 4:30:17.382057\n",
      "[Epoch 7/10] [Batch 119/350] [D loss: 0.251575, acc:  43%] [G loss: 1.113669] time: 4:30:23.676228\n",
      "[Epoch 7/10] [Batch 120/350] [D loss: 0.251363, acc:  56%] [G loss: 1.152161] time: 4:30:29.982366\n",
      "[Epoch 7/10] [Batch 121/350] [D loss: 0.251483, acc:  50%] [G loss: 1.055516] time: 4:30:36.261577\n",
      "[Epoch 7/10] [Batch 122/350] [D loss: 0.251255, acc:  45%] [G loss: 1.095265] time: 4:30:42.537796\n",
      "[Epoch 7/10] [Batch 123/350] [D loss: 0.251559, acc:  49%] [G loss: 1.064967] time: 4:30:48.820030\n",
      "[Epoch 7/10] [Batch 124/350] [D loss: 0.252069, acc:  50%] [G loss: 1.096513] time: 4:30:55.102201\n",
      "[Epoch 7/10] [Batch 125/350] [D loss: 0.251708, acc:  48%] [G loss: 1.033151] time: 4:31:01.389390\n",
      "[Epoch 7/10] [Batch 126/350] [D loss: 0.251374, acc:  46%] [G loss: 1.191091] time: 4:31:07.674585\n",
      "[Epoch 7/10] [Batch 127/350] [D loss: 0.251799, acc:  52%] [G loss: 1.168097] time: 4:31:13.950804\n",
      "[Epoch 7/10] [Batch 128/350] [D loss: 0.251985, acc:  50%] [G loss: 1.050927] time: 4:31:20.245972\n",
      "[Epoch 7/10] [Batch 129/350] [D loss: 0.251441, acc:  48%] [G loss: 1.188012] time: 4:31:26.550116\n",
      "[Epoch 7/10] [Batch 130/350] [D loss: 0.251883, acc:  49%] [G loss: 1.215986] time: 4:31:32.856255\n",
      "[Epoch 7/10] [Batch 131/350] [D loss: 0.251648, acc:  50%] [G loss: 1.061582] time: 4:31:39.161428\n",
      "[Epoch 7/10] [Batch 132/350] [D loss: 0.251368, acc:  48%] [G loss: 1.043041] time: 4:31:45.475514\n",
      "[Epoch 7/10] [Batch 133/350] [D loss: 0.252192, acc:  48%] [G loss: 1.189606] time: 4:31:51.762734\n",
      "[Epoch 7/10] [Batch 134/350] [D loss: 0.251827, acc:  47%] [G loss: 1.147848] time: 4:31:58.031971\n",
      "[Epoch 7/10] [Batch 135/350] [D loss: 0.251114, acc:  45%] [G loss: 1.256194] time: 4:32:04.331097\n",
      "[Epoch 7/10] [Batch 136/350] [D loss: 0.251008, acc:  47%] [G loss: 1.057362] time: 4:32:10.613332\n",
      "[Epoch 7/10] [Batch 137/350] [D loss: 0.250928, acc:  48%] [G loss: 1.187255] time: 4:32:16.961327\n",
      "[Epoch 7/10] [Batch 138/350] [D loss: 0.251127, acc:  54%] [G loss: 1.281724] time: 4:32:23.251508\n",
      "[Epoch 7/10] [Batch 139/350] [D loss: 0.251465, acc:  53%] [G loss: 1.076193] time: 4:32:29.556649\n",
      "[Epoch 7/10] [Batch 140/350] [D loss: 0.251503, acc:  49%] [G loss: 1.169090] time: 4:32:35.857834\n",
      "[Epoch 7/10] [Batch 141/350] [D loss: 0.251314, acc:  44%] [G loss: 1.067941] time: 4:32:42.127039\n",
      "[Epoch 7/10] [Batch 142/350] [D loss: 0.251335, acc:  49%] [G loss: 1.080785] time: 4:32:48.426225\n",
      "[Epoch 7/10] [Batch 143/350] [D loss: 0.251153, acc:  48%] [G loss: 1.196033] time: 4:32:54.687455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/10] [Batch 144/350] [D loss: 0.251145, acc:  48%] [G loss: 1.195626] time: 4:33:00.967663\n",
      "[Epoch 7/10] [Batch 145/350] [D loss: 0.251320, acc:  47%] [G loss: 1.328567] time: 4:33:07.255849\n",
      "[Epoch 7/10] [Batch 146/350] [D loss: 0.251140, acc:  46%] [G loss: 1.195621] time: 4:33:13.546031\n",
      "[Epoch 7/10] [Batch 147/350] [D loss: 0.251163, acc:  47%] [G loss: 1.175318] time: 4:33:19.844191\n",
      "[Epoch 7/10] [Batch 148/350] [D loss: 0.251757, acc:  42%] [G loss: 1.155620] time: 4:33:26.154319\n",
      "[Epoch 7/10] [Batch 149/350] [D loss: 0.251674, acc:  49%] [G loss: 1.122307] time: 4:33:32.489380\n",
      "[Epoch 7/10] [Batch 150/350] [D loss: 0.251355, acc:  51%] [G loss: 1.328147] time: 4:33:38.793524\n",
      "[Epoch 7/10] [Batch 151/350] [D loss: 0.250998, acc:  46%] [G loss: 1.230254] time: 4:33:45.126591\n",
      "[Epoch 7/10] [Batch 152/350] [D loss: 0.250982, acc:  47%] [G loss: 1.337022] time: 4:33:51.414777\n",
      "[Epoch 7/10] [Batch 153/350] [D loss: 0.250886, acc:  48%] [G loss: 1.116599] time: 4:33:57.709977\n",
      "[Epoch 7/10] [Batch 154/350] [D loss: 0.251312, acc:  49%] [G loss: 1.242219] time: 4:34:04.029049\n",
      "[Epoch 7/10] [Batch 155/350] [D loss: 0.251385, acc:  46%] [G loss: 1.151586] time: 4:34:10.323220\n",
      "[Epoch 7/10] [Batch 156/350] [D loss: 0.251393, acc:  46%] [G loss: 1.125427] time: 4:34:16.607417\n",
      "[Epoch 7/10] [Batch 157/350] [D loss: 0.251340, acc:  48%] [G loss: 1.183182] time: 4:34:22.892612\n",
      "[Epoch 7/10] [Batch 158/350] [D loss: 0.251241, acc:  51%] [G loss: 1.145726] time: 4:34:29.181796\n",
      "[Epoch 7/10] [Batch 159/350] [D loss: 0.251108, acc:  44%] [G loss: 1.298279] time: 4:34:35.492921\n",
      "[Epoch 7/10] [Batch 160/350] [D loss: 0.251087, acc:  50%] [G loss: 1.100545] time: 4:34:41.788090\n",
      "[Epoch 7/10] [Batch 161/350] [D loss: 0.251261, acc:  48%] [G loss: 1.181938] time: 4:34:48.061316\n",
      "[Epoch 7/10] [Batch 162/350] [D loss: 0.251114, acc:  47%] [G loss: 1.092624] time: 4:34:54.372476\n",
      "[Epoch 7/10] [Batch 163/350] [D loss: 0.251442, acc:  43%] [G loss: 1.139010] time: 4:35:00.671599\n",
      "[Epoch 7/10] [Batch 164/350] [D loss: 0.251490, acc:  49%] [G loss: 1.067593] time: 4:35:06.946855\n",
      "[Epoch 7/10] [Batch 165/350] [D loss: 0.251197, acc:  41%] [G loss: 1.086925] time: 4:35:13.221045\n",
      "[Epoch 7/10] [Batch 166/350] [D loss: 0.251121, acc:  49%] [G loss: 1.132682] time: 4:35:19.508233\n",
      "[Epoch 7/10] [Batch 167/350] [D loss: 0.251111, acc:  49%] [G loss: 0.957246] time: 4:35:25.804433\n",
      "[Epoch 7/10] [Batch 168/350] [D loss: 0.251224, acc:  51%] [G loss: 1.109932] time: 4:35:32.112532\n",
      "[Epoch 7/10] [Batch 169/350] [D loss: 0.251800, acc:  57%] [G loss: 0.939581] time: 4:35:38.377780\n",
      "[Epoch 7/10] [Batch 170/350] [D loss: 0.252078, acc:  49%] [G loss: 1.194820] time: 4:35:44.712841\n",
      "[Epoch 7/10] [Batch 171/350] [D loss: 0.251610, acc:  49%] [G loss: 1.138321] time: 4:35:51.016021\n",
      "[Epoch 7/10] [Batch 172/350] [D loss: 0.252047, acc:  55%] [G loss: 1.120712] time: 4:35:57.289244\n",
      "[Epoch 7/10] [Batch 173/350] [D loss: 0.252881, acc:  49%] [G loss: 1.363167] time: 4:36:03.601369\n",
      "[Epoch 7/10] [Batch 174/350] [D loss: 0.251924, acc:  50%] [G loss: 1.128904] time: 4:36:09.893513\n",
      "[Epoch 7/10] [Batch 175/350] [D loss: 0.252031, acc:  48%] [G loss: 1.228053] time: 4:36:16.182697\n",
      "[Epoch 7/10] [Batch 176/350] [D loss: 0.252812, acc:  49%] [G loss: 1.109130] time: 4:36:28.069913\n",
      "[Epoch 7/10] [Batch 177/350] [D loss: 0.251985, acc:  49%] [G loss: 1.198654] time: 4:36:34.362089\n",
      "[Epoch 7/10] [Batch 178/350] [D loss: 0.251039, acc:  50%] [G loss: 1.146989] time: 4:36:40.667231\n",
      "[Epoch 7/10] [Batch 179/350] [D loss: 0.251128, acc:  48%] [G loss: 1.058726] time: 4:36:46.967385\n",
      "[Epoch 7/10] [Batch 180/350] [D loss: 0.251187, acc:  47%] [G loss: 1.041223] time: 4:36:53.281535\n",
      "[Epoch 7/10] [Batch 181/350] [D loss: 0.251251, acc:  50%] [G loss: 1.166068] time: 4:36:59.584681\n",
      "[Epoch 7/10] [Batch 182/350] [D loss: 0.251244, acc:  47%] [G loss: 1.039101] time: 4:37:05.869844\n",
      "[Epoch 7/10] [Batch 183/350] [D loss: 0.250947, acc:  49%] [G loss: 1.225555] time: 4:37:12.163017\n",
      "[Epoch 7/10] [Batch 184/350] [D loss: 0.251045, acc:  50%] [G loss: 1.220648] time: 4:37:18.532019\n",
      "[Epoch 7/10] [Batch 185/350] [D loss: 0.251258, acc:  49%] [G loss: 0.960740] time: 4:37:24.833140\n",
      "[Epoch 7/10] [Batch 186/350] [D loss: 0.251128, acc:  46%] [G loss: 1.180162] time: 4:37:31.105369\n",
      "[Epoch 7/10] [Batch 187/350] [D loss: 0.251051, acc:  46%] [G loss: 1.165026] time: 4:37:37.415529\n",
      "[Epoch 7/10] [Batch 188/350] [D loss: 0.251244, acc:  48%] [G loss: 0.966655] time: 4:37:43.745572\n",
      "[Epoch 7/10] [Batch 189/350] [D loss: 0.251263, acc:  56%] [G loss: 1.095918] time: 4:37:50.045726\n",
      "[Epoch 7/10] [Batch 190/350] [D loss: 0.251217, acc:  51%] [G loss: 1.322742] time: 4:37:56.301999\n",
      "[Epoch 7/10] [Batch 191/350] [D loss: 0.251509, acc:  45%] [G loss: 1.185508] time: 4:38:02.598195\n",
      "[Epoch 7/10] [Batch 192/350] [D loss: 0.251323, acc:  44%] [G loss: 1.043231] time: 4:38:08.865438\n",
      "[Epoch 7/10] [Batch 193/350] [D loss: 0.251596, acc:  50%] [G loss: 1.153394] time: 4:38:15.137636\n",
      "[Epoch 7/10] [Batch 194/350] [D loss: 0.251585, acc:  50%] [G loss: 1.308806] time: 4:38:21.420836\n",
      "[Epoch 7/10] [Batch 195/350] [D loss: 0.251862, acc:  45%] [G loss: 1.104118] time: 4:38:27.708056\n",
      "[Epoch 7/10] [Batch 196/350] [D loss: 0.252266, acc:  54%] [G loss: 1.161236] time: 4:38:33.984244\n",
      "[Epoch 7/10] [Batch 197/350] [D loss: 0.251940, acc:  52%] [G loss: 0.995632] time: 4:38:40.278447\n",
      "[Epoch 7/10] [Batch 198/350] [D loss: 0.251662, acc:  48%] [G loss: 1.065853] time: 4:38:46.547684\n",
      "[Epoch 7/10] [Batch 199/350] [D loss: 0.252020, acc:  45%] [G loss: 1.115168] time: 4:38:52.833876\n",
      "[Epoch 7/10] [Batch 200/350] [D loss: 0.251585, acc:  45%] [G loss: 1.149963] time: 4:38:59.140980\n",
      "[Epoch 7/10] [Batch 201/350] [D loss: 0.251001, acc:  49%] [G loss: 0.988708] time: 4:39:05.435151\n",
      "[Epoch 7/10] [Batch 202/350] [D loss: 0.251176, acc:  47%] [G loss: 1.125006] time: 4:39:11.697407\n",
      "[Epoch 7/10] [Batch 203/350] [D loss: 0.251109, acc:  44%] [G loss: 1.053380] time: 4:39:17.975654\n",
      "[Epoch 7/10] [Batch 204/350] [D loss: 0.251225, acc:  45%] [G loss: 1.074032] time: 4:39:24.257822\n",
      "[Epoch 7/10] [Batch 205/350] [D loss: 0.251264, acc:  52%] [G loss: 1.009878] time: 4:39:30.549999\n",
      "[Epoch 7/10] [Batch 206/350] [D loss: 0.251158, acc:  51%] [G loss: 1.081444] time: 4:39:36.840180\n",
      "[Epoch 7/10] [Batch 207/350] [D loss: 0.251149, acc:  51%] [G loss: 1.180374] time: 4:39:43.181226\n",
      "[Epoch 7/10] [Batch 208/350] [D loss: 0.251259, acc:  48%] [G loss: 1.052233] time: 4:39:49.475396\n",
      "[Epoch 7/10] [Batch 209/350] [D loss: 0.251820, acc:  47%] [G loss: 1.239332] time: 4:39:55.755604\n",
      "[Epoch 7/10] [Batch 210/350] [D loss: 0.251548, acc:  51%] [G loss: 1.137959] time: 4:40:02.038835\n",
      "[Epoch 7/10] [Batch 211/350] [D loss: 0.251321, acc:  47%] [G loss: 0.998410] time: 4:40:08.314057\n",
      "[Epoch 7/10] [Batch 212/350] [D loss: 0.251205, acc:  45%] [G loss: 0.904978] time: 4:40:14.606201\n",
      "[Epoch 7/10] [Batch 213/350] [D loss: 0.251431, acc:  48%] [G loss: 1.072237] time: 4:40:20.899375\n",
      "[Epoch 7/10] [Batch 214/350] [D loss: 0.251031, acc:  48%] [G loss: 1.029369] time: 4:40:27.192579\n",
      "[Epoch 7/10] [Batch 215/350] [D loss: 0.250997, acc:  49%] [G loss: 1.140807] time: 4:40:33.476745\n",
      "[Epoch 7/10] [Batch 216/350] [D loss: 0.250928, acc:  49%] [G loss: 0.998002] time: 4:40:39.759958\n",
      "[Epoch 7/10] [Batch 217/350] [D loss: 0.251016, acc:  49%] [G loss: 0.957576] time: 4:40:46.044143\n",
      "[Epoch 7/10] [Batch 218/350] [D loss: 0.251093, acc:  48%] [G loss: 1.078123] time: 4:40:52.351279\n",
      "[Epoch 7/10] [Batch 219/350] [D loss: 0.251939, acc:  39%] [G loss: 1.058122] time: 4:40:58.661438\n",
      "[Epoch 7/10] [Batch 220/350] [D loss: 0.252276, acc:  48%] [G loss: 1.304354] time: 4:41:04.965551\n",
      "[Epoch 7/10] [Batch 221/350] [D loss: 0.251810, acc:  46%] [G loss: 0.975552] time: 4:41:11.249748\n",
      "[Epoch 7/10] [Batch 222/350] [D loss: 0.251276, acc:  49%] [G loss: 1.013147] time: 4:41:17.523972\n",
      "[Epoch 7/10] [Batch 223/350] [D loss: 0.251482, acc:  52%] [G loss: 1.201152] time: 4:41:23.814153\n",
      "[Epoch 7/10] [Batch 224/350] [D loss: 0.251606, acc:  49%] [G loss: 1.158599] time: 4:41:30.103368\n",
      "[Epoch 7/10] [Batch 225/350] [D loss: 0.250993, acc:  51%] [G loss: 1.044799] time: 4:41:36.394516\n",
      "[Epoch 7/10] [Batch 226/350] [D loss: 0.251011, acc:  47%] [G loss: 1.122489] time: 4:41:42.722596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/10] [Batch 227/350] [D loss: 0.251330, acc:  47%] [G loss: 1.203652] time: 4:41:49.038708\n",
      "[Epoch 7/10] [Batch 228/350] [D loss: 0.251347, acc:  48%] [G loss: 1.129284] time: 4:41:55.303956\n",
      "[Epoch 7/10] [Batch 229/350] [D loss: 0.251096, acc:  48%] [G loss: 1.171038] time: 4:42:01.611092\n",
      "[Epoch 7/10] [Batch 230/350] [D loss: 0.251305, acc:  51%] [G loss: 1.151374] time: 4:42:07.893326\n",
      "[Epoch 7/10] [Batch 231/350] [D loss: 0.251369, acc:  45%] [G loss: 1.271981] time: 4:42:14.174500\n",
      "[Epoch 7/10] [Batch 232/350] [D loss: 0.251296, acc:  51%] [G loss: 1.100839] time: 4:42:20.452713\n",
      "[Epoch 7/10] [Batch 233/350] [D loss: 0.251308, acc:  47%] [G loss: 1.053963] time: 4:42:26.734948\n",
      "[Epoch 7/10] [Batch 234/350] [D loss: 0.251303, acc:  48%] [G loss: 1.167854] time: 4:42:33.026130\n",
      "[Epoch 7/10] [Batch 235/350] [D loss: 0.251074, acc:  48%] [G loss: 1.151227] time: 4:42:39.314281\n",
      "[Epoch 7/10] [Batch 236/350] [D loss: 0.251216, acc:  43%] [G loss: 1.064450] time: 4:42:45.612441\n",
      "[Epoch 7/10] [Batch 237/350] [D loss: 0.251223, acc:  48%] [G loss: 1.076338] time: 4:42:51.934537\n",
      "[Epoch 7/10] [Batch 238/350] [D loss: 0.251048, acc:  49%] [G loss: 1.072200] time: 4:42:58.211753\n",
      "[Epoch 7/10] [Batch 239/350] [D loss: 0.250891, acc:  46%] [G loss: 1.041571] time: 4:43:04.485011\n",
      "[Epoch 7/10] [Batch 240/350] [D loss: 0.251167, acc:  46%] [G loss: 1.147640] time: 4:43:10.770175\n",
      "[Epoch 7/10] [Batch 241/350] [D loss: 0.251178, acc:  48%] [G loss: 1.110031] time: 4:43:17.053375\n",
      "[Epoch 7/10] [Batch 242/350] [D loss: 0.251084, acc:  44%] [G loss: 1.081891] time: 4:43:23.324607\n",
      "[Epoch 7/10] [Batch 243/350] [D loss: 0.251614, acc:  41%] [G loss: 1.330096] time: 4:43:29.645705\n",
      "[Epoch 7/10] [Batch 244/350] [D loss: 0.251527, acc:  48%] [G loss: 1.038986] time: 4:43:35.933892\n",
      "[Epoch 7/10] [Batch 245/350] [D loss: 0.251114, acc:  51%] [G loss: 1.121884] time: 4:43:42.270980\n",
      "[Epoch 7/10] [Batch 246/350] [D loss: 0.251148, acc:  54%] [G loss: 1.125984] time: 4:43:48.562127\n",
      "[Epoch 7/10] [Batch 247/350] [D loss: 0.251334, acc:  48%] [G loss: 1.029018] time: 4:43:54.868266\n",
      "[Epoch 7/10] [Batch 248/350] [D loss: 0.251122, acc:  44%] [G loss: 1.209529] time: 4:44:01.137503\n",
      "[Epoch 7/10] [Batch 249/350] [D loss: 0.251076, acc:  51%] [G loss: 1.307246] time: 4:44:07.436660\n",
      "[Epoch 7/10] [Batch 250/350] [D loss: 0.251238, acc:  46%] [G loss: 1.266633] time: 4:44:13.731828\n",
      "[Epoch 7/10] [Batch 251/350] [D loss: 0.251067, acc:  50%] [G loss: 1.239525] time: 4:44:20.024004\n",
      "[Epoch 7/10] [Batch 252/350] [D loss: 0.251253, acc:  50%] [G loss: 1.070790] time: 4:44:26.338153\n",
      "[Epoch 7/10] [Batch 253/350] [D loss: 0.251170, acc:  50%] [G loss: 1.298419] time: 4:44:32.658223\n",
      "[Epoch 7/10] [Batch 254/350] [D loss: 0.251228, acc:  47%] [G loss: 1.141555] time: 4:44:38.948436\n",
      "[Epoch 7/10] [Batch 255/350] [D loss: 0.251133, acc:  49%] [G loss: 1.138415] time: 4:44:45.232601\n",
      "[Epoch 7/10] [Batch 256/350] [D loss: 0.251296, acc:  44%] [G loss: 1.048529] time: 4:44:51.537775\n",
      "[Epoch 7/10] [Batch 257/350] [D loss: 0.251118, acc:  46%] [G loss: 1.198814] time: 4:44:57.832911\n",
      "[Epoch 7/10] [Batch 258/350] [D loss: 0.250963, acc:  46%] [G loss: 1.247662] time: 4:45:04.117108\n",
      "[Epoch 7/10] [Batch 259/350] [D loss: 0.250868, acc:  46%] [G loss: 0.956533] time: 4:45:10.408293\n",
      "[Epoch 7/10] [Batch 260/350] [D loss: 0.250917, acc:  49%] [G loss: 1.115591] time: 4:45:16.689492\n",
      "[Epoch 7/10] [Batch 261/350] [D loss: 0.251090, acc:  48%] [G loss: 1.040636] time: 4:45:22.976710\n",
      "[Epoch 7/10] [Batch 262/350] [D loss: 0.251005, acc:  45%] [G loss: 1.367784] time: 4:45:29.266894\n",
      "[Epoch 7/10] [Batch 263/350] [D loss: 0.251101, acc:  48%] [G loss: 1.107762] time: 4:45:35.563028\n",
      "[Epoch 7/10] [Batch 264/350] [D loss: 0.251047, acc:  49%] [G loss: 1.137021] time: 4:45:41.882132\n",
      "[Epoch 7/10] [Batch 265/350] [D loss: 0.251408, acc:  48%] [G loss: 0.991729] time: 4:45:48.180292\n",
      "[Epoch 7/10] [Batch 266/350] [D loss: 0.251347, acc:  48%] [G loss: 1.040011] time: 4:45:54.487428\n",
      "[Epoch 7/10] [Batch 267/350] [D loss: 0.251298, acc:  49%] [G loss: 0.980169] time: 4:46:00.775646\n",
      "[Epoch 7/10] [Batch 268/350] [D loss: 0.251442, acc:  54%] [G loss: 1.081954] time: 4:46:07.039899\n",
      "[Epoch 7/10] [Batch 269/350] [D loss: 0.251634, acc:  47%] [G loss: 1.062995] time: 4:46:13.321102\n",
      "[Epoch 7/10] [Batch 270/350] [D loss: 0.251306, acc:  39%] [G loss: 1.169904] time: 4:46:19.602276\n",
      "[Epoch 7/10] [Batch 271/350] [D loss: 0.251322, acc:  51%] [G loss: 0.952111] time: 4:46:25.905455\n",
      "[Epoch 7/10] [Batch 272/350] [D loss: 0.251268, acc:  49%] [G loss: 1.158606] time: 4:46:32.214553\n",
      "[Epoch 7/10] [Batch 273/350] [D loss: 0.251107, acc:  52%] [G loss: 1.218569] time: 4:46:38.496756\n",
      "[Epoch 7/10] [Batch 274/350] [D loss: 0.250840, acc:  50%] [G loss: 1.254431] time: 4:46:44.776964\n",
      "[Epoch 7/10] [Batch 275/350] [D loss: 0.251283, acc:  48%] [G loss: 1.127962] time: 4:46:51.075124\n",
      "[Epoch 7/10] [Batch 276/350] [D loss: 0.251218, acc:  56%] [G loss: 1.103427] time: 4:46:57.353369\n",
      "[Epoch 7/10] [Batch 277/350] [D loss: 0.251310, acc:  49%] [G loss: 1.048776] time: 4:47:03.643519\n",
      "[Epoch 7/10] [Batch 278/350] [D loss: 0.251052, acc:  48%] [G loss: 1.150658] time: 4:47:09.936692\n",
      "[Epoch 7/10] [Batch 279/350] [D loss: 0.251097, acc:  46%] [G loss: 1.102626] time: 4:47:16.325609\n",
      "[Epoch 7/10] [Batch 280/350] [D loss: 0.251042, acc:  49%] [G loss: 1.071207] time: 4:47:22.608842\n",
      "[Epoch 7/10] [Batch 281/350] [D loss: 0.251047, acc:  49%] [G loss: 1.071954] time: 4:47:28.900985\n",
      "[Epoch 7/10] [Batch 282/350] [D loss: 0.251338, acc:  50%] [G loss: 1.078659] time: 4:47:35.182191\n",
      "[Epoch 7/10] [Batch 283/350] [D loss: 0.251478, acc:  46%] [G loss: 0.973455] time: 4:47:41.502292\n",
      "[Epoch 7/10] [Batch 284/350] [D loss: 0.251563, acc:  49%] [G loss: 1.052029] time: 4:47:47.794468\n",
      "[Epoch 7/10] [Batch 285/350] [D loss: 0.251110, acc:  45%] [G loss: 1.025019] time: 4:47:54.095620\n",
      "[Epoch 7/10] [Batch 286/350] [D loss: 0.251049, acc:  47%] [G loss: 1.036355] time: 4:48:00.373865\n",
      "[Epoch 7/10] [Batch 287/350] [D loss: 0.250914, acc:  46%] [G loss: 1.073179] time: 4:48:06.674019\n",
      "[Epoch 7/10] [Batch 288/350] [D loss: 0.251083, acc:  47%] [G loss: 1.122941] time: 4:48:12.978132\n",
      "[Epoch 7/10] [Batch 289/350] [D loss: 0.251154, acc:  55%] [G loss: 1.183830] time: 4:48:19.239391\n",
      "[Epoch 7/10] [Batch 290/350] [D loss: 0.251174, acc:  50%] [G loss: 0.967546] time: 4:48:25.545529\n",
      "[Epoch 7/10] [Batch 291/350] [D loss: 0.251351, acc:  45%] [G loss: 1.176184] time: 4:48:31.853662\n",
      "[Epoch 7/10] [Batch 292/350] [D loss: 0.251054, acc:  48%] [G loss: 1.033129] time: 4:48:38.147833\n",
      "[Epoch 7/10] [Batch 293/350] [D loss: 0.251028, acc:  48%] [G loss: 1.380400] time: 4:48:44.443998\n",
      "[Epoch 7/10] [Batch 294/350] [D loss: 0.251130, acc:  54%] [G loss: 1.136919] time: 4:48:50.725204\n",
      "[Epoch 7/10] [Batch 295/350] [D loss: 0.251283, acc:  49%] [G loss: 1.117071] time: 4:48:56.983505\n",
      "[Epoch 7/10] [Batch 296/350] [D loss: 0.251059, acc:  44%] [G loss: 1.241855] time: 4:49:03.283626\n",
      "[Epoch 7/10] [Batch 297/350] [D loss: 0.250939, acc:  48%] [G loss: 1.116113] time: 4:49:09.578823\n",
      "[Epoch 7/10] [Batch 298/350] [D loss: 0.250958, acc:  49%] [G loss: 1.176535] time: 4:49:15.858004\n",
      "[Epoch 7/10] [Batch 299/350] [D loss: 0.251045, acc:  48%] [G loss: 1.332674] time: 4:49:22.143199\n",
      "[Epoch 7/10] [Batch 300/350] [D loss: 0.251339, acc:  48%] [G loss: 1.327532] time: 4:49:28.419417\n",
      "[Epoch 7/10] [Batch 301/350] [D loss: 0.251356, acc:  48%] [G loss: 1.212188] time: 4:49:34.714585\n",
      "[Epoch 7/10] [Batch 302/350] [D loss: 0.251333, acc:  49%] [G loss: 1.057611] time: 4:49:41.012745\n",
      "[Epoch 7/10] [Batch 303/350] [D loss: 0.251157, acc:  52%] [G loss: 1.145101] time: 4:49:47.322905\n",
      "[Epoch 7/10] [Batch 304/350] [D loss: 0.251420, acc:  47%] [G loss: 1.002062] time: 4:49:53.631007\n",
      "[Epoch 7/10] [Batch 305/350] [D loss: 0.251416, acc:  50%] [G loss: 1.110209] time: 4:49:59.926175\n",
      "[Epoch 7/10] [Batch 306/350] [D loss: 0.251000, acc:  49%] [G loss: 1.113356] time: 4:50:06.209375\n",
      "[Epoch 7/10] [Batch 307/350] [D loss: 0.251046, acc:  45%] [G loss: 1.197299] time: 4:50:12.488586\n",
      "[Epoch 7/10] [Batch 308/350] [D loss: 0.251021, acc:  50%] [G loss: 1.108137] time: 4:50:18.762809\n",
      "[Epoch 7/10] [Batch 309/350] [D loss: 0.251043, acc:  49%] [G loss: 1.075341] time: 4:50:25.066954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/10] [Batch 310/350] [D loss: 0.251079, acc:  48%] [G loss: 1.111763] time: 4:50:31.372095\n",
      "[Epoch 7/10] [Batch 311/350] [D loss: 0.250965, acc:  45%] [G loss: 1.171076] time: 4:50:37.672249\n",
      "[Epoch 7/10] [Batch 312/350] [D loss: 0.251683, acc:  47%] [G loss: 1.036306] time: 4:50:43.942484\n",
      "[Epoch 7/10] [Batch 313/350] [D loss: 0.251724, acc:  50%] [G loss: 0.933853] time: 4:50:50.244633\n",
      "[Epoch 7/10] [Batch 314/350] [D loss: 0.252145, acc:  49%] [G loss: 1.170595] time: 4:50:56.541796\n",
      "[Epoch 7/10] [Batch 315/350] [D loss: 0.251630, acc:  49%] [G loss: 1.113084] time: 4:51:02.830980\n",
      "[Epoch 7/10] [Batch 316/350] [D loss: 0.251664, acc:  50%] [G loss: 1.139639] time: 4:51:09.123156\n",
      "[Epoch 7/10] [Batch 317/350] [D loss: 0.252457, acc:  51%] [G loss: 1.137296] time: 4:51:15.409348\n",
      "[Epoch 7/10] [Batch 318/350] [D loss: 0.252092, acc:  47%] [G loss: 1.154430] time: 4:51:21.681609\n",
      "[Epoch 7/10] [Batch 319/350] [D loss: 0.251130, acc:  51%] [G loss: 1.167054] time: 4:51:27.944830\n",
      "[Epoch 7/10] [Batch 320/350] [D loss: 0.251398, acc:  48%] [G loss: 1.131774] time: 4:51:34.252998\n",
      "[Epoch 7/10] [Batch 321/350] [D loss: 0.251680, acc:  48%] [G loss: 1.203799] time: 4:51:40.559103\n",
      "[Epoch 7/10] [Batch 322/350] [D loss: 0.251330, acc:  50%] [G loss: 1.328978] time: 4:51:46.870228\n",
      "[Epoch 7/10] [Batch 323/350] [D loss: 0.251231, acc:  50%] [G loss: 1.178301] time: 4:51:53.171380\n",
      "[Epoch 7/10] [Batch 324/350] [D loss: 0.251162, acc:  48%] [G loss: 1.075986] time: 4:51:59.468575\n",
      "[Epoch 7/10] [Batch 325/350] [D loss: 0.251010, acc:  44%] [G loss: 1.199758] time: 4:52:05.762713\n",
      "[Epoch 7/10] [Batch 326/350] [D loss: 0.251356, acc:  51%] [G loss: 1.136229] time: 4:52:12.010009\n",
      "[Epoch 7/10] [Batch 327/350] [D loss: 0.251265, acc:  44%] [G loss: 1.089926] time: 4:52:18.347066\n",
      "[Epoch 7/10] [Batch 328/350] [D loss: 0.251225, acc:  47%] [G loss: 1.115869] time: 4:52:24.655230\n",
      "[Epoch 7/10] [Batch 329/350] [D loss: 0.251048, acc:  48%] [G loss: 1.183653] time: 4:52:30.962335\n",
      "[Epoch 7/10] [Batch 330/350] [D loss: 0.251044, acc:  49%] [G loss: 1.181675] time: 4:52:37.260495\n",
      "[Epoch 7/10] [Batch 331/350] [D loss: 0.251096, acc:  49%] [G loss: 1.320862] time: 4:52:43.555663\n",
      "[Epoch 7/10] [Batch 332/350] [D loss: 0.251234, acc:  47%] [G loss: 1.246762] time: 4:52:49.825897\n",
      "[Epoch 7/10] [Batch 333/350] [D loss: 0.251273, acc:  46%] [G loss: 1.008508] time: 4:52:56.131039\n",
      "[Epoch 7/10] [Batch 334/350] [D loss: 0.251187, acc:  46%] [G loss: 1.067878] time: 4:53:02.425210\n",
      "[Epoch 7/10] [Batch 335/350] [D loss: 0.251333, acc:  43%] [G loss: 1.218566] time: 4:53:08.713396\n",
      "[Epoch 7/10] [Batch 336/350] [D loss: 0.251364, acc:  49%] [G loss: 1.202811] time: 4:53:15.019534\n",
      "[Epoch 7/10] [Batch 337/350] [D loss: 0.251081, acc:  50%] [G loss: 1.136841] time: 4:53:21.305727\n",
      "[Epoch 7/10] [Batch 338/350] [D loss: 0.251004, acc:  48%] [G loss: 1.283409] time: 4:53:27.605913\n",
      "[Epoch 7/10] [Batch 339/350] [D loss: 0.250852, acc:  46%] [G loss: 1.044477] time: 4:53:33.902047\n",
      "[Epoch 7/10] [Batch 340/350] [D loss: 0.251266, acc:  39%] [G loss: 0.982408] time: 4:53:40.224175\n",
      "[Epoch 7/10] [Batch 341/350] [D loss: 0.251400, acc:  48%] [G loss: 1.016882] time: 4:53:46.514324\n",
      "[Epoch 7/10] [Batch 342/350] [D loss: 0.251359, acc:  45%] [G loss: 1.340179] time: 4:53:52.790542\n",
      "[Epoch 7/10] [Batch 343/350] [D loss: 0.251352, acc:  49%] [G loss: 1.125401] time: 4:53:59.086708\n",
      "[Epoch 7/10] [Batch 344/350] [D loss: 0.251729, acc:  45%] [G loss: 1.228875] time: 4:54:05.382873\n",
      "[Epoch 7/10] [Batch 345/350] [D loss: 0.251609, acc:  51%] [G loss: 1.095849] time: 4:54:11.674052\n",
      "[Epoch 7/10] [Batch 346/350] [D loss: 0.251377, acc:  47%] [G loss: 1.094484] time: 4:54:17.970247\n",
      "[Epoch 7/10] [Batch 347/350] [D loss: 0.251540, acc:  55%] [G loss: 1.075971] time: 4:54:24.248431\n",
      "[Epoch 7/10] [Batch 348/350] [D loss: 0.251600, acc:  49%] [G loss: 1.015689] time: 4:54:30.529636\n",
      "weights saved...\n",
      "[Epoch 8/10] [Batch 0/350] [D loss: 0.251123, acc:  49%] [G loss: 1.031721] time: 4:54:37.167918\n",
      "[Epoch 8/10] [Batch 1/350] [D loss: 0.250932, acc:  49%] [G loss: 1.020430] time: 4:54:49.050116\n",
      "[Epoch 8/10] [Batch 2/350] [D loss: 0.251145, acc:  48%] [G loss: 1.159422] time: 4:54:55.343289\n",
      "[Epoch 8/10] [Batch 3/350] [D loss: 0.251386, acc:  51%] [G loss: 1.259477] time: 4:55:01.625492\n",
      "[Epoch 8/10] [Batch 4/350] [D loss: 0.251361, acc:  50%] [G loss: 1.233969] time: 4:55:07.902740\n",
      "[Epoch 8/10] [Batch 5/350] [D loss: 0.251100, acc:  51%] [G loss: 1.240405] time: 4:55:14.197876\n",
      "[Epoch 8/10] [Batch 6/350] [D loss: 0.251357, acc:  40%] [G loss: 1.195131] time: 4:55:20.503017\n",
      "[Epoch 8/10] [Batch 7/350] [D loss: 0.251164, acc:  44%] [G loss: 1.158292] time: 4:55:26.779236\n",
      "[Epoch 8/10] [Batch 8/350] [D loss: 0.251336, acc:  45%] [G loss: 0.998537] time: 4:55:33.136239\n",
      "[Epoch 8/10] [Batch 9/350] [D loss: 0.251504, acc:  51%] [G loss: 1.083770] time: 4:55:39.413455\n",
      "[Epoch 8/10] [Batch 10/350] [D loss: 0.251341, acc:  44%] [G loss: 1.181866] time: 4:55:45.727572\n",
      "[Epoch 8/10] [Batch 11/350] [D loss: 0.251647, acc:  49%] [G loss: 1.252522] time: 4:55:52.014761\n",
      "[Epoch 8/10] [Batch 12/350] [D loss: 0.252001, acc:  51%] [G loss: 1.078030] time: 4:55:58.305940\n",
      "[Epoch 8/10] [Batch 13/350] [D loss: 0.251791, acc:  47%] [G loss: 1.011630] time: 4:56:04.588143\n",
      "[Epoch 8/10] [Batch 14/350] [D loss: 0.251019, acc:  48%] [G loss: 1.029940] time: 4:56:10.873337\n",
      "[Epoch 8/10] [Batch 15/350] [D loss: 0.251037, acc:  50%] [G loss: 1.000389] time: 4:56:17.165513\n",
      "[Epoch 8/10] [Batch 16/350] [D loss: 0.251053, acc:  45%] [G loss: 0.970733] time: 4:56:23.440767\n",
      "[Epoch 8/10] [Batch 17/350] [D loss: 0.251074, acc:  50%] [G loss: 1.337272] time: 4:56:29.708975\n",
      "[Epoch 8/10] [Batch 18/350] [D loss: 0.251093, acc:  48%] [G loss: 1.146791] time: 4:56:35.992175\n",
      "[Epoch 8/10] [Batch 19/350] [D loss: 0.251099, acc:  44%] [G loss: 1.110400] time: 4:56:42.265401\n",
      "[Epoch 8/10] [Batch 20/350] [D loss: 0.251112, acc:  44%] [G loss: 1.293542] time: 4:56:48.563561\n",
      "[Epoch 8/10] [Batch 21/350] [D loss: 0.251237, acc:  49%] [G loss: 1.146846] time: 4:56:54.859727\n",
      "[Epoch 8/10] [Batch 22/350] [D loss: 0.251139, acc:  48%] [G loss: 1.022964] time: 4:57:01.144921\n",
      "[Epoch 8/10] [Batch 23/350] [D loss: 0.250821, acc:  47%] [G loss: 1.177962] time: 4:57:07.434105\n",
      "[Epoch 8/10] [Batch 24/350] [D loss: 0.251068, acc:  47%] [G loss: 1.035323] time: 4:57:13.705337\n",
      "[Epoch 8/10] [Batch 25/350] [D loss: 0.251014, acc:  45%] [G loss: 1.051890] time: 4:57:20.019455\n",
      "[Epoch 8/10] [Batch 26/350] [D loss: 0.250981, acc:  48%] [G loss: 1.100417] time: 4:57:26.305647\n",
      "[Epoch 8/10] [Batch 27/350] [D loss: 0.251066, acc:  46%] [G loss: 1.141024] time: 4:57:32.597823\n",
      "[Epoch 8/10] [Batch 28/350] [D loss: 0.251189, acc:  42%] [G loss: 1.014916] time: 4:57:38.891993\n",
      "[Epoch 8/10] [Batch 29/350] [D loss: 0.251070, acc:  46%] [G loss: 1.068460] time: 4:57:45.221071\n",
      "[Epoch 8/10] [Batch 30/350] [D loss: 0.250928, acc:  49%] [G loss: 1.031808] time: 4:57:51.505268\n",
      "[Epoch 8/10] [Batch 31/350] [D loss: 0.250925, acc:  48%] [G loss: 1.047921] time: 4:57:57.798442\n",
      "[Epoch 8/10] [Batch 32/350] [D loss: 0.250967, acc:  46%] [G loss: 1.004903] time: 4:58:04.115582\n",
      "[Epoch 8/10] [Batch 33/350] [D loss: 0.251007, acc:  47%] [G loss: 1.058081] time: 4:58:10.387811\n",
      "[Epoch 8/10] [Batch 34/350] [D loss: 0.251200, acc:  51%] [G loss: 1.011758] time: 4:58:16.674969\n",
      "[Epoch 8/10] [Batch 35/350] [D loss: 0.251115, acc:  52%] [G loss: 0.899488] time: 4:58:22.971135\n",
      "[Epoch 8/10] [Batch 36/350] [D loss: 0.251047, acc:  51%] [G loss: 0.938010] time: 4:58:29.256329\n",
      "[Epoch 8/10] [Batch 37/350] [D loss: 0.251007, acc:  48%] [G loss: 1.153139] time: 4:58:35.534543\n",
      "[Epoch 8/10] [Batch 38/350] [D loss: 0.251258, acc:  48%] [G loss: 1.115936] time: 4:58:41.825721\n",
      "[Epoch 8/10] [Batch 39/350] [D loss: 0.251007, acc:  49%] [G loss: 1.036052] time: 4:58:48.100943\n",
      "[Epoch 8/10] [Batch 40/350] [D loss: 0.251134, acc:  47%] [G loss: 1.135709] time: 4:58:54.392122\n",
      "[Epoch 8/10] [Batch 41/350] [D loss: 0.251327, acc:  46%] [G loss: 1.102308] time: 4:59:00.696265\n",
      "[Epoch 8/10] [Batch 42/350] [D loss: 0.251142, acc:  49%] [G loss: 0.994041] time: 4:59:06.972484\n",
      "[Epoch 8/10] [Batch 43/350] [D loss: 0.251242, acc:  48%] [G loss: 1.151498] time: 4:59:13.249700\n",
      "[Epoch 8/10] [Batch 44/350] [D loss: 0.251111, acc:  45%] [G loss: 1.109591] time: 4:59:19.529908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/10] [Batch 45/350] [D loss: 0.251222, acc:  48%] [G loss: 1.074386] time: 4:59:25.826073\n",
      "[Epoch 8/10] [Batch 46/350] [D loss: 0.250937, acc:  49%] [G loss: 0.975278] time: 4:59:32.119246\n",
      "[Epoch 8/10] [Batch 47/350] [D loss: 0.250903, acc:  48%] [G loss: 1.062352] time: 4:59:38.393500\n",
      "[Epoch 8/10] [Batch 48/350] [D loss: 0.251075, acc:  46%] [G loss: 1.110462] time: 4:59:44.733518\n",
      "[Epoch 8/10] [Batch 49/350] [D loss: 0.251037, acc:  49%] [G loss: 0.919226] time: 4:59:51.045673\n",
      "[Epoch 8/10] [Batch 50/350] [D loss: 0.250985, acc:  48%] [G loss: 0.931830] time: 4:59:57.325849\n",
      "[Epoch 8/10] [Batch 51/350] [D loss: 0.251298, acc:  47%] [G loss: 0.918110] time: 5:00:03.626035\n",
      "[Epoch 8/10] [Batch 52/350] [D loss: 0.251287, acc:  49%] [G loss: 0.968330] time: 5:00:09.911213\n",
      "[Epoch 8/10] [Batch 53/350] [D loss: 0.251363, acc:  50%] [G loss: 0.954638] time: 5:00:16.232329\n",
      "[Epoch 8/10] [Batch 54/350] [D loss: 0.251198, acc:  50%] [G loss: 1.090739] time: 5:00:22.522479\n",
      "[Epoch 8/10] [Batch 55/350] [D loss: 0.251162, acc:  50%] [G loss: 1.026865] time: 5:00:28.820638\n",
      "[Epoch 8/10] [Batch 56/350] [D loss: 0.250909, acc:  48%] [G loss: 1.175397] time: 5:00:35.105834\n",
      "[Epoch 8/10] [Batch 57/350] [D loss: 0.251163, acc:  55%] [G loss: 1.100422] time: 5:00:41.360111\n",
      "[Epoch 8/10] [Batch 58/350] [D loss: 0.251287, acc:  52%] [G loss: 1.144832] time: 5:00:47.671236\n",
      "[Epoch 8/10] [Batch 59/350] [D loss: 0.251187, acc:  52%] [G loss: 1.127986] time: 5:00:53.960420\n",
      "[Epoch 8/10] [Batch 60/350] [D loss: 0.251416, acc:  52%] [G loss: 1.318554] time: 5:01:00.264564\n",
      "[Epoch 8/10] [Batch 61/350] [D loss: 0.251339, acc:  47%] [G loss: 1.481503] time: 5:01:06.575720\n",
      "[Epoch 8/10] [Batch 62/350] [D loss: 0.251068, acc:  41%] [G loss: 1.292773] time: 5:01:12.851908\n",
      "[Epoch 8/10] [Batch 63/350] [D loss: 0.251081, acc:  50%] [G loss: 1.244436] time: 5:01:19.122174\n",
      "[Epoch 8/10] [Batch 64/350] [D loss: 0.251084, acc:  48%] [G loss: 1.307242] time: 5:01:25.398392\n",
      "[Epoch 8/10] [Batch 65/350] [D loss: 0.251370, acc:  45%] [G loss: 1.079327] time: 5:01:31.707523\n",
      "[Epoch 8/10] [Batch 66/350] [D loss: 0.251153, acc:  48%] [G loss: 1.125321] time: 5:01:38.001692\n",
      "[Epoch 8/10] [Batch 67/350] [D loss: 0.251215, acc:  49%] [G loss: 1.149198] time: 5:01:44.336724\n",
      "[Epoch 8/10] [Batch 68/350] [D loss: 0.251572, acc:  48%] [G loss: 1.062309] time: 5:01:50.651870\n",
      "[Epoch 8/10] [Batch 69/350] [D loss: 0.251727, acc:  47%] [G loss: 1.218389] time: 5:01:56.947007\n",
      "[Epoch 8/10] [Batch 70/350] [D loss: 0.251806, acc:  47%] [G loss: 1.164127] time: 5:02:03.246164\n",
      "[Epoch 8/10] [Batch 71/350] [D loss: 0.251472, acc:  48%] [G loss: 1.138616] time: 5:02:09.530393\n",
      "[Epoch 8/10] [Batch 72/350] [D loss: 0.251636, acc:  51%] [G loss: 1.152454] time: 5:02:15.877391\n",
      "[Epoch 8/10] [Batch 73/350] [D loss: 0.251578, acc:  51%] [G loss: 1.076297] time: 5:02:22.164580\n",
      "[Epoch 8/10] [Batch 74/350] [D loss: 0.251721, acc:  49%] [G loss: 1.264251] time: 5:02:28.448777\n",
      "[Epoch 8/10] [Batch 75/350] [D loss: 0.252253, acc:  48%] [G loss: 1.197604] time: 5:02:34.731977\n",
      "[Epoch 8/10] [Batch 76/350] [D loss: 0.252111, acc:  48%] [G loss: 1.347775] time: 5:02:41.016175\n",
      "[Epoch 8/10] [Batch 77/350] [D loss: 0.251367, acc:  52%] [G loss: 1.097993] time: 5:02:47.317359\n",
      "[Epoch 8/10] [Batch 78/350] [D loss: 0.251774, acc:  52%] [G loss: 1.106417] time: 5:02:53.598532\n",
      "[Epoch 8/10] [Batch 79/350] [D loss: 0.251516, acc:  47%] [G loss: 1.279805] time: 5:02:59.896692\n",
      "[Epoch 8/10] [Batch 80/350] [D loss: 0.251575, acc:  50%] [G loss: 1.169227] time: 5:03:06.184879\n",
      "[Epoch 8/10] [Batch 81/350] [D loss: 0.252270, acc:  52%] [G loss: 1.252979] time: 5:03:12.469076\n",
      "[Epoch 8/10] [Batch 82/350] [D loss: 0.252278, acc:  51%] [G loss: 1.010591] time: 5:03:18.763247\n",
      "[Epoch 8/10] [Batch 83/350] [D loss: 0.251945, acc:  50%] [G loss: 1.207148] time: 5:03:25.068420\n",
      "[Epoch 8/10] [Batch 84/350] [D loss: 0.252166, acc:  46%] [G loss: 1.322351] time: 5:03:31.355577\n",
      "[Epoch 8/10] [Batch 85/350] [D loss: 0.251771, acc:  47%] [G loss: 1.191055] time: 5:03:37.634788\n",
      "[Epoch 8/10] [Batch 86/350] [D loss: 0.251506, acc:  50%] [G loss: 1.067071] time: 5:03:43.954890\n",
      "[Epoch 8/10] [Batch 87/350] [D loss: 0.251996, acc:  52%] [G loss: 1.293190] time: 5:03:50.233102\n",
      "[Epoch 8/10] [Batch 88/350] [D loss: 0.251857, acc:  49%] [G loss: 1.021028] time: 5:03:56.525278\n",
      "[Epoch 8/10] [Batch 89/350] [D loss: 0.251144, acc:  52%] [G loss: 1.105101] time: 5:04:02.834410\n",
      "[Epoch 8/10] [Batch 90/350] [D loss: 0.251109, acc:  50%] [G loss: 1.077486] time: 5:04:09.132569\n",
      "[Epoch 8/10] [Batch 91/350] [D loss: 0.251001, acc:  48%] [G loss: 0.982514] time: 5:04:15.413775\n",
      "[Epoch 8/10] [Batch 92/350] [D loss: 0.251205, acc:  47%] [G loss: 1.017466] time: 5:04:21.695977\n",
      "[Epoch 8/10] [Batch 93/350] [D loss: 0.250998, acc:  50%] [G loss: 1.066062] time: 5:04:28.155705\n",
      "[Epoch 8/10] [Batch 94/350] [D loss: 0.251001, acc:  49%] [G loss: 1.135992] time: 5:04:34.473812\n",
      "[Epoch 8/10] [Batch 95/350] [D loss: 0.251010, acc:  47%] [G loss: 1.120911] time: 5:04:40.785935\n",
      "[Epoch 8/10] [Batch 96/350] [D loss: 0.251011, acc:  50%] [G loss: 0.952754] time: 5:04:47.057167\n",
      "[Epoch 8/10] [Batch 97/350] [D loss: 0.251130, acc:  49%] [G loss: 1.170435] time: 5:04:53.334383\n",
      "[Epoch 8/10] [Batch 98/350] [D loss: 0.251098, acc:  49%] [G loss: 1.009705] time: 5:04:59.604617\n",
      "[Epoch 8/10] [Batch 99/350] [D loss: 0.251016, acc:  45%] [G loss: 1.066472] time: 5:05:05.885823\n",
      "[Epoch 8/10] [Batch 100/350] [D loss: 0.251008, acc:  51%] [G loss: 1.242823] time: 5:05:12.160078\n",
      "[Epoch 8/10] [Batch 101/350] [D loss: 0.251278, acc:  49%] [G loss: 1.046909] time: 5:05:18.461199\n",
      "[Epoch 8/10] [Batch 102/350] [D loss: 0.252234, acc:  56%] [G loss: 1.323318] time: 5:05:24.744432\n",
      "[Epoch 8/10] [Batch 103/350] [D loss: 0.252664, acc:  49%] [G loss: 1.208945] time: 5:05:31.039568\n",
      "[Epoch 8/10] [Batch 104/350] [D loss: 0.251809, acc:  55%] [G loss: 1.183182] time: 5:05:37.361663\n",
      "[Epoch 8/10] [Batch 105/350] [D loss: 0.251620, acc:  40%] [G loss: 1.098792] time: 5:05:43.713679\n",
      "[Epoch 8/10] [Batch 106/350] [D loss: 0.251853, acc:  51%] [G loss: 1.293386] time: 5:05:50.005855\n",
      "[Epoch 8/10] [Batch 107/350] [D loss: 0.251342, acc:  53%] [G loss: 0.962820] time: 5:05:56.315016\n",
      "[Epoch 8/10] [Batch 108/350] [D loss: 0.251559, acc:  45%] [G loss: 1.080008] time: 5:06:02.606164\n",
      "[Epoch 8/10] [Batch 109/350] [D loss: 0.252593, acc:  52%] [G loss: 1.065508] time: 5:06:08.893382\n",
      "[Epoch 8/10] [Batch 110/350] [D loss: 0.252125, acc:  49%] [G loss: 1.203843] time: 5:06:15.174559\n",
      "[Epoch 8/10] [Batch 111/350] [D loss: 0.251634, acc:  46%] [G loss: 1.086425] time: 5:06:21.455764\n",
      "[Epoch 8/10] [Batch 112/350] [D loss: 0.252527, acc:  50%] [G loss: 1.280334] time: 5:06:27.740959\n",
      "[Epoch 8/10] [Batch 113/350] [D loss: 0.252382, acc:  50%] [G loss: 1.176683] time: 5:06:34.031140\n",
      "[Epoch 8/10] [Batch 114/350] [D loss: 0.251502, acc:  47%] [G loss: 1.189204] time: 5:06:40.330297\n",
      "[Epoch 8/10] [Batch 115/350] [D loss: 0.252079, acc:  47%] [G loss: 1.316963] time: 5:06:46.628457\n",
      "[Epoch 8/10] [Batch 116/350] [D loss: 0.252173, acc:  56%] [G loss: 1.174064] time: 5:06:52.921631\n",
      "[Epoch 8/10] [Batch 117/350] [D loss: 0.251763, acc:  53%] [G loss: 1.088502] time: 5:06:59.198847\n",
      "[Epoch 8/10] [Batch 118/350] [D loss: 0.252568, acc:  49%] [G loss: 1.187172] time: 5:07:05.486037\n",
      "[Epoch 8/10] [Batch 119/350] [D loss: 0.251536, acc:  43%] [G loss: 1.061253] time: 5:07:11.783198\n",
      "[Epoch 8/10] [Batch 120/350] [D loss: 0.251339, acc:  56%] [G loss: 1.135987] time: 5:07:18.157156\n",
      "[Epoch 8/10] [Batch 121/350] [D loss: 0.251459, acc:  50%] [G loss: 1.068360] time: 5:07:24.437395\n",
      "[Epoch 8/10] [Batch 122/350] [D loss: 0.251223, acc:  45%] [G loss: 1.097377] time: 5:07:30.724553\n",
      "[Epoch 8/10] [Batch 123/350] [D loss: 0.251531, acc:  49%] [G loss: 1.037400] time: 5:07:37.010745\n",
      "[Epoch 8/10] [Batch 124/350] [D loss: 0.252043, acc:  50%] [G loss: 1.085585] time: 5:07:43.329880\n",
      "[Epoch 8/10] [Batch 125/350] [D loss: 0.251660, acc:  48%] [G loss: 1.005191] time: 5:07:49.626014\n",
      "[Epoch 8/10] [Batch 126/350] [D loss: 0.251337, acc:  46%] [G loss: 1.158246] time: 5:07:55.919188\n",
      "[Epoch 8/10] [Batch 127/350] [D loss: 0.251770, acc:  52%] [G loss: 1.120518] time: 5:08:02.199396\n",
      "[Epoch 8/10] [Batch 128/350] [D loss: 0.251944, acc:  50%] [G loss: 1.031583] time: 5:08:08.496559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/10] [Batch 129/350] [D loss: 0.251401, acc:  48%] [G loss: 1.156682] time: 5:08:14.792756\n",
      "[Epoch 8/10] [Batch 130/350] [D loss: 0.251849, acc:  49%] [G loss: 1.188358] time: 5:08:21.093876\n",
      "[Epoch 8/10] [Batch 131/350] [D loss: 0.251609, acc:  50%] [G loss: 1.036464] time: 5:08:27.385054\n",
      "[Epoch 8/10] [Batch 132/350] [D loss: 0.251351, acc:  48%] [G loss: 0.996717] time: 5:08:33.672244\n",
      "[Epoch 8/10] [Batch 133/350] [D loss: 0.252164, acc:  48%] [G loss: 1.153920] time: 5:08:39.960431\n",
      "[Epoch 8/10] [Batch 134/350] [D loss: 0.251772, acc:  46%] [G loss: 1.110911] time: 5:08:46.229668\n",
      "[Epoch 8/10] [Batch 135/350] [D loss: 0.251076, acc:  45%] [G loss: 1.223159] time: 5:08:52.508913\n",
      "[Epoch 8/10] [Batch 136/350] [D loss: 0.250991, acc:  47%] [G loss: 1.041402] time: 5:08:58.795102\n",
      "[Epoch 8/10] [Batch 137/350] [D loss: 0.250892, acc:  48%] [G loss: 1.130933] time: 5:09:05.131161\n",
      "[Epoch 8/10] [Batch 138/350] [D loss: 0.251092, acc:  54%] [G loss: 1.218065] time: 5:09:11.415327\n",
      "[Epoch 8/10] [Batch 139/350] [D loss: 0.251411, acc:  53%] [G loss: 1.048016] time: 5:09:17.698526\n",
      "[Epoch 8/10] [Batch 140/350] [D loss: 0.251461, acc:  49%] [G loss: 1.135334] time: 5:09:23.992698\n",
      "[Epoch 8/10] [Batch 141/350] [D loss: 0.251274, acc:  44%] [G loss: 1.012615] time: 5:09:30.259940\n",
      "[Epoch 8/10] [Batch 142/350] [D loss: 0.251277, acc:  49%] [G loss: 1.056142] time: 5:09:36.571065\n",
      "[Epoch 8/10] [Batch 143/350] [D loss: 0.251124, acc:  48%] [G loss: 1.194710] time: 5:09:42.891199\n",
      "[Epoch 8/10] [Batch 144/350] [D loss: 0.251113, acc:  49%] [G loss: 1.164172] time: 5:09:49.170409\n",
      "[Epoch 8/10] [Batch 145/350] [D loss: 0.251274, acc:  47%] [G loss: 1.251081] time: 5:09:55.459593\n",
      "[Epoch 8/10] [Batch 146/350] [D loss: 0.251115, acc:  46%] [G loss: 1.236898] time: 5:10:01.757722\n",
      "[Epoch 8/10] [Batch 147/350] [D loss: 0.251130, acc:  47%] [G loss: 1.329312] time: 5:10:08.049925\n",
      "[Epoch 8/10] [Batch 148/350] [D loss: 0.251709, acc:  42%] [G loss: 1.275396] time: 5:10:14.356067\n",
      "[Epoch 8/10] [Batch 149/350] [D loss: 0.251635, acc:  49%] [G loss: 0.993435] time: 5:10:20.672148\n",
      "[Epoch 8/10] [Batch 150/350] [D loss: 0.251310, acc:  51%] [G loss: 1.226107] time: 5:10:26.995242\n",
      "[Epoch 8/10] [Batch 151/350] [D loss: 0.250961, acc:  46%] [G loss: 1.124253] time: 5:10:33.291407\n",
      "[Epoch 8/10] [Batch 152/350] [D loss: 0.250963, acc:  47%] [G loss: 1.251452] time: 5:10:39.574607\n",
      "[Epoch 8/10] [Batch 153/350] [D loss: 0.250855, acc:  48%] [G loss: 1.046448] time: 5:10:45.863823\n",
      "[Epoch 8/10] [Batch 154/350] [D loss: 0.251279, acc:  49%] [G loss: 1.157043] time: 5:10:52.168932\n",
      "[Epoch 8/10] [Batch 155/350] [D loss: 0.251372, acc:  46%] [G loss: 1.135812] time: 5:10:58.466128\n",
      "[Epoch 8/10] [Batch 156/350] [D loss: 0.251357, acc:  46%] [G loss: 1.133299] time: 5:11:04.749295\n",
      "[Epoch 8/10] [Batch 157/350] [D loss: 0.251307, acc:  48%] [G loss: 1.135730] time: 5:11:11.032495\n",
      "[Epoch 8/10] [Batch 158/350] [D loss: 0.251201, acc:  51%] [G loss: 1.121890] time: 5:11:17.310708\n",
      "[Epoch 8/10] [Batch 159/350] [D loss: 0.251074, acc:  44%] [G loss: 1.250871] time: 5:11:23.605908\n",
      "[Epoch 8/10] [Batch 160/350] [D loss: 0.251044, acc:  50%] [G loss: 1.058336] time: 5:11:29.891071\n",
      "[Epoch 8/10] [Batch 161/350] [D loss: 0.251225, acc:  48%] [G loss: 1.127892] time: 5:11:36.165295\n",
      "[Epoch 8/10] [Batch 162/350] [D loss: 0.251079, acc:  47%] [G loss: 1.040882] time: 5:11:42.494372\n",
      "[Epoch 8/10] [Batch 163/350] [D loss: 0.251392, acc:  43%] [G loss: 1.091242] time: 5:11:48.791535\n",
      "[Epoch 8/10] [Batch 164/350] [D loss: 0.251441, acc:  49%] [G loss: 1.041269] time: 5:11:55.063764\n",
      "[Epoch 8/10] [Batch 165/350] [D loss: 0.251158, acc:  41%] [G loss: 1.037946] time: 5:12:01.370900\n",
      "[Epoch 8/10] [Batch 166/350] [D loss: 0.251090, acc:  49%] [G loss: 1.078085] time: 5:12:07.655097\n",
      "[Epoch 8/10] [Batch 167/350] [D loss: 0.251070, acc:  49%] [G loss: 0.926083] time: 5:12:13.973204\n",
      "[Epoch 8/10] [Batch 168/350] [D loss: 0.251189, acc:  52%] [G loss: 1.062712] time: 5:12:20.278345\n",
      "[Epoch 8/10] [Batch 169/350] [D loss: 0.251742, acc:  57%] [G loss: 0.892595] time: 5:12:26.554564\n",
      "[Epoch 8/10] [Batch 170/350] [D loss: 0.252016, acc:  49%] [G loss: 1.155409] time: 5:12:32.846740\n",
      "[Epoch 8/10] [Batch 171/350] [D loss: 0.251570, acc:  49%] [G loss: 1.093033] time: 5:12:39.146895\n",
      "[Epoch 8/10] [Batch 172/350] [D loss: 0.251991, acc:  55%] [G loss: 1.083290] time: 5:12:45.437107\n",
      "[Epoch 8/10] [Batch 173/350] [D loss: 0.252779, acc:  49%] [G loss: 1.291042] time: 5:12:51.730281\n",
      "[Epoch 8/10] [Batch 174/350] [D loss: 0.251851, acc:  49%] [G loss: 1.080192] time: 5:12:58.023454\n",
      "[Epoch 8/10] [Batch 175/350] [D loss: 0.251972, acc:  48%] [G loss: 1.168367] time: 5:13:04.321618\n",
      "[Epoch 8/10] [Batch 176/350] [D loss: 0.252714, acc:  49%] [G loss: 1.066374] time: 5:13:16.194863\n",
      "[Epoch 8/10] [Batch 177/350] [D loss: 0.251908, acc:  49%] [G loss: 1.175922] time: 5:13:22.471081\n",
      "[Epoch 8/10] [Batch 178/350] [D loss: 0.251006, acc:  50%] [G loss: 1.138439] time: 5:13:28.771267\n",
      "[Epoch 8/10] [Batch 179/350] [D loss: 0.251083, acc:  48%] [G loss: 1.043857] time: 5:13:35.060420\n",
      "[Epoch 8/10] [Batch 180/350] [D loss: 0.251154, acc:  47%] [G loss: 0.996087] time: 5:13:41.370548\n",
      "[Epoch 8/10] [Batch 181/350] [D loss: 0.251210, acc:  50%] [G loss: 1.109529] time: 5:13:47.707603\n",
      "[Epoch 8/10] [Batch 182/350] [D loss: 0.251213, acc:  47%] [G loss: 0.986172] time: 5:13:53.994822\n",
      "[Epoch 8/10] [Batch 183/350] [D loss: 0.250922, acc:  49%] [G loss: 1.197694] time: 5:14:00.270046\n",
      "[Epoch 8/10] [Batch 184/350] [D loss: 0.251008, acc:  51%] [G loss: 1.196423] time: 5:14:06.553214\n",
      "[Epoch 8/10] [Batch 185/350] [D loss: 0.251230, acc:  49%] [G loss: 0.939514] time: 5:14:12.848412\n",
      "[Epoch 8/10] [Batch 186/350] [D loss: 0.251105, acc:  47%] [G loss: 1.122788] time: 5:14:19.124601\n",
      "[Epoch 8/10] [Batch 187/350] [D loss: 0.251013, acc:  46%] [G loss: 1.116407] time: 5:14:25.421764\n",
      "[Epoch 8/10] [Batch 188/350] [D loss: 0.251214, acc:  48%] [G loss: 0.917088] time: 5:14:31.703967\n",
      "[Epoch 8/10] [Batch 189/350] [D loss: 0.251233, acc:  56%] [G loss: 1.066573] time: 5:14:37.989161\n",
      "[Epoch 8/10] [Batch 190/350] [D loss: 0.251190, acc:  51%] [G loss: 1.271929] time: 5:14:44.240446\n",
      "[Epoch 8/10] [Batch 191/350] [D loss: 0.251494, acc:  45%] [G loss: 1.120202] time: 5:14:50.530628\n",
      "[Epoch 8/10] [Batch 192/350] [D loss: 0.251295, acc:  44%] [G loss: 1.084387] time: 5:14:56.819817\n",
      "[Epoch 8/10] [Batch 193/350] [D loss: 0.251568, acc:  50%] [G loss: 1.135298] time: 5:15:03.103012\n",
      "[Epoch 8/10] [Batch 194/350] [D loss: 0.251561, acc:  50%] [G loss: 1.263942] time: 5:15:09.378233\n",
      "[Epoch 8/10] [Batch 195/350] [D loss: 0.251824, acc:  45%] [G loss: 1.094275] time: 5:15:15.672403\n",
      "[Epoch 8/10] [Batch 196/350] [D loss: 0.252206, acc:  54%] [G loss: 1.135366] time: 5:15:21.938684\n",
      "[Epoch 8/10] [Batch 197/350] [D loss: 0.251895, acc:  52%] [G loss: 0.978100] time: 5:15:28.234847\n",
      "[Epoch 8/10] [Batch 198/350] [D loss: 0.251620, acc:  48%] [G loss: 1.049735] time: 5:15:34.529982\n",
      "[Epoch 8/10] [Batch 199/350] [D loss: 0.251958, acc:  45%] [G loss: 1.088960] time: 5:15:40.842105\n",
      "[Epoch 8/10] [Batch 200/350] [D loss: 0.251536, acc:  45%] [G loss: 1.124948] time: 5:15:47.144254\n",
      "[Epoch 8/10] [Batch 201/350] [D loss: 0.250975, acc:  49%] [G loss: 0.961603] time: 5:15:53.424497\n",
      "[Epoch 8/10] [Batch 202/350] [D loss: 0.251134, acc:  47%] [G loss: 1.082072] time: 5:15:59.682729\n",
      "[Epoch 8/10] [Batch 203/350] [D loss: 0.251089, acc:  44%] [G loss: 1.020639] time: 5:16:05.977928\n",
      "[Epoch 8/10] [Batch 204/350] [D loss: 0.251186, acc:  45%] [G loss: 1.032184] time: 5:16:12.247135\n",
      "[Epoch 8/10] [Batch 205/350] [D loss: 0.251227, acc:  52%] [G loss: 0.978079] time: 5:16:18.519395\n",
      "[Epoch 8/10] [Batch 206/350] [D loss: 0.251132, acc:  52%] [G loss: 1.021616] time: 5:16:24.800569\n",
      "[Epoch 8/10] [Batch 207/350] [D loss: 0.251118, acc:  51%] [G loss: 1.132549] time: 5:16:31.094739\n",
      "[Epoch 8/10] [Batch 208/350] [D loss: 0.251226, acc:  48%] [G loss: 1.032213] time: 5:16:37.382958\n",
      "[Epoch 8/10] [Batch 209/350] [D loss: 0.251791, acc:  47%] [G loss: 1.204528] time: 5:16:43.655155\n",
      "[Epoch 8/10] [Batch 210/350] [D loss: 0.251509, acc:  51%] [G loss: 1.117598] time: 5:16:49.916446\n",
      "[Epoch 8/10] [Batch 211/350] [D loss: 0.251294, acc:  47%] [G loss: 0.963800] time: 5:16:56.202638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/10] [Batch 212/350] [D loss: 0.251168, acc:  45%] [G loss: 0.893653] time: 5:17:02.489796\n",
      "[Epoch 8/10] [Batch 213/350] [D loss: 0.251403, acc:  48%] [G loss: 1.043377] time: 5:17:08.774024\n",
      "[Epoch 8/10] [Batch 214/350] [D loss: 0.251001, acc:  48%] [G loss: 1.014419] time: 5:17:15.123049\n",
      "[Epoch 8/10] [Batch 215/350] [D loss: 0.250969, acc:  49%] [G loss: 1.107258] time: 5:17:21.413199\n",
      "[Epoch 8/10] [Batch 216/350] [D loss: 0.250913, acc:  49%] [G loss: 0.973082] time: 5:17:27.761225\n",
      "[Epoch 8/10] [Batch 217/350] [D loss: 0.250970, acc:  49%] [G loss: 0.926494] time: 5:17:34.043427\n",
      "[Epoch 8/10] [Batch 218/350] [D loss: 0.251069, acc:  48%] [G loss: 1.039472] time: 5:17:40.346575\n",
      "[Epoch 8/10] [Batch 219/350] [D loss: 0.251909, acc:  39%] [G loss: 1.023055] time: 5:17:46.673657\n",
      "[Epoch 8/10] [Batch 220/350] [D loss: 0.252259, acc:  48%] [G loss: 1.227959] time: 5:17:52.986777\n",
      "[Epoch 8/10] [Batch 221/350] [D loss: 0.251782, acc:  46%] [G loss: 0.927614] time: 5:17:59.248036\n",
      "[Epoch 8/10] [Batch 222/350] [D loss: 0.251257, acc:  49%] [G loss: 0.976969] time: 5:18:05.528243\n",
      "[Epoch 8/10] [Batch 223/350] [D loss: 0.251454, acc:  52%] [G loss: 1.142893] time: 5:18:11.810446\n",
      "[Epoch 8/10] [Batch 224/350] [D loss: 0.251567, acc:  49%] [G loss: 1.090761] time: 5:18:18.093681\n",
      "[Epoch 8/10] [Batch 225/350] [D loss: 0.250977, acc:  51%] [G loss: 0.986880] time: 5:18:24.383859\n",
      "[Epoch 8/10] [Batch 226/350] [D loss: 0.250976, acc:  47%] [G loss: 1.102855] time: 5:18:30.677998\n",
      "[Epoch 8/10] [Batch 227/350] [D loss: 0.251313, acc:  47%] [G loss: 1.125369] time: 5:18:36.983139\n",
      "[Epoch 8/10] [Batch 228/350] [D loss: 0.251316, acc:  48%] [G loss: 1.163086] time: 5:18:43.245427\n",
      "[Epoch 8/10] [Batch 229/350] [D loss: 0.251034, acc:  48%] [G loss: 1.198871] time: 5:18:49.537605\n",
      "[Epoch 8/10] [Batch 230/350] [D loss: 0.251243, acc:  51%] [G loss: 1.249626] time: 5:18:55.810798\n",
      "[Epoch 8/10] [Batch 231/350] [D loss: 0.251314, acc:  45%] [G loss: 1.402843] time: 5:19:02.063113\n",
      "[Epoch 8/10] [Batch 232/350] [D loss: 0.251257, acc:  51%] [G loss: 1.119332] time: 5:19:08.332318\n",
      "[Epoch 8/10] [Batch 233/350] [D loss: 0.251258, acc:  47%] [G loss: 1.116893] time: 5:19:14.597566\n",
      "[Epoch 8/10] [Batch 234/350] [D loss: 0.251257, acc:  48%] [G loss: 1.207540] time: 5:19:20.889774\n",
      "[Epoch 8/10] [Batch 235/350] [D loss: 0.251045, acc:  48%] [G loss: 1.140439] time: 5:19:27.167956\n",
      "[Epoch 8/10] [Batch 236/350] [D loss: 0.251185, acc:  43%] [G loss: 1.068530] time: 5:19:33.467113\n",
      "[Epoch 8/10] [Batch 237/350] [D loss: 0.251177, acc:  48%] [G loss: 1.063950] time: 5:19:39.779236\n",
      "[Epoch 8/10] [Batch 238/350] [D loss: 0.251029, acc:  49%] [G loss: 1.058908] time: 5:19:46.070446\n",
      "[Epoch 8/10] [Batch 239/350] [D loss: 0.250860, acc:  46%] [G loss: 1.022956] time: 5:19:52.355609\n",
      "[Epoch 8/10] [Batch 240/350] [D loss: 0.251120, acc:  46%] [G loss: 1.107007] time: 5:19:58.647785\n",
      "[Epoch 8/10] [Batch 241/350] [D loss: 0.251177, acc:  47%] [G loss: 1.096994] time: 5:20:04.927027\n",
      "[Epoch 8/10] [Batch 242/350] [D loss: 0.251049, acc:  44%] [G loss: 1.129836] time: 5:20:11.183267\n",
      "[Epoch 8/10] [Batch 243/350] [D loss: 0.251552, acc:  41%] [G loss: 1.410802] time: 5:20:17.477470\n",
      "[Epoch 8/10] [Batch 244/350] [D loss: 0.251496, acc:  49%] [G loss: 1.114681] time: 5:20:23.764628\n",
      "[Epoch 8/10] [Batch 245/350] [D loss: 0.251089, acc:  51%] [G loss: 1.238113] time: 5:20:30.049822\n",
      "[Epoch 8/10] [Batch 246/350] [D loss: 0.251112, acc:  54%] [G loss: 1.180073] time: 5:20:36.333022\n",
      "[Epoch 8/10] [Batch 247/350] [D loss: 0.251319, acc:  48%] [G loss: 1.080658] time: 5:20:42.638164\n",
      "[Epoch 8/10] [Batch 248/350] [D loss: 0.251087, acc:  44%] [G loss: 1.299568] time: 5:20:48.901417\n",
      "[Epoch 8/10] [Batch 249/350] [D loss: 0.251073, acc:  51%] [G loss: 1.328232] time: 5:20:55.190601\n",
      "[Epoch 8/10] [Batch 250/350] [D loss: 0.251200, acc:  46%] [G loss: 1.165264] time: 5:21:01.469811\n",
      "[Epoch 8/10] [Batch 251/350] [D loss: 0.251055, acc:  50%] [G loss: 1.245039] time: 5:21:07.757001\n",
      "[Epoch 8/10] [Batch 252/350] [D loss: 0.251235, acc:  50%] [G loss: 1.044718] time: 5:21:14.053166\n",
      "[Epoch 8/10] [Batch 253/350] [D loss: 0.251132, acc:  50%] [G loss: 1.308420] time: 5:21:20.347338\n",
      "[Epoch 8/10] [Batch 254/350] [D loss: 0.251200, acc:  47%] [G loss: 1.138239] time: 5:21:26.634526\n",
      "[Epoch 8/10] [Batch 255/350] [D loss: 0.251095, acc:  49%] [G loss: 1.122597] time: 5:21:32.922713\n",
      "[Epoch 8/10] [Batch 256/350] [D loss: 0.251264, acc:  44%] [G loss: 1.035589] time: 5:21:39.222868\n",
      "[Epoch 8/10] [Batch 257/350] [D loss: 0.251099, acc:  46%] [G loss: 1.220628] time: 5:21:45.569897\n",
      "[Epoch 8/10] [Batch 258/350] [D loss: 0.250928, acc:  46%] [G loss: 1.238588] time: 5:21:51.837140\n",
      "[Epoch 8/10] [Batch 259/350] [D loss: 0.250838, acc:  46%] [G loss: 0.956492] time: 5:21:58.127321\n",
      "[Epoch 8/10] [Batch 260/350] [D loss: 0.250886, acc:  49%] [G loss: 1.110046] time: 5:22:04.415508\n",
      "[Epoch 8/10] [Batch 261/350] [D loss: 0.251068, acc:  48%] [G loss: 1.045850] time: 5:22:10.696746\n",
      "[Epoch 8/10] [Batch 262/350] [D loss: 0.250977, acc:  45%] [G loss: 1.338840] time: 5:22:17.018809\n",
      "[Epoch 8/10] [Batch 263/350] [D loss: 0.251067, acc:  48%] [G loss: 1.137030] time: 5:22:23.319993\n",
      "[Epoch 8/10] [Batch 264/350] [D loss: 0.251005, acc:  49%] [G loss: 1.115324] time: 5:22:29.598174\n",
      "[Epoch 8/10] [Batch 265/350] [D loss: 0.251387, acc:  48%] [G loss: 1.003770] time: 5:22:35.886361\n",
      "[Epoch 8/10] [Batch 266/350] [D loss: 0.251315, acc:  48%] [G loss: 1.026744] time: 5:22:42.174548\n",
      "[Epoch 8/10] [Batch 267/350] [D loss: 0.251263, acc:  49%] [G loss: 0.975332] time: 5:22:48.463731\n",
      "[Epoch 8/10] [Batch 268/350] [D loss: 0.251403, acc:  54%] [G loss: 1.107153] time: 5:22:54.723993\n",
      "[Epoch 8/10] [Batch 269/350] [D loss: 0.251606, acc:  47%] [G loss: 1.073684] time: 5:23:01.013177\n",
      "[Epoch 8/10] [Batch 270/350] [D loss: 0.251275, acc:  39%] [G loss: 1.142844] time: 5:23:07.282445\n",
      "[Epoch 8/10] [Batch 271/350] [D loss: 0.251308, acc:  51%] [G loss: 0.956226] time: 5:23:13.578580\n",
      "[Epoch 8/10] [Batch 272/350] [D loss: 0.251247, acc:  49%] [G loss: 1.070034] time: 5:23:19.869758\n",
      "[Epoch 8/10] [Batch 273/350] [D loss: 0.251089, acc:  52%] [G loss: 1.129249] time: 5:23:26.220809\n",
      "[Epoch 8/10] [Batch 274/350] [D loss: 0.250823, acc:  50%] [G loss: 1.208807] time: 5:23:32.499988\n",
      "[Epoch 8/10] [Batch 275/350] [D loss: 0.251247, acc:  48%] [G loss: 1.162876] time: 5:23:38.792195\n",
      "[Epoch 8/10] [Batch 276/350] [D loss: 0.251185, acc:  56%] [G loss: 1.056391] time: 5:23:45.114260\n",
      "[Epoch 8/10] [Batch 277/350] [D loss: 0.251278, acc:  49%] [G loss: 1.021592] time: 5:23:51.398457\n",
      "[Epoch 8/10] [Batch 278/350] [D loss: 0.251033, acc:  48%] [G loss: 1.103007] time: 5:23:57.689667\n",
      "[Epoch 8/10] [Batch 279/350] [D loss: 0.251063, acc:  46%] [G loss: 1.080302] time: 5:24:03.992782\n",
      "[Epoch 8/10] [Batch 280/350] [D loss: 0.251012, acc:  49%] [G loss: 1.045052] time: 5:24:10.269999\n",
      "[Epoch 8/10] [Batch 281/350] [D loss: 0.251021, acc:  49%] [G loss: 1.042726] time: 5:24:16.552232\n",
      "[Epoch 8/10] [Batch 282/350] [D loss: 0.251313, acc:  50%] [G loss: 1.035926] time: 5:24:22.838393\n",
      "[Epoch 8/10] [Batch 283/350] [D loss: 0.251444, acc:  46%] [G loss: 0.952301] time: 5:24:29.139546\n",
      "[Epoch 8/10] [Batch 284/350] [D loss: 0.251541, acc:  49%] [G loss: 1.019609] time: 5:24:35.444718\n",
      "[Epoch 8/10] [Batch 285/350] [D loss: 0.251089, acc:  45%] [G loss: 1.055491] time: 5:24:41.739888\n",
      "[Epoch 8/10] [Batch 286/350] [D loss: 0.251015, acc:  47%] [G loss: 1.069269] time: 5:24:48.000115\n",
      "[Epoch 8/10] [Batch 287/350] [D loss: 0.250890, acc:  46%] [G loss: 1.078842] time: 5:24:54.293321\n",
      "[Epoch 8/10] [Batch 288/350] [D loss: 0.251049, acc:  48%] [G loss: 1.131058] time: 5:25:00.590451\n",
      "[Epoch 8/10] [Batch 289/350] [D loss: 0.251126, acc:  55%] [G loss: 1.165940] time: 5:25:06.851739\n",
      "[Epoch 8/10] [Batch 290/350] [D loss: 0.251133, acc:  50%] [G loss: 0.931999] time: 5:25:13.144884\n",
      "[Epoch 8/10] [Batch 291/350] [D loss: 0.251324, acc:  45%] [G loss: 1.165721] time: 5:25:19.436062\n",
      "[Epoch 8/10] [Batch 292/350] [D loss: 0.251014, acc:  48%] [G loss: 1.053415] time: 5:25:25.747219\n",
      "[Epoch 8/10] [Batch 293/350] [D loss: 0.250969, acc:  47%] [G loss: 1.376042] time: 5:25:32.037403\n",
      "[Epoch 8/10] [Batch 294/350] [D loss: 0.251109, acc:  54%] [G loss: 1.215463] time: 5:25:38.308601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/10] [Batch 295/350] [D loss: 0.251224, acc:  49%] [G loss: 1.167923] time: 5:25:44.615737\n",
      "[Epoch 8/10] [Batch 296/350] [D loss: 0.251028, acc:  44%] [G loss: 1.177502] time: 5:25:50.907913\n",
      "[Epoch 8/10] [Batch 297/350] [D loss: 0.250914, acc:  48%] [G loss: 1.089497] time: 5:25:57.189150\n",
      "[Epoch 8/10] [Batch 298/350] [D loss: 0.250921, acc:  49%] [G loss: 1.136747] time: 5:26:03.471321\n",
      "[Epoch 8/10] [Batch 299/350] [D loss: 0.251004, acc:  48%] [G loss: 1.279209] time: 5:26:09.748568\n",
      "[Epoch 8/10] [Batch 300/350] [D loss: 0.251301, acc:  48%] [G loss: 1.296097] time: 5:26:16.023758\n",
      "[Epoch 8/10] [Batch 301/350] [D loss: 0.251288, acc:  48%] [G loss: 1.190605] time: 5:26:22.303966\n",
      "[Epoch 8/10] [Batch 302/350] [D loss: 0.251271, acc:  49%] [G loss: 1.000765] time: 5:26:28.592153\n",
      "[Epoch 8/10] [Batch 303/350] [D loss: 0.251128, acc:  52%] [G loss: 1.115547] time: 5:26:34.892308\n",
      "[Epoch 8/10] [Batch 304/350] [D loss: 0.251364, acc:  47%] [G loss: 0.947884] time: 5:26:41.178500\n",
      "[Epoch 8/10] [Batch 305/350] [D loss: 0.251354, acc:  50%] [G loss: 1.070113] time: 5:26:47.448734\n",
      "[Epoch 8/10] [Batch 306/350] [D loss: 0.250965, acc:  48%] [G loss: 1.073430] time: 5:26:53.731934\n",
      "[Epoch 8/10] [Batch 307/350] [D loss: 0.251024, acc:  45%] [G loss: 1.132982] time: 5:27:00.027102\n",
      "[Epoch 8/10] [Batch 308/350] [D loss: 0.251002, acc:  50%] [G loss: 1.055227] time: 5:27:06.309306\n",
      "[Epoch 8/10] [Batch 309/350] [D loss: 0.251015, acc:  50%] [G loss: 1.024454] time: 5:27:12.595498\n",
      "[Epoch 8/10] [Batch 310/350] [D loss: 0.251057, acc:  48%] [G loss: 1.045103] time: 5:27:18.936542\n",
      "[Epoch 8/10] [Batch 311/350] [D loss: 0.250936, acc:  45%] [G loss: 1.155830] time: 5:27:25.245707\n",
      "[Epoch 8/10] [Batch 312/350] [D loss: 0.251635, acc:  47%] [G loss: 1.001712] time: 5:27:31.514910\n",
      "[Epoch 8/10] [Batch 313/350] [D loss: 0.251699, acc:  50%] [G loss: 0.893794] time: 5:27:37.820052\n",
      "[Epoch 8/10] [Batch 314/350] [D loss: 0.252115, acc:  49%] [G loss: 1.138658] time: 5:27:44.143145\n",
      "[Epoch 8/10] [Batch 315/350] [D loss: 0.251605, acc:  49%] [G loss: 1.078035] time: 5:27:50.419363\n",
      "[Epoch 8/10] [Batch 316/350] [D loss: 0.251640, acc:  50%] [G loss: 1.093251] time: 5:27:56.701566\n",
      "[Epoch 8/10] [Batch 317/350] [D loss: 0.252427, acc:  51%] [G loss: 1.100620] time: 5:28:02.983769\n",
      "[Epoch 8/10] [Batch 318/350] [D loss: 0.252051, acc:  47%] [G loss: 1.089342] time: 5:28:09.253006\n",
      "[Epoch 8/10] [Batch 319/350] [D loss: 0.251110, acc:  51%] [G loss: 0.991337] time: 5:28:15.506286\n",
      "[Epoch 8/10] [Batch 320/350] [D loss: 0.251383, acc:  48%] [G loss: 1.119442] time: 5:28:21.790515\n",
      "[Epoch 8/10] [Batch 321/350] [D loss: 0.251658, acc:  48%] [G loss: 1.134183] time: 5:28:28.076676\n",
      "[Epoch 8/10] [Batch 322/350] [D loss: 0.251324, acc:  50%] [G loss: 1.292634] time: 5:28:34.382814\n",
      "[Epoch 8/10] [Batch 323/350] [D loss: 0.251222, acc:  49%] [G loss: 1.084547] time: 5:28:40.681971\n",
      "[Epoch 8/10] [Batch 324/350] [D loss: 0.251143, acc:  48%] [G loss: 1.029633] time: 5:28:46.973150\n",
      "[Epoch 8/10] [Batch 325/350] [D loss: 0.250969, acc:  44%] [G loss: 1.189516] time: 5:28:53.256350\n",
      "[Epoch 8/10] [Batch 326/350] [D loss: 0.251310, acc:  51%] [G loss: 1.070428] time: 5:28:59.501651\n",
      "[Epoch 8/10] [Batch 327/350] [D loss: 0.251229, acc:  44%] [G loss: 1.016631] time: 5:29:05.798845\n",
      "[Epoch 8/10] [Batch 328/350] [D loss: 0.251195, acc:  47%] [G loss: 1.028529] time: 5:29:12.083043\n",
      "[Epoch 8/10] [Batch 329/350] [D loss: 0.251017, acc:  48%] [G loss: 1.126920] time: 5:29:18.358233\n",
      "[Epoch 8/10] [Batch 330/350] [D loss: 0.251009, acc:  49%] [G loss: 1.166649] time: 5:29:24.624478\n",
      "[Epoch 8/10] [Batch 331/350] [D loss: 0.251068, acc:  49%] [G loss: 1.225873] time: 5:29:30.917652\n",
      "[Epoch 8/10] [Batch 332/350] [D loss: 0.251189, acc:  47%] [G loss: 1.173734] time: 5:29:37.203844\n",
      "[Epoch 8/10] [Batch 333/350] [D loss: 0.251235, acc:  46%] [G loss: 0.977519] time: 5:29:43.542894\n",
      "[Epoch 8/10] [Batch 334/350] [D loss: 0.251160, acc:  46%] [G loss: 1.015250] time: 5:29:49.811134\n",
      "[Epoch 8/10] [Batch 335/350] [D loss: 0.251302, acc:  43%] [G loss: 1.159822] time: 5:29:56.092339\n",
      "[Epoch 8/10] [Batch 336/350] [D loss: 0.251334, acc:  49%] [G loss: 1.170164] time: 5:30:02.387507\n",
      "[Epoch 8/10] [Batch 337/350] [D loss: 0.251053, acc:  50%] [G loss: 1.112511] time: 5:30:08.670708\n",
      "[Epoch 8/10] [Batch 338/350] [D loss: 0.250977, acc:  48%] [G loss: 1.239587] time: 5:30:14.960889\n",
      "[Epoch 8/10] [Batch 339/350] [D loss: 0.250826, acc:  46%] [G loss: 1.084113] time: 5:30:21.240131\n",
      "[Epoch 8/10] [Batch 340/350] [D loss: 0.251234, acc:  39%] [G loss: 0.957902] time: 5:30:27.537263\n",
      "[Epoch 8/10] [Batch 341/350] [D loss: 0.251371, acc:  48%] [G loss: 0.999173] time: 5:30:33.822457\n",
      "[Epoch 8/10] [Batch 342/350] [D loss: 0.251323, acc:  46%] [G loss: 1.276162] time: 5:30:40.098676\n",
      "[Epoch 8/10] [Batch 343/350] [D loss: 0.251316, acc:  49%] [G loss: 1.105595] time: 5:30:46.389854\n",
      "[Epoch 8/10] [Batch 344/350] [D loss: 0.251689, acc:  45%] [G loss: 1.177044] time: 5:30:52.670062\n",
      "[Epoch 8/10] [Batch 345/350] [D loss: 0.251594, acc:  51%] [G loss: 1.072738] time: 5:30:58.954260\n",
      "[Epoch 8/10] [Batch 346/350] [D loss: 0.251354, acc:  47%] [G loss: 1.051154] time: 5:31:05.238457\n",
      "[Epoch 8/10] [Batch 347/350] [D loss: 0.251495, acc:  55%] [G loss: 1.039726] time: 5:31:11.500713\n",
      "[Epoch 8/10] [Batch 348/350] [D loss: 0.251570, acc:  49%] [G loss: 0.968108] time: 5:31:17.771945\n",
      "weights saved...\n",
      "[Epoch 9/10] [Batch 0/350] [D loss: 0.251108, acc:  49%] [G loss: 0.994993] time: 5:31:24.380276\n",
      "[Epoch 9/10] [Batch 1/350] [D loss: 0.250910, acc:  49%] [G loss: 0.984345] time: 5:31:36.308018\n",
      "[Epoch 9/10] [Batch 2/350] [D loss: 0.251115, acc:  48%] [G loss: 1.091365] time: 5:31:42.640056\n",
      "[Epoch 9/10] [Batch 3/350] [D loss: 0.251349, acc:  51%] [G loss: 1.180856] time: 5:31:48.908296\n",
      "[Epoch 9/10] [Batch 4/350] [D loss: 0.251332, acc:  50%] [G loss: 1.180733] time: 5:31:55.197480\n",
      "[Epoch 9/10] [Batch 5/350] [D loss: 0.251064, acc:  52%] [G loss: 1.210230] time: 5:32:01.474697\n",
      "[Epoch 9/10] [Batch 6/350] [D loss: 0.251323, acc:  40%] [G loss: 1.162352] time: 5:32:07.783827\n",
      "[Epoch 9/10] [Batch 7/350] [D loss: 0.251134, acc:  44%] [G loss: 1.123912] time: 5:32:14.071017\n",
      "[Epoch 9/10] [Batch 8/350] [D loss: 0.251299, acc:  45%] [G loss: 0.969361] time: 5:32:20.383139\n",
      "[Epoch 9/10] [Batch 9/350] [D loss: 0.251469, acc:  51%] [G loss: 1.053616] time: 5:32:26.668365\n",
      "[Epoch 9/10] [Batch 10/350] [D loss: 0.251314, acc:  44%] [G loss: 1.143924] time: 5:32:32.940595\n",
      "[Epoch 9/10] [Batch 11/350] [D loss: 0.251620, acc:  49%] [G loss: 1.199884] time: 5:32:39.230745\n",
      "[Epoch 9/10] [Batch 12/350] [D loss: 0.251962, acc:  51%] [G loss: 1.015065] time: 5:32:45.517934\n",
      "[Epoch 9/10] [Batch 13/350] [D loss: 0.251767, acc:  48%] [G loss: 0.977826] time: 5:32:51.791161\n",
      "[Epoch 9/10] [Batch 14/350] [D loss: 0.250991, acc:  48%] [G loss: 0.996559] time: 5:32:58.066381\n",
      "[Epoch 9/10] [Batch 15/350] [D loss: 0.251007, acc:  50%] [G loss: 0.955513] time: 5:33:04.351578\n",
      "[Epoch 9/10] [Batch 16/350] [D loss: 0.251026, acc:  45%] [G loss: 0.944110] time: 5:33:10.617822\n",
      "[Epoch 9/10] [Batch 17/350] [D loss: 0.251035, acc:  50%] [G loss: 1.270408] time: 5:33:16.870105\n",
      "[Epoch 9/10] [Batch 18/350] [D loss: 0.251063, acc:  48%] [G loss: 1.093824] time: 5:33:23.151310\n",
      "[Epoch 9/10] [Batch 19/350] [D loss: 0.251068, acc:  44%] [G loss: 1.070111] time: 5:33:29.436536\n",
      "[Epoch 9/10] [Batch 20/350] [D loss: 0.251079, acc:  44%] [G loss: 1.252559] time: 5:33:35.749656\n",
      "[Epoch 9/10] [Batch 21/350] [D loss: 0.251209, acc:  49%] [G loss: 1.112616] time: 5:33:42.061747\n",
      "[Epoch 9/10] [Batch 22/350] [D loss: 0.251116, acc:  48%] [G loss: 0.991615] time: 5:33:48.341955\n",
      "[Epoch 9/10] [Batch 23/350] [D loss: 0.250780, acc:  47%] [G loss: 1.154224] time: 5:33:54.622163\n",
      "[Epoch 9/10] [Batch 24/350] [D loss: 0.251033, acc:  47%] [G loss: 1.002991] time: 5:34:00.883422\n",
      "[Epoch 9/10] [Batch 25/350] [D loss: 0.250983, acc:  45%] [G loss: 1.017590] time: 5:34:07.177592\n",
      "[Epoch 9/10] [Batch 26/350] [D loss: 0.250952, acc:  48%] [G loss: 1.064645] time: 5:34:13.453811\n",
      "[Epoch 9/10] [Batch 27/350] [D loss: 0.251044, acc:  46%] [G loss: 1.105737] time: 5:34:19.734019\n",
      "[Epoch 9/10] [Batch 28/350] [D loss: 0.251159, acc:  41%] [G loss: 0.978730] time: 5:34:26.036169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] [Batch 29/350] [D loss: 0.251035, acc:  46%] [G loss: 1.006233] time: 5:34:32.318371\n",
      "[Epoch 9/10] [Batch 30/350] [D loss: 0.250894, acc:  49%] [G loss: 0.989943] time: 5:34:38.611545\n",
      "[Epoch 9/10] [Batch 31/350] [D loss: 0.250897, acc:  48%] [G loss: 1.002411] time: 5:34:44.891752\n",
      "[Epoch 9/10] [Batch 32/350] [D loss: 0.250935, acc:  46%] [G loss: 0.958913] time: 5:34:51.190911\n",
      "[Epoch 9/10] [Batch 33/350] [D loss: 0.250975, acc:  47%] [G loss: 1.003714] time: 5:34:57.464137\n",
      "[Epoch 9/10] [Batch 34/350] [D loss: 0.251164, acc:  51%] [G loss: 0.972044] time: 5:35:03.746339\n",
      "[Epoch 9/10] [Batch 35/350] [D loss: 0.251101, acc:  52%] [G loss: 0.918235] time: 5:35:10.023556\n",
      "[Epoch 9/10] [Batch 36/350] [D loss: 0.251012, acc:  51%] [G loss: 0.964939] time: 5:35:16.301768\n",
      "[Epoch 9/10] [Batch 37/350] [D loss: 0.250968, acc:  48%] [G loss: 1.136601] time: 5:35:22.573998\n",
      "[Epoch 9/10] [Batch 38/350] [D loss: 0.251226, acc:  49%] [G loss: 1.091022] time: 5:35:28.867172\n",
      "[Epoch 9/10] [Batch 39/350] [D loss: 0.250976, acc:  49%] [G loss: 0.997279] time: 5:35:35.138404\n",
      "[Epoch 9/10] [Batch 40/350] [D loss: 0.251095, acc:  47%] [G loss: 1.184634] time: 5:35:41.484436\n",
      "[Epoch 9/10] [Batch 41/350] [D loss: 0.251284, acc:  46%] [G loss: 1.267155] time: 5:35:47.764677\n",
      "[Epoch 9/10] [Batch 42/350] [D loss: 0.251101, acc:  49%] [G loss: 1.184847] time: 5:35:54.030889\n",
      "[Epoch 9/10] [Batch 43/350] [D loss: 0.251184, acc:  48%] [G loss: 1.293074] time: 5:36:00.302121\n",
      "[Epoch 9/10] [Batch 44/350] [D loss: 0.251064, acc:  45%] [G loss: 1.230737] time: 5:36:06.589310\n",
      "[Epoch 9/10] [Batch 45/350] [D loss: 0.251166, acc:  48%] [G loss: 1.179048] time: 5:36:12.869518\n",
      "[Epoch 9/10] [Batch 46/350] [D loss: 0.250901, acc:  49%] [G loss: 1.066759] time: 5:36:19.144739\n",
      "[Epoch 9/10] [Batch 47/350] [D loss: 0.250884, acc:  48%] [G loss: 1.157916] time: 5:36:25.421955\n",
      "[Epoch 9/10] [Batch 48/350] [D loss: 0.251040, acc:  47%] [G loss: 1.239048] time: 5:36:31.710142\n",
      "[Epoch 9/10] [Batch 49/350] [D loss: 0.251001, acc:  49%] [G loss: 1.008346] time: 5:36:38.025256\n",
      "[Epoch 9/10] [Batch 50/350] [D loss: 0.250957, acc:  48%] [G loss: 1.030143] time: 5:36:44.298515\n",
      "[Epoch 9/10] [Batch 51/350] [D loss: 0.251274, acc:  47%] [G loss: 1.043017] time: 5:36:50.574702\n",
      "[Epoch 9/10] [Batch 52/350] [D loss: 0.251241, acc:  50%] [G loss: 0.982448] time: 5:36:56.853912\n",
      "[Epoch 9/10] [Batch 53/350] [D loss: 0.251322, acc:  49%] [G loss: 0.987872] time: 5:37:03.170056\n",
      "[Epoch 9/10] [Batch 54/350] [D loss: 0.251180, acc:  50%] [G loss: 1.124139] time: 5:37:09.444248\n",
      "[Epoch 9/10] [Batch 55/350] [D loss: 0.251122, acc:  51%] [G loss: 1.056695] time: 5:37:15.784296\n",
      "[Epoch 9/10] [Batch 56/350] [D loss: 0.250888, acc:  48%] [G loss: 1.222922] time: 5:37:22.060549\n",
      "[Epoch 9/10] [Batch 57/350] [D loss: 0.251143, acc:  55%] [G loss: 1.126280] time: 5:37:28.320808\n",
      "[Epoch 9/10] [Batch 58/350] [D loss: 0.251243, acc:  51%] [G loss: 1.171290] time: 5:37:34.628946\n",
      "[Epoch 9/10] [Batch 59/350] [D loss: 0.251173, acc:  52%] [G loss: 1.118923] time: 5:37:40.935048\n",
      "[Epoch 9/10] [Batch 60/350] [D loss: 0.251379, acc:  52%] [G loss: 1.174312] time: 5:37:47.236200\n",
      "[Epoch 9/10] [Batch 61/350] [D loss: 0.251315, acc:  47%] [G loss: 1.353991] time: 5:37:53.523421\n",
      "[Epoch 9/10] [Batch 62/350] [D loss: 0.251020, acc:  41%] [G loss: 1.212568] time: 5:37:59.790632\n",
      "[Epoch 9/10] [Batch 63/350] [D loss: 0.251049, acc:  50%] [G loss: 1.203901] time: 5:38:06.060867\n",
      "[Epoch 9/10] [Batch 64/350] [D loss: 0.251045, acc:  48%] [G loss: 1.305956] time: 5:38:12.326116\n",
      "[Epoch 9/10] [Batch 65/350] [D loss: 0.251333, acc:  45%] [G loss: 1.082581] time: 5:38:18.630260\n",
      "[Epoch 9/10] [Batch 66/350] [D loss: 0.251125, acc:  48%] [G loss: 1.102650] time: 5:38:24.931411\n",
      "[Epoch 9/10] [Batch 67/350] [D loss: 0.251187, acc:  49%] [G loss: 1.151545] time: 5:38:31.214611\n",
      "[Epoch 9/10] [Batch 68/350] [D loss: 0.251545, acc:  48%] [G loss: 1.082627] time: 5:38:37.515795\n",
      "[Epoch 9/10] [Batch 69/350] [D loss: 0.251699, acc:  47%] [G loss: 1.207056] time: 5:38:43.811959\n",
      "[Epoch 9/10] [Batch 70/350] [D loss: 0.251783, acc:  47%] [G loss: 1.166227] time: 5:38:50.083161\n",
      "[Epoch 9/10] [Batch 71/350] [D loss: 0.251449, acc:  48%] [G loss: 1.135551] time: 5:38:56.370350\n",
      "[Epoch 9/10] [Batch 72/350] [D loss: 0.251611, acc:  51%] [G loss: 1.135143] time: 5:39:02.707406\n",
      "[Epoch 9/10] [Batch 73/350] [D loss: 0.251545, acc:  51%] [G loss: 1.057776] time: 5:39:08.992600\n",
      "[Epoch 9/10] [Batch 74/350] [D loss: 0.251698, acc:  49%] [G loss: 1.225287] time: 5:39:15.268849\n",
      "[Epoch 9/10] [Batch 75/350] [D loss: 0.252209, acc:  48%] [G loss: 1.167827] time: 5:39:21.532072\n",
      "[Epoch 9/10] [Batch 76/350] [D loss: 0.252077, acc:  48%] [G loss: 1.348125] time: 5:39:27.821256\n",
      "[Epoch 9/10] [Batch 77/350] [D loss: 0.251351, acc:  53%] [G loss: 1.091466] time: 5:39:34.145347\n",
      "[Epoch 9/10] [Batch 78/350] [D loss: 0.251738, acc:  52%] [G loss: 1.099747] time: 5:39:40.423561\n",
      "[Epoch 9/10] [Batch 79/350] [D loss: 0.251494, acc:  47%] [G loss: 1.282773] time: 5:39:46.752638\n",
      "[Epoch 9/10] [Batch 80/350] [D loss: 0.251561, acc:  49%] [G loss: 1.152948] time: 5:39:53.038862\n",
      "[Epoch 9/10] [Batch 81/350] [D loss: 0.252242, acc:  52%] [G loss: 1.189878] time: 5:39:59.325022\n",
      "[Epoch 9/10] [Batch 82/350] [D loss: 0.252228, acc:  51%] [G loss: 0.998643] time: 5:40:05.616201\n",
      "[Epoch 9/10] [Batch 83/350] [D loss: 0.251927, acc:  50%] [G loss: 1.162951] time: 5:40:11.903390\n",
      "[Epoch 9/10] [Batch 84/350] [D loss: 0.252161, acc:  45%] [G loss: 1.260942] time: 5:40:18.182632\n",
      "[Epoch 9/10] [Batch 85/350] [D loss: 0.251750, acc:  47%] [G loss: 1.150573] time: 5:40:24.475806\n",
      "[Epoch 9/10] [Batch 86/350] [D loss: 0.251471, acc:  51%] [G loss: 1.054159] time: 5:40:30.746008\n",
      "[Epoch 9/10] [Batch 87/350] [D loss: 0.251965, acc:  52%] [G loss: 1.239752] time: 5:40:37.028242\n",
      "[Epoch 9/10] [Batch 88/350] [D loss: 0.251816, acc:  49%] [G loss: 1.008029] time: 5:40:43.328366\n",
      "[Epoch 9/10] [Batch 89/350] [D loss: 0.251116, acc:  52%] [G loss: 1.089469] time: 5:40:49.616584\n",
      "[Epoch 9/10] [Batch 90/350] [D loss: 0.251071, acc:  50%] [G loss: 1.031670] time: 5:40:55.893768\n",
      "[Epoch 9/10] [Batch 91/350] [D loss: 0.250973, acc:  49%] [G loss: 0.965074] time: 5:41:02.172979\n",
      "[Epoch 9/10] [Batch 92/350] [D loss: 0.251173, acc:  47%] [G loss: 0.998832] time: 5:41:08.463193\n",
      "[Epoch 9/10] [Batch 93/350] [D loss: 0.250970, acc:  50%] [G loss: 1.023967] time: 5:41:14.745363\n",
      "[Epoch 9/10] [Batch 94/350] [D loss: 0.250971, acc:  49%] [G loss: 1.097411] time: 5:41:21.027566\n",
      "[Epoch 9/10] [Batch 95/350] [D loss: 0.250984, acc:  47%] [G loss: 1.091136] time: 5:41:27.326723\n",
      "[Epoch 9/10] [Batch 96/350] [D loss: 0.250982, acc:  50%] [G loss: 0.917773] time: 5:41:33.605935\n",
      "[Epoch 9/10] [Batch 97/350] [D loss: 0.251114, acc:  49%] [G loss: 1.092828] time: 5:41:39.895118\n",
      "[Epoch 9/10] [Batch 98/350] [D loss: 0.251074, acc:  49%] [G loss: 0.920065] time: 5:41:46.181310\n",
      "[Epoch 9/10] [Batch 99/350] [D loss: 0.250968, acc:  45%] [G loss: 1.063878] time: 5:41:52.480467\n",
      "[Epoch 9/10] [Batch 100/350] [D loss: 0.251007, acc:  51%] [G loss: 1.218321] time: 5:41:58.739732\n",
      "[Epoch 9/10] [Batch 101/350] [D loss: 0.251267, acc:  49%] [G loss: 1.015467] time: 5:42:05.042910\n",
      "[Epoch 9/10] [Batch 102/350] [D loss: 0.252223, acc:  56%] [G loss: 1.331785] time: 5:42:11.299150\n",
      "[Epoch 9/10] [Batch 103/350] [D loss: 0.252657, acc:  50%] [G loss: 1.192485] time: 5:42:17.668121\n",
      "[Epoch 9/10] [Batch 104/350] [D loss: 0.251803, acc:  55%] [G loss: 1.156754] time: 5:42:23.972264\n",
      "[Epoch 9/10] [Batch 105/350] [D loss: 0.251615, acc:  40%] [G loss: 1.065214] time: 5:42:30.278439\n",
      "[Epoch 9/10] [Batch 106/350] [D loss: 0.251849, acc:  51%] [G loss: 1.212148] time: 5:42:36.565593\n",
      "[Epoch 9/10] [Batch 107/350] [D loss: 0.251320, acc:  53%] [G loss: 0.955857] time: 5:42:42.877747\n",
      "[Epoch 9/10] [Batch 108/350] [D loss: 0.251551, acc:  45%] [G loss: 1.049392] time: 5:42:49.168895\n",
      "[Epoch 9/10] [Batch 109/350] [D loss: 0.252568, acc:  52%] [G loss: 1.035044] time: 5:42:55.443118\n",
      "[Epoch 9/10] [Batch 110/350] [D loss: 0.252107, acc:  49%] [G loss: 1.153781] time: 5:43:01.720333\n",
      "[Epoch 9/10] [Batch 111/350] [D loss: 0.251610, acc:  46%] [G loss: 1.047167] time: 5:43:07.990569\n",
      "[Epoch 9/10] [Batch 112/350] [D loss: 0.252485, acc:  50%] [G loss: 1.207892] time: 5:43:14.276760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] [Batch 113/350] [D loss: 0.252368, acc:  50%] [G loss: 1.112292] time: 5:43:20.566942\n",
      "[Epoch 9/10] [Batch 114/350] [D loss: 0.251485, acc:  47%] [G loss: 1.102094] time: 5:43:26.870120\n",
      "[Epoch 9/10] [Batch 115/350] [D loss: 0.252055, acc:  48%] [G loss: 1.256508] time: 5:43:33.169246\n",
      "[Epoch 9/10] [Batch 116/350] [D loss: 0.252145, acc:  57%] [G loss: 1.069794] time: 5:43:39.474388\n",
      "[Epoch 9/10] [Batch 117/350] [D loss: 0.251763, acc:  53%] [G loss: 1.092171] time: 5:43:45.772547\n",
      "[Epoch 9/10] [Batch 118/350] [D loss: 0.252555, acc:  49%] [G loss: 1.203545] time: 5:43:52.049794\n",
      "[Epoch 9/10] [Batch 119/350] [D loss: 0.251501, acc:  44%] [G loss: 1.043971] time: 5:43:58.330004\n",
      "[Epoch 9/10] [Batch 120/350] [D loss: 0.251326, acc:  56%] [G loss: 1.088828] time: 5:44:04.618158\n",
      "[Epoch 9/10] [Batch 121/350] [D loss: 0.251451, acc:  50%] [G loss: 1.046381] time: 5:44:10.877422\n",
      "[Epoch 9/10] [Batch 122/350] [D loss: 0.251190, acc:  45%] [G loss: 1.021435] time: 5:44:17.156664\n",
      "[Epoch 9/10] [Batch 123/350] [D loss: 0.251512, acc:  48%] [G loss: 1.120541] time: 5:44:23.445816\n",
      "[Epoch 9/10] [Batch 124/350] [D loss: 0.252021, acc:  50%] [G loss: 1.061312] time: 5:44:29.790851\n",
      "[Epoch 9/10] [Batch 125/350] [D loss: 0.251620, acc:  48%] [G loss: 0.972196] time: 5:44:36.085054\n",
      "[Epoch 9/10] [Batch 126/350] [D loss: 0.251299, acc:  46%] [G loss: 1.137995] time: 5:44:42.368253\n",
      "[Epoch 9/10] [Batch 127/350] [D loss: 0.251737, acc:  52%] [G loss: 1.090061] time: 5:44:48.649428\n",
      "[Epoch 9/10] [Batch 128/350] [D loss: 0.251915, acc:  50%] [G loss: 0.982256] time: 5:44:54.938642\n",
      "[Epoch 9/10] [Batch 129/350] [D loss: 0.251359, acc:  48%] [G loss: 1.155600] time: 5:45:01.236771\n",
      "[Epoch 9/10] [Batch 130/350] [D loss: 0.251823, acc:  49%] [G loss: 1.172651] time: 5:45:07.521997\n",
      "[Epoch 9/10] [Batch 131/350] [D loss: 0.251573, acc:  50%] [G loss: 1.004224] time: 5:45:13.805166\n",
      "[Epoch 9/10] [Batch 132/350] [D loss: 0.251342, acc:  48%] [G loss: 0.956135] time: 5:45:20.091358\n",
      "[Epoch 9/10] [Batch 133/350] [D loss: 0.252142, acc:  48%] [G loss: 1.099265] time: 5:45:26.393507\n",
      "[Epoch 9/10] [Batch 134/350] [D loss: 0.251730, acc:  46%] [G loss: 1.063371] time: 5:45:32.682723\n",
      "[Epoch 9/10] [Batch 135/350] [D loss: 0.251045, acc:  46%] [G loss: 1.200640] time: 5:45:38.955918\n",
      "[Epoch 9/10] [Batch 136/350] [D loss: 0.250971, acc:  48%] [G loss: 0.990753] time: 5:45:45.294969\n",
      "[Epoch 9/10] [Batch 137/350] [D loss: 0.250872, acc:  48%] [G loss: 1.125411] time: 5:45:51.601107\n",
      "[Epoch 9/10] [Batch 138/350] [D loss: 0.251060, acc:  54%] [G loss: 1.207256] time: 5:45:57.872368\n",
      "[Epoch 9/10] [Batch 139/350] [D loss: 0.251346, acc:  53%] [G loss: 1.058928] time: 5:46:04.168536\n",
      "[Epoch 9/10] [Batch 140/350] [D loss: 0.251438, acc:  49%] [G loss: 1.116604] time: 5:46:10.445720\n",
      "[Epoch 9/10] [Batch 141/350] [D loss: 0.251255, acc:  45%] [G loss: 1.001001] time: 5:46:16.701993\n",
      "[Epoch 9/10] [Batch 142/350] [D loss: 0.251201, acc:  49%] [G loss: 1.038662] time: 5:46:22.999155\n",
      "[Epoch 9/10] [Batch 143/350] [D loss: 0.251091, acc:  48%] [G loss: 1.120007] time: 5:46:29.267396\n",
      "[Epoch 9/10] [Batch 144/350] [D loss: 0.251092, acc:  49%] [G loss: 1.114345] time: 5:46:35.555582\n",
      "[Epoch 9/10] [Batch 145/350] [D loss: 0.251229, acc:  47%] [G loss: 1.201541] time: 5:46:41.840776\n",
      "[Epoch 9/10] [Batch 146/350] [D loss: 0.251063, acc:  46%] [G loss: 1.116798] time: 5:46:48.145919\n",
      "[Epoch 9/10] [Batch 147/350] [D loss: 0.251103, acc:  47%] [G loss: 1.142862] time: 5:46:54.418147\n",
      "[Epoch 9/10] [Batch 148/350] [D loss: 0.251688, acc:  42%] [G loss: 1.189078] time: 5:47:00.713316\n",
      "[Epoch 9/10] [Batch 149/350] [D loss: 0.251595, acc:  49%] [G loss: 0.982498] time: 5:47:07.030424\n",
      "[Epoch 9/10] [Batch 150/350] [D loss: 0.251271, acc:  50%] [G loss: 1.175748] time: 5:47:13.339555\n",
      "[Epoch 9/10] [Batch 151/350] [D loss: 0.250939, acc:  46%] [G loss: 1.097167] time: 5:47:19.635721\n",
      "[Epoch 9/10] [Batch 152/350] [D loss: 0.250947, acc:  47%] [G loss: 1.166562] time: 5:47:25.927896\n",
      "[Epoch 9/10] [Batch 153/350] [D loss: 0.250829, acc:  48%] [G loss: 1.038611] time: 5:47:32.230046\n",
      "[Epoch 9/10] [Batch 154/350] [D loss: 0.251258, acc:  49%] [G loss: 1.126566] time: 5:47:38.535218\n",
      "[Epoch 9/10] [Batch 155/350] [D loss: 0.251342, acc:  46%] [G loss: 1.071893] time: 5:47:44.886237\n",
      "[Epoch 9/10] [Batch 156/350] [D loss: 0.251333, acc:  46%] [G loss: 1.055616] time: 5:47:51.172398\n",
      "[Epoch 9/10] [Batch 157/350] [D loss: 0.251281, acc:  48%] [G loss: 1.081929] time: 5:47:57.452606\n",
      "[Epoch 9/10] [Batch 158/350] [D loss: 0.251169, acc:  51%] [G loss: 1.086603] time: 5:48:03.736834\n",
      "[Epoch 9/10] [Batch 159/350] [D loss: 0.251047, acc:  44%] [G loss: 1.180403] time: 5:48:10.024990\n",
      "[Epoch 9/10] [Batch 160/350] [D loss: 0.251011, acc:  50%] [G loss: 1.016078] time: 5:48:16.306227\n",
      "[Epoch 9/10] [Batch 161/350] [D loss: 0.251186, acc:  48%] [G loss: 1.064499] time: 5:48:22.582414\n",
      "[Epoch 9/10] [Batch 162/350] [D loss: 0.251039, acc:  47%] [G loss: 0.992283] time: 5:48:28.868638\n",
      "[Epoch 9/10] [Batch 163/350] [D loss: 0.251353, acc:  43%] [G loss: 1.043930] time: 5:48:35.172749\n",
      "[Epoch 9/10] [Batch 164/350] [D loss: 0.251403, acc:  49%] [G loss: 1.001419] time: 5:48:41.447005\n",
      "[Epoch 9/10] [Batch 165/350] [D loss: 0.251125, acc:  41%] [G loss: 0.996145] time: 5:48:47.716211\n",
      "[Epoch 9/10] [Batch 166/350] [D loss: 0.251055, acc:  49%] [G loss: 1.040899] time: 5:48:53.994458\n",
      "[Epoch 9/10] [Batch 167/350] [D loss: 0.251040, acc:  49%] [G loss: 0.892423] time: 5:49:00.282611\n",
      "[Epoch 9/10] [Batch 168/350] [D loss: 0.251145, acc:  52%] [G loss: 1.023473] time: 5:49:06.584760\n",
      "[Epoch 9/10] [Batch 169/350] [D loss: 0.251700, acc:  57%] [G loss: 0.872158] time: 5:49:12.840035\n",
      "[Epoch 9/10] [Batch 170/350] [D loss: 0.251962, acc:  49%] [G loss: 1.102172] time: 5:49:19.112265\n",
      "[Epoch 9/10] [Batch 171/350] [D loss: 0.251520, acc:  49%] [G loss: 1.086338] time: 5:49:25.417406\n",
      "[Epoch 9/10] [Batch 172/350] [D loss: 0.251942, acc:  55%] [G loss: 1.027639] time: 5:49:31.922014\n",
      "[Epoch 9/10] [Batch 173/350] [D loss: 0.252696, acc:  49%] [G loss: 1.298488] time: 5:49:38.258072\n",
      "[Epoch 9/10] [Batch 174/350] [D loss: 0.251780, acc:  49%] [G loss: 1.049800] time: 5:49:44.631033\n",
      "[Epoch 9/10] [Batch 175/350] [D loss: 0.251916, acc:  48%] [G loss: 1.085154] time: 5:49:51.113699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] [Batch 176/350] [D loss: 0.252617, acc:  49%] [G loss: 1.121531] time: 5:50:04.370852\n",
      "[Epoch 9/10] [Batch 177/350] [D loss: 0.251848, acc:  49%] [G loss: 1.190772] time: 5:50:10.935583\n",
      "[Epoch 9/10] [Batch 178/350] [D loss: 0.250973, acc:  50%] [G loss: 1.252012] time: 5:50:17.546632\n",
      "[Epoch 9/10] [Batch 179/350] [D loss: 0.251055, acc:  48%] [G loss: 1.062395] time: 5:50:24.041267\n",
      "[Epoch 9/10] [Batch 180/350] [D loss: 0.251107, acc:  47%] [G loss: 1.045665] time: 5:50:30.354387\n",
      "[Epoch 9/10] [Batch 181/350] [D loss: 0.251194, acc:  50%] [G loss: 1.120226] time: 5:50:36.955737\n",
      "[Epoch 9/10] [Batch 182/350] [D loss: 0.251190, acc:  47%] [G loss: 1.012562] time: 5:50:43.404525\n",
      "[Epoch 9/10] [Batch 183/350] [D loss: 0.250893, acc:  49%] [G loss: 1.190439] time: 5:50:49.729581\n",
      "[Epoch 9/10] [Batch 184/350] [D loss: 0.250975, acc:  51%] [G loss: 1.186181] time: 5:50:56.039710\n",
      "[Epoch 9/10] [Batch 185/350] [D loss: 0.251204, acc:  49%] [G loss: 0.932293] time: 5:51:02.354855\n",
      "[Epoch 9/10] [Batch 186/350] [D loss: 0.251085, acc:  47%] [G loss: 1.098706] time: 5:51:08.654979\n",
      "[Epoch 9/10] [Batch 187/350] [D loss: 0.250989, acc:  46%] [G loss: 1.077728] time: 5:51:14.982061\n",
      "[Epoch 9/10] [Batch 188/350] [D loss: 0.251181, acc:  48%] [G loss: 0.899172] time: 5:51:21.287204\n",
      "[Epoch 9/10] [Batch 189/350] [D loss: 0.251197, acc:  57%] [G loss: 1.033865] time: 5:51:27.619273\n",
      "[Epoch 9/10] [Batch 190/350] [D loss: 0.251166, acc:  51%] [G loss: 1.228250] time: 5:51:33.919427\n",
      "[Epoch 9/10] [Batch 191/350] [D loss: 0.251481, acc:  45%] [G loss: 1.068488] time: 5:51:40.271442\n",
      "[Epoch 9/10] [Batch 192/350] [D loss: 0.251281, acc:  44%] [G loss: 0.987742] time: 5:51:46.609496\n",
      "[Epoch 9/10] [Batch 193/350] [D loss: 0.251528, acc:  50%] [G loss: 1.106939] time: 5:51:52.914638\n",
      "[Epoch 9/10] [Batch 194/350] [D loss: 0.251538, acc:  50%] [G loss: 1.209884] time: 5:51:59.239725\n",
      "[Epoch 9/10] [Batch 195/350] [D loss: 0.251799, acc:  45%] [G loss: 1.040017] time: 5:52:05.552845\n",
      "[Epoch 9/10] [Batch 196/350] [D loss: 0.252160, acc:  54%] [G loss: 1.099459] time: 5:52:11.834051\n",
      "[Epoch 9/10] [Batch 197/350] [D loss: 0.251847, acc:  52%] [G loss: 0.919146] time: 5:52:18.219976\n",
      "[Epoch 9/10] [Batch 198/350] [D loss: 0.251586, acc:  48%] [G loss: 1.037520] time: 5:52:24.533129\n",
      "[Epoch 9/10] [Batch 199/350] [D loss: 0.251903, acc:  45%] [G loss: 1.069950] time: 5:52:30.857187\n",
      "[Epoch 9/10] [Batch 200/350] [D loss: 0.251489, acc:  45%] [G loss: 1.118336] time: 5:52:37.168312\n",
      "[Epoch 9/10] [Batch 201/350] [D loss: 0.250942, acc:  49%] [G loss: 0.926193] time: 5:52:43.480435\n",
      "[Epoch 9/10] [Batch 202/350] [D loss: 0.251105, acc:  46%] [G loss: 1.063438] time: 5:52:49.789565\n",
      "[Epoch 9/10] [Batch 203/350] [D loss: 0.251078, acc:  44%] [G loss: 1.008063] time: 5:52:56.108670\n",
      "[Epoch 9/10] [Batch 204/350] [D loss: 0.251140, acc:  45%] [G loss: 1.006970] time: 5:53:02.405841\n",
      "[Epoch 9/10] [Batch 205/350] [D loss: 0.251204, acc:  52%] [G loss: 0.960712] time: 5:53:08.715960\n",
      "[Epoch 9/10] [Batch 206/350] [D loss: 0.251099, acc:  52%] [G loss: 0.984804] time: 5:53:15.027086\n",
      "[Epoch 9/10] [Batch 207/350] [D loss: 0.251105, acc:  51%] [G loss: 1.102823] time: 5:53:21.344195\n",
      "[Epoch 9/10] [Batch 208/350] [D loss: 0.251180, acc:  47%] [G loss: 0.986471] time: 5:53:27.660307\n",
      "[Epoch 9/10] [Batch 209/350] [D loss: 0.251771, acc:  47%] [G loss: 1.151993] time: 5:53:33.988387\n",
      "[Epoch 9/10] [Batch 210/350] [D loss: 0.251490, acc:  51%] [G loss: 1.072341] time: 5:53:40.332424\n",
      "[Epoch 9/10] [Batch 211/350] [D loss: 0.251259, acc:  47%] [G loss: 0.948757] time: 5:53:46.679453\n",
      "[Epoch 9/10] [Batch 212/350] [D loss: 0.251134, acc:  44%] [G loss: 0.881013] time: 5:53:53.003576\n",
      "[Epoch 9/10] [Batch 213/350] [D loss: 0.251381, acc:  48%] [G loss: 1.036346] time: 5:53:59.327635\n",
      "[Epoch 9/10] [Batch 214/350] [D loss: 0.250982, acc:  48%] [G loss: 0.985612] time: 5:54:05.654718\n",
      "[Epoch 9/10] [Batch 215/350] [D loss: 0.250944, acc:  49%] [G loss: 1.070591] time: 5:54:11.973821\n",
      "[Epoch 9/10] [Batch 216/350] [D loss: 0.250900, acc:  49%] [G loss: 0.950539] time: 5:54:18.266995\n",
      "[Epoch 9/10] [Batch 217/350] [D loss: 0.250933, acc:  48%] [G loss: 0.912741] time: 5:54:24.584104\n",
      "[Epoch 9/10] [Batch 218/350] [D loss: 0.251044, acc:  48%] [G loss: 1.029923] time: 5:54:30.917171\n",
      "[Epoch 9/10] [Batch 219/350] [D loss: 0.251882, acc:  39%] [G loss: 0.984572] time: 5:54:37.263234\n",
      "[Epoch 9/10] [Batch 220/350] [D loss: 0.252248, acc:  48%] [G loss: 1.180541] time: 5:54:43.603282\n",
      "[Epoch 9/10] [Batch 221/350] [D loss: 0.251763, acc:  45%] [G loss: 0.891263] time: 5:54:49.903405\n",
      "[Epoch 9/10] [Batch 222/350] [D loss: 0.251228, acc:  49%] [G loss: 0.940576] time: 5:54:56.218520\n",
      "[Epoch 9/10] [Batch 223/350] [D loss: 0.251432, acc:  52%] [G loss: 1.105988] time: 5:55:02.556573\n",
      "[Epoch 9/10] [Batch 224/350] [D loss: 0.251541, acc:  50%] [G loss: 1.086719] time: 5:55:08.865705\n",
      "[Epoch 9/10] [Batch 225/350] [D loss: 0.250943, acc:  52%] [G loss: 1.084441] time: 5:55:15.185805\n",
      "[Epoch 9/10] [Batch 226/350] [D loss: 0.250906, acc:  47%] [G loss: 1.271399] time: 5:55:21.500920\n",
      "[Epoch 9/10] [Batch 227/350] [D loss: 0.251294, acc:  47%] [G loss: 1.346984] time: 5:55:27.844958\n",
      "[Epoch 9/10] [Batch 228/350] [D loss: 0.251292, acc:  48%] [G loss: 1.212485] time: 5:55:34.171043\n",
      "[Epoch 9/10] [Batch 229/350] [D loss: 0.251042, acc:  48%] [G loss: 1.307236] time: 5:55:40.546995\n",
      "[Epoch 9/10] [Batch 230/350] [D loss: 0.251214, acc:  51%] [G loss: 1.267050] time: 5:55:46.895022\n",
      "[Epoch 9/10] [Batch 231/350] [D loss: 0.251274, acc:  45%] [G loss: 1.412442] time: 5:55:53.178253\n",
      "[Epoch 9/10] [Batch 232/350] [D loss: 0.251198, acc:  51%] [G loss: 1.121076] time: 5:55:59.484391\n",
      "[Epoch 9/10] [Batch 233/350] [D loss: 0.251196, acc:  47%] [G loss: 1.131442] time: 5:56:05.804461\n",
      "[Epoch 9/10] [Batch 234/350] [D loss: 0.251219, acc:  48%] [G loss: 1.192606] time: 5:56:12.122568\n",
      "[Epoch 9/10] [Batch 235/350] [D loss: 0.251001, acc:  48%] [G loss: 1.188796] time: 5:56:18.446659\n",
      "[Epoch 9/10] [Batch 236/350] [D loss: 0.251141, acc:  43%] [G loss: 1.095409] time: 5:56:24.767758\n",
      "[Epoch 9/10] [Batch 237/350] [D loss: 0.251151, acc:  48%] [G loss: 1.110734] time: 5:56:31.095837\n",
      "[Epoch 9/10] [Batch 238/350] [D loss: 0.250988, acc:  49%] [G loss: 1.082633] time: 5:56:37.414941\n",
      "[Epoch 9/10] [Batch 239/350] [D loss: 0.250828, acc:  46%] [G loss: 1.051222] time: 5:56:43.737037\n",
      "[Epoch 9/10] [Batch 240/350] [D loss: 0.251094, acc:  46%] [G loss: 1.149992] time: 5:56:50.052152\n",
      "[Epoch 9/10] [Batch 241/350] [D loss: 0.251135, acc:  47%] [G loss: 1.059113] time: 5:56:56.381261\n",
      "[Epoch 9/10] [Batch 242/350] [D loss: 0.251035, acc:  43%] [G loss: 1.060130] time: 5:57:02.689369\n",
      "[Epoch 9/10] [Batch 243/350] [D loss: 0.251512, acc:  41%] [G loss: 1.305809] time: 5:57:09.019438\n",
      "[Epoch 9/10] [Batch 244/350] [D loss: 0.251484, acc:  49%] [G loss: 1.035331] time: 5:57:15.370465\n",
      "[Epoch 9/10] [Batch 245/350] [D loss: 0.251075, acc:  51%] [G loss: 1.107258] time: 5:57:21.688595\n",
      "[Epoch 9/10] [Batch 246/350] [D loss: 0.251117, acc:  54%] [G loss: 1.117500] time: 5:57:28.028611\n",
      "[Epoch 9/10] [Batch 247/350] [D loss: 0.251291, acc:  48%] [G loss: 1.011738] time: 5:57:34.370685\n",
      "[Epoch 9/10] [Batch 248/350] [D loss: 0.251056, acc:  44%] [G loss: 1.188454] time: 5:57:40.707709\n",
      "[Epoch 9/10] [Batch 249/350] [D loss: 0.251044, acc:  51%] [G loss: 1.272671] time: 5:57:47.061720\n",
      "[Epoch 9/10] [Batch 250/350] [D loss: 0.251186, acc:  46%] [G loss: 1.137218] time: 5:57:53.372845\n",
      "[Epoch 9/10] [Batch 251/350] [D loss: 0.251013, acc:  50%] [G loss: 1.097611] time: 5:57:59.694941\n",
      "[Epoch 9/10] [Batch 252/350] [D loss: 0.251200, acc:  50%] [G loss: 1.023610] time: 5:58:06.018035\n",
      "[Epoch 9/10] [Batch 253/350] [D loss: 0.251117, acc:  50%] [G loss: 1.258076] time: 5:58:12.348110\n",
      "[Epoch 9/10] [Batch 254/350] [D loss: 0.251178, acc:  47%] [G loss: 1.092110] time: 5:58:18.662226\n",
      "[Epoch 9/10] [Batch 255/350] [D loss: 0.251077, acc:  49%] [G loss: 1.081233] time: 5:58:24.985320\n",
      "[Epoch 9/10] [Batch 256/350] [D loss: 0.251244, acc:  44%] [G loss: 0.998762] time: 5:58:31.320382\n",
      "[Epoch 9/10] [Batch 257/350] [D loss: 0.251073, acc:  46%] [G loss: 1.153842] time: 5:58:37.660429\n",
      "[Epoch 9/10] [Batch 258/350] [D loss: 0.250898, acc:  46%] [G loss: 1.162852] time: 5:58:43.954600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] [Batch 259/350] [D loss: 0.250811, acc:  46%] [G loss: 0.935684] time: 5:58:50.288664\n",
      "[Epoch 9/10] [Batch 260/350] [D loss: 0.250860, acc:  49%] [G loss: 1.081445] time: 5:58:56.606771\n",
      "[Epoch 9/10] [Batch 261/350] [D loss: 0.251047, acc:  48%] [G loss: 0.982864] time: 5:59:02.921885\n",
      "[Epoch 9/10] [Batch 262/350] [D loss: 0.250950, acc:  45%] [G loss: 1.269048] time: 5:59:09.230019\n",
      "[Epoch 9/10] [Batch 263/350] [D loss: 0.251058, acc:  48%] [G loss: 1.040152] time: 5:59:15.551117\n",
      "[Epoch 9/10] [Batch 264/350] [D loss: 0.250980, acc:  49%] [G loss: 1.053524] time: 5:59:21.855261\n",
      "[Epoch 9/10] [Batch 265/350] [D loss: 0.251367, acc:  48%] [G loss: 0.929367] time: 5:59:28.175363\n",
      "[Epoch 9/10] [Batch 266/350] [D loss: 0.251273, acc:  48%] [G loss: 0.996236] time: 5:59:34.502477\n",
      "[Epoch 9/10] [Batch 267/350] [D loss: 0.251240, acc:  48%] [G loss: 0.937745] time: 5:59:40.859448\n",
      "[Epoch 9/10] [Batch 268/350] [D loss: 0.251365, acc:  55%] [G loss: 1.035185] time: 5:59:47.174563\n",
      "[Epoch 9/10] [Batch 269/350] [D loss: 0.251596, acc:  47%] [G loss: 0.982576] time: 5:59:53.492697\n",
      "[Epoch 9/10] [Batch 270/350] [D loss: 0.251253, acc:  40%] [G loss: 1.088827] time: 5:59:59.785843\n",
      "[Epoch 9/10] [Batch 271/350] [D loss: 0.251270, acc:  51%] [G loss: 0.925252] time: 6:00:06.110931\n",
      "[Epoch 9/10] [Batch 272/350] [D loss: 0.251237, acc:  49%] [G loss: 1.140422] time: 6:00:12.428072\n",
      "[Epoch 9/10] [Batch 273/350] [D loss: 0.251059, acc:  52%] [G loss: 1.132851] time: 6:00:18.741160\n",
      "[Epoch 9/10] [Batch 274/350] [D loss: 0.250813, acc:  49%] [G loss: 1.188905] time: 6:00:25.054280\n",
      "[Epoch 9/10] [Batch 275/350] [D loss: 0.251212, acc:  48%] [G loss: 1.116390] time: 6:00:31.380365\n",
      "[Epoch 9/10] [Batch 276/350] [D loss: 0.251155, acc:  56%] [G loss: 1.005594] time: 6:00:37.680520\n",
      "[Epoch 9/10] [Batch 277/350] [D loss: 0.251244, acc:  49%] [G loss: 1.022178] time: 6:00:44.001650\n",
      "[Epoch 9/10] [Batch 278/350] [D loss: 0.251003, acc:  48%] [G loss: 1.090667] time: 6:00:50.810646\n",
      "[Epoch 9/10] [Batch 279/350] [D loss: 0.251031, acc:  46%] [G loss: 1.059716] time: 6:00:57.348134\n",
      "[Epoch 9/10] [Batch 280/350] [D loss: 0.250992, acc:  49%] [G loss: 1.017760] time: 6:01:03.680204\n",
      "[Epoch 9/10] [Batch 281/350] [D loss: 0.250990, acc:  49%] [G loss: 1.011828] time: 6:01:10.055158\n",
      "[Epoch 9/10] [Batch 282/350] [D loss: 0.251303, acc:  50%] [G loss: 1.013211] time: 6:01:16.427121\n",
      "[Epoch 9/10] [Batch 283/350] [D loss: 0.251424, acc:  46%] [G loss: 0.927025] time: 6:01:22.837979\n",
      "[Epoch 9/10] [Batch 284/350] [D loss: 0.251502, acc:  48%] [G loss: 0.978332] time: 6:01:29.162071\n",
      "[Epoch 9/10] [Batch 285/350] [D loss: 0.251083, acc:  45%] [G loss: 1.003068] time: 6:01:35.486161\n",
      "[Epoch 9/10] [Batch 286/350] [D loss: 0.250986, acc:  47%] [G loss: 1.004185] time: 6:01:41.856129\n",
      "[Epoch 9/10] [Batch 287/350] [D loss: 0.250871, acc:  46%] [G loss: 1.039563] time: 6:01:48.178225\n",
      "[Epoch 9/10] [Batch 288/350] [D loss: 0.251015, acc:  47%] [G loss: 1.079183] time: 6:01:54.510294\n",
      "[Epoch 9/10] [Batch 289/350] [D loss: 0.251102, acc:  55%] [G loss: 1.086477] time: 6:02:00.799478\n",
      "[Epoch 9/10] [Batch 290/350] [D loss: 0.251102, acc:  50%] [G loss: 0.895578] time: 6:02:07.133542\n",
      "[Epoch 9/10] [Batch 291/350] [D loss: 0.251275, acc:  45%] [G loss: 1.091461] time: 6:02:13.471595\n",
      "[Epoch 9/10] [Batch 292/350] [D loss: 0.251004, acc:  48%] [G loss: 1.023310] time: 6:02:19.792695\n",
      "[Epoch 9/10] [Batch 293/350] [D loss: 0.250939, acc:  47%] [G loss: 1.369084] time: 6:02:26.125760\n",
      "[Epoch 9/10] [Batch 294/350] [D loss: 0.251058, acc:  55%] [G loss: 1.102570] time: 6:02:32.444865\n",
      "[Epoch 9/10] [Batch 295/350] [D loss: 0.251206, acc:  49%] [G loss: 1.206876] time: 6:02:38.737041\n",
      "[Epoch 9/10] [Batch 296/350] [D loss: 0.251011, acc:  45%] [G loss: 1.327106] time: 6:02:45.062129\n",
      "[Epoch 9/10] [Batch 297/350] [D loss: 0.250882, acc:  48%] [G loss: 1.094502] time: 6:02:51.372257\n",
      "[Epoch 9/10] [Batch 298/350] [D loss: 0.250875, acc:  49%] [G loss: 1.203672] time: 6:02:57.681388\n",
      "[Epoch 9/10] [Batch 299/350] [D loss: 0.250960, acc:  47%] [G loss: 1.317682] time: 6:03:04.011462\n",
      "[Epoch 9/10] [Batch 300/350] [D loss: 0.251256, acc:  48%] [G loss: 1.337407] time: 6:03:10.319596\n",
      "[Epoch 9/10] [Batch 301/350] [D loss: 0.251221, acc:  48%] [G loss: 1.263257] time: 6:03:16.621745\n",
      "[Epoch 9/10] [Batch 302/350] [D loss: 0.251217, acc:  49%] [G loss: 0.994422] time: 6:03:22.940849\n",
      "[Epoch 9/10] [Batch 303/350] [D loss: 0.251092, acc:  52%] [G loss: 1.110967] time: 6:03:29.275911\n",
      "[Epoch 9/10] [Batch 304/350] [D loss: 0.251323, acc:  46%] [G loss: 0.927358] time: 6:03:35.617953\n",
      "[Epoch 9/10] [Batch 305/350] [D loss: 0.251301, acc:  49%] [G loss: 1.058794] time: 6:03:41.985926\n",
      "[Epoch 9/10] [Batch 306/350] [D loss: 0.250928, acc:  48%] [G loss: 1.054638] time: 6:03:48.300043\n",
      "[Epoch 9/10] [Batch 307/350] [D loss: 0.250998, acc:  45%] [G loss: 1.121148] time: 6:03:54.617153\n",
      "[Epoch 9/10] [Batch 308/350] [D loss: 0.250984, acc:  50%] [G loss: 1.024942] time: 6:04:00.944236\n",
      "[Epoch 9/10] [Batch 309/350] [D loss: 0.250992, acc:  50%] [G loss: 1.013479] time: 6:04:07.263340\n",
      "[Epoch 9/10] [Batch 310/350] [D loss: 0.251027, acc:  48%] [G loss: 1.047191] time: 6:04:13.596406\n",
      "[Epoch 9/10] [Batch 311/350] [D loss: 0.250914, acc:  45%] [G loss: 1.107010] time: 6:04:19.936454\n",
      "[Epoch 9/10] [Batch 312/350] [D loss: 0.251606, acc:  46%] [G loss: 1.036420] time: 6:04:26.344349\n",
      "[Epoch 9/10] [Batch 313/350] [D loss: 0.251671, acc:  50%] [G loss: 0.889156] time: 6:04:32.676390\n",
      "[Epoch 9/10] [Batch 314/350] [D loss: 0.252099, acc:  49%] [G loss: 1.100648] time: 6:04:39.051345\n",
      "[Epoch 9/10] [Batch 315/350] [D loss: 0.251574, acc:  49%] [G loss: 1.050328] time: 6:04:45.375435\n",
      "[Epoch 9/10] [Batch 316/350] [D loss: 0.251619, acc:  50%] [G loss: 1.101924] time: 6:04:51.678583\n",
      "[Epoch 9/10] [Batch 317/350] [D loss: 0.252410, acc:  51%] [G loss: 1.053953] time: 6:04:57.993697\n",
      "[Epoch 9/10] [Batch 318/350] [D loss: 0.252008, acc:  47%] [G loss: 1.132434] time: 6:05:04.304854\n",
      "[Epoch 9/10] [Batch 319/350] [D loss: 0.251099, acc:  51%] [G loss: 0.998641] time: 6:05:10.587024\n",
      "[Epoch 9/10] [Batch 320/350] [D loss: 0.251350, acc:  48%] [G loss: 1.109676] time: 6:05:16.909121\n",
      "[Epoch 9/10] [Batch 321/350] [D loss: 0.251632, acc:  48%] [G loss: 1.100507] time: 6:05:23.240193\n",
      "[Epoch 9/10] [Batch 322/350] [D loss: 0.251276, acc:  50%] [G loss: 1.259211] time: 6:05:29.569270\n",
      "[Epoch 9/10] [Batch 323/350] [D loss: 0.251211, acc:  49%] [G loss: 1.098960] time: 6:05:35.901339\n",
      "[Epoch 9/10] [Batch 324/350] [D loss: 0.251120, acc:  48%] [G loss: 0.979500] time: 6:05:42.295243\n",
      "[Epoch 9/10] [Batch 325/350] [D loss: 0.250948, acc:  44%] [G loss: 1.120613] time: 6:05:48.587420\n",
      "[Epoch 9/10] [Batch 326/350] [D loss: 0.251281, acc:  51%] [G loss: 1.053753] time: 6:05:54.869622\n",
      "[Epoch 9/10] [Batch 327/350] [D loss: 0.251199, acc:  44%] [G loss: 0.967246] time: 6:06:01.208673\n",
      "[Epoch 9/10] [Batch 328/350] [D loss: 0.251169, acc:  47%] [G loss: 0.977763] time: 6:06:07.550715\n",
      "[Epoch 9/10] [Batch 329/350] [D loss: 0.250987, acc:  49%] [G loss: 1.080268] time: 6:06:13.866827\n",
      "[Epoch 9/10] [Batch 330/350] [D loss: 0.250981, acc:  49%] [G loss: 1.140665] time: 6:06:20.154027\n",
      "[Epoch 9/10] [Batch 331/350] [D loss: 0.251050, acc:  49%] [G loss: 1.157877] time: 6:06:26.491073\n",
      "[Epoch 9/10] [Batch 332/350] [D loss: 0.251132, acc:  48%] [G loss: 1.232363] time: 6:06:32.793223\n",
      "[Epoch 9/10] [Batch 333/350] [D loss: 0.251222, acc:  46%] [G loss: 0.971800] time: 6:06:39.109335\n",
      "[Epoch 9/10] [Batch 334/350] [D loss: 0.251145, acc:  46%] [G loss: 1.024744] time: 6:06:45.427441\n",
      "[Epoch 9/10] [Batch 335/350] [D loss: 0.251271, acc:  43%] [G loss: 1.147377] time: 6:06:51.727596\n",
      "[Epoch 9/10] [Batch 336/350] [D loss: 0.251305, acc:  49%] [G loss: 1.144766] time: 6:06:58.054678\n",
      "[Epoch 9/10] [Batch 337/350] [D loss: 0.251018, acc:  50%] [G loss: 1.056738] time: 6:07:04.382758\n",
      "[Epoch 9/10] [Batch 338/350] [D loss: 0.250955, acc:  48%] [G loss: 1.186228] time: 6:07:10.710838\n",
      "[Epoch 9/10] [Batch 339/350] [D loss: 0.250811, acc:  46%] [G loss: 0.992597] time: 6:07:17.081804\n",
      "[Epoch 9/10] [Batch 340/350] [D loss: 0.251193, acc:  39%] [G loss: 0.956002] time: 6:07:23.414902\n",
      "[Epoch 9/10] [Batch 341/350] [D loss: 0.251350, acc:  48%] [G loss: 0.986823] time: 6:07:29.715056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] [Batch 342/350] [D loss: 0.251307, acc:  46%] [G loss: 1.254246] time: 6:07:36.027147\n",
      "[Epoch 9/10] [Batch 343/350] [D loss: 0.251288, acc:  49%] [G loss: 1.079780] time: 6:07:42.421084\n",
      "[Epoch 9/10] [Batch 344/350] [D loss: 0.251662, acc:  45%] [G loss: 1.148721] time: 6:07:48.735200\n",
      "[Epoch 9/10] [Batch 345/350] [D loss: 0.251563, acc:  51%] [G loss: 1.037053] time: 6:07:55.051312\n",
      "[Epoch 9/10] [Batch 346/350] [D loss: 0.251328, acc:  47%] [G loss: 1.027043] time: 6:08:01.367393\n",
      "[Epoch 9/10] [Batch 347/350] [D loss: 0.251465, acc:  55%] [G loss: 1.016329] time: 6:08:07.667548\n",
      "[Epoch 9/10] [Batch 348/350] [D loss: 0.251553, acc:  49%] [G loss: 0.952170] time: 6:08:13.970727\n",
      "weights saved...\n"
     ]
    }
   ],
   "source": [
    "gan.train(epochs=10, batch_size=100, sample_interval=175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "C:\\Users\\miche\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "C:\\Users\\miche\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "#gan.save(10)\n",
    "gan.sample_images(11,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "data = DataLoader(dataset_name=\"val_256\",\n",
    "                                      img_res=(256, 256))\n",
    "imgs_A, imgs_B = data.load_data(batch_size=60, is_testing=True)\n",
    "\n",
    "r, c = 3, 3\n",
    "\n",
    "fake_A = gan.generator.predict(imgs_B)\n",
    "\n",
    "gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "# Rescale images 0 - 1\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "fake_A = 0.5 * fake_A + 0.5\n",
    "imgs_B = 0.5 * imgs_B + 0.5\n",
    "imgs_A = 0.5 * imgs_A + 0.5\n",
    "titles = ['Originale', 'B&W', 'Generata']\n",
    "\n",
    "\n",
    "ic = 0\n",
    "f=0\n",
    "cnt = 0\n",
    "for img in fake_A:\n",
    "    f += 1\n",
    "    imsave('images/test9000/testOutput%d.png' % (f), img)\n",
    "    \n",
    "    if ic==2:\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        axs[0, 0].set_title(titles[0])\n",
    "        axs[0, 1].set_title(titles[1])\n",
    "        axs[0, 2].set_title(titles[2])\n",
    "        for i in range(r):\n",
    "            axs[i,0].imshow(imgs_A[cnt])\n",
    "            axs[i,1].imshow(imgs_B[cnt])\n",
    "            axs[i,2].imshow(fake_A[cnt])\n",
    "            cnt += 1\n",
    "        \n",
    "        fig.savefig(\"images/test9000/%d.png\" % (cnt))\n",
    "        plt.close()\n",
    "    if ic == 2:\n",
    "        ic=0\n",
    "    else:\n",
    "        ic += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_A, embed ,imgs_B = gan.data_loader.load_data(batch_size=2)\n",
    "fake_A = gan.generator.predict([imgs_B , embed])\n",
    "fake_A = fake_A * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(fake_A)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = imgs_B[i][:,:,0]\n",
    "    cur[:,:,1:] = fake_A[i]\n",
    "    imsave(\"images/test-c1/img_final_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
